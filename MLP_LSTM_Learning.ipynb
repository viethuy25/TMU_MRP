{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b61c5998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f9335d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605a487b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>encoded_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509812</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.906781e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509813</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.486586e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.179891e-05</td>\n",
       "      <td>0.022490</td>\n",
       "      <td>0.680028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459038</td>\n",
       "      <td>6.565172e-07</td>\n",
       "      <td>8.784210e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.578240</td>\n",
       "      <td>0.999839</td>\n",
       "      <td>0.016088</td>\n",
       "      <td>6.101171e-03</td>\n",
       "      <td>3.595742e-01</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.016082</td>\n",
       "      <td>0.037998</td>\n",
       "      <td>6.038352e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.081934e-03</td>\n",
       "      <td>0.039148</td>\n",
       "      <td>0.764455</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.019570</td>\n",
       "      <td>2.624302e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.467841</td>\n",
       "      <td>0.996626</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.092086e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.040388e-04</td>\n",
       "      <td>0.028460</td>\n",
       "      <td>0.859879</td>\n",
       "      <td>0.242375</td>\n",
       "      <td>0.361443</td>\n",
       "      <td>3.157241e-02</td>\n",
       "      <td>6.552889e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.322503</td>\n",
       "      <td>0.989857</td>\n",
       "      <td>0.023677</td>\n",
       "      <td>1.015950e-06</td>\n",
       "      <td>7.954423e-01</td>\n",
       "      <td>0.412684</td>\n",
       "      <td>0.127934</td>\n",
       "      <td>0.015942</td>\n",
       "      <td>0.116336</td>\n",
       "      <td>6.150468e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.787286e-04</td>\n",
       "      <td>0.033901</td>\n",
       "      <td>0.751330</td>\n",
       "      <td>0.049434</td>\n",
       "      <td>0.032961</td>\n",
       "      <td>4.568948e-02</td>\n",
       "      <td>1.137700e-03</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388330</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388331</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388332</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388333</th>\n",
       "      <td>0.293524</td>\n",
       "      <td>0.951149</td>\n",
       "      <td>0.006017</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.639506e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006017</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.380474e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.850077e-05</td>\n",
       "      <td>0.009008</td>\n",
       "      <td>0.996098</td>\n",
       "      <td>0.070973</td>\n",
       "      <td>0.048470</td>\n",
       "      <td>1.586959e-01</td>\n",
       "      <td>6.269141e-01</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388334</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5388335 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_0  feature_1  feature_2     feature_3     feature_4  \\\n",
       "0         0.428620   1.000000   0.509812  0.000000e+00  8.906781e-07   \n",
       "1         0.578240   0.999839   0.016088  6.101171e-03  3.595742e-01   \n",
       "2         0.467841   0.996626   0.002890  0.000000e+00  0.000000e+00   \n",
       "3         0.322503   0.989857   0.023677  1.015950e-06  7.954423e-01   \n",
       "4         0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "...            ...        ...        ...           ...           ...   \n",
       "5388330   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "5388331   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "5388332   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "5388333   0.293524   0.951149   0.006017  0.000000e+00  4.639506e-07   \n",
       "5388334   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "\n",
       "         feature_5  feature_6  feature_7  feature_8     feature_9  ...  \\\n",
       "0         0.000000   0.000000   0.509813   0.000001  2.486586e-06  ...   \n",
       "1         0.000223   0.000125   0.016082   0.037998  6.038352e-05  ...   \n",
       "2         0.000000   0.000000   0.002891   0.000000  4.092086e-04  ...   \n",
       "3         0.412684   0.127934   0.015942   0.116336  6.150468e-05  ...   \n",
       "4         0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "...            ...        ...        ...        ...           ...  ...   \n",
       "5388330   0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "5388331   0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "5388332   0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "5388333   0.000000   0.000000   0.006017   0.000001  2.380474e-04  ...   \n",
       "5388334   0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "\n",
       "         feature_11    feature_12  feature_13  feature_14  feature_15  \\\n",
       "0               0.0  9.179891e-05    0.022490    0.680028    1.000000   \n",
       "1               1.0  5.081934e-03    0.039148    0.764455    0.000006   \n",
       "2               0.0  1.040388e-04    0.028460    0.859879    0.242375   \n",
       "3               0.0  2.787286e-04    0.033901    0.751330    0.049434   \n",
       "4               0.0  1.587743e-08    0.000004    0.580702    0.000543   \n",
       "...             ...           ...         ...         ...         ...   \n",
       "5388330         0.0  1.587743e-08    0.000004    0.580702    0.000543   \n",
       "5388331         0.0  1.587743e-08    0.000004    0.580702    0.000543   \n",
       "5388332         0.0  1.587743e-08    0.000004    0.580702    0.000543   \n",
       "5388333         0.0  8.850077e-05    0.009008    0.996098    0.070973   \n",
       "5388334         0.0  1.587743e-08    0.000004    0.580702    0.000543   \n",
       "\n",
       "         feature_16    feature_17    feature_18  feature_19  encoded_tags  \n",
       "0          0.459038  6.565172e-07  8.784210e-09    0.000003           184  \n",
       "1          0.019570  2.624302e-01  0.000000e+00    0.000404           141  \n",
       "2          0.361443  3.157241e-02  6.552889e-06    0.000009           194  \n",
       "3          0.032961  4.568948e-02  1.137700e-03    0.000133            60  \n",
       "4          1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "...             ...           ...           ...         ...           ...  \n",
       "5388330    1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "5388331    1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "5388332    1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "5388333    0.048470  1.586959e-01  6.269141e-01    0.000092           142  \n",
       "5388334    1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "\n",
       "[5388335 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed_data_expanded = pd.read_csv('./output/scaled_train_data.csv')\n",
    "# train_processed_data_expanded = train_processed_data_expanded.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "train_processed_data_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed7f7364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>encoded_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.327324</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.219593</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.189355e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.219594</td>\n",
       "      <td>5.066213e-02</td>\n",
       "      <td>6.685087e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998936</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.153770</td>\n",
       "      <td>5.788697e-01</td>\n",
       "      <td>8.198362e-01</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.327324</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.219593</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.189355e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.219594</td>\n",
       "      <td>5.066213e-02</td>\n",
       "      <td>6.685087e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998936</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.153770</td>\n",
       "      <td>5.788697e-01</td>\n",
       "      <td>8.198362e-01</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.268661</td>\n",
       "      <td>0.999726</td>\n",
       "      <td>0.011852</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.806285e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.011853</td>\n",
       "      <td>1.266585e-07</td>\n",
       "      <td>1.335921e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.040388e-04</td>\n",
       "      <td>0.028460</td>\n",
       "      <td>0.859879</td>\n",
       "      <td>0.242375</td>\n",
       "      <td>0.361443</td>\n",
       "      <td>3.157241e-02</td>\n",
       "      <td>6.552889e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.428620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509812</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.906781e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.509813</td>\n",
       "      <td>1.013268e-06</td>\n",
       "      <td>2.486586e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.179891e-05</td>\n",
       "      <td>0.022490</td>\n",
       "      <td>0.680028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459038</td>\n",
       "      <td>6.565172e-07</td>\n",
       "      <td>8.784210e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.387329</td>\n",
       "      <td>0.612336</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.416578e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.099598e-05</td>\n",
       "      <td>0.008395</td>\n",
       "      <td>0.300106</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.597327e-07</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149097</th>\n",
       "      <td>0.296351</td>\n",
       "      <td>0.983435</td>\n",
       "      <td>0.160314</td>\n",
       "      <td>4.718805e-03</td>\n",
       "      <td>4.475495e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.160314</td>\n",
       "      <td>1.199722e-03</td>\n",
       "      <td>9.322364e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.734385e-03</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.706279</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.130509</td>\n",
       "      <td>3.088446e-02</td>\n",
       "      <td>4.192803e-07</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149098</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.276211e-02</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149099</th>\n",
       "      <td>0.387087</td>\n",
       "      <td>0.560943</td>\n",
       "      <td>0.115950</td>\n",
       "      <td>3.422385e-09</td>\n",
       "      <td>7.597835e-01</td>\n",
       "      <td>0.928852</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.115950</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.698501e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.448698e-08</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.208585</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.176432</td>\n",
       "      <td>8.838643e-01</td>\n",
       "      <td>1.165525e-05</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149100</th>\n",
       "      <td>0.428620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509812</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.906781e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.509813</td>\n",
       "      <td>1.013268e-06</td>\n",
       "      <td>2.486586e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.179891e-05</td>\n",
       "      <td>0.022490</td>\n",
       "      <td>0.680028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459038</td>\n",
       "      <td>6.565172e-07</td>\n",
       "      <td>8.784210e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149101</th>\n",
       "      <td>0.510120</td>\n",
       "      <td>0.939192</td>\n",
       "      <td>0.067684</td>\n",
       "      <td>3.353653e-11</td>\n",
       "      <td>6.993792e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>1.393255e-02</td>\n",
       "      <td>1.446382e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.179891e-05</td>\n",
       "      <td>0.022490</td>\n",
       "      <td>0.680028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459038</td>\n",
       "      <td>6.565172e-07</td>\n",
       "      <td>8.784210e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1149102 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_0  feature_1  feature_2     feature_3     feature_4  \\\n",
       "0         0.327324   0.999999   0.219593  1.000000e+00  4.189355e-01   \n",
       "1         0.327324   0.999999   0.219593  1.000000e+00  4.189355e-01   \n",
       "2         0.268661   0.999726   0.011852  0.000000e+00  4.806285e-08   \n",
       "3         0.428620   1.000000   0.509812  0.000000e+00  8.906781e-07   \n",
       "4         0.387329   0.612336   0.001213  0.000000e+00  0.000000e+00   \n",
       "...            ...        ...        ...           ...           ...   \n",
       "1149097   0.296351   0.983435   0.160314  4.718805e-03  4.475495e-02   \n",
       "1149098   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "1149099   0.387087   0.560943   0.115950  3.422385e-09  7.597835e-01   \n",
       "1149100   0.428620   1.000000   0.509812  0.000000e+00  8.906781e-07   \n",
       "1149101   0.510120   0.939192   0.067684  3.353653e-11  6.993792e-03   \n",
       "\n",
       "         feature_5  feature_6  feature_7     feature_8     feature_9  ...  \\\n",
       "0         0.000000    0.00000   0.219594  5.066213e-02  6.685087e-06  ...   \n",
       "1         0.000000    0.00000   0.219594  5.066213e-02  6.685087e-06  ...   \n",
       "2         0.000000    0.00000   0.011853  1.266585e-07  1.335921e-04  ...   \n",
       "3         0.000000    0.00000   0.509813  1.013268e-06  2.486586e-06  ...   \n",
       "4         0.000000    0.00000   0.001214  0.000000e+00  4.416578e-04  ...   \n",
       "...            ...        ...        ...           ...           ...  ...   \n",
       "1149097   0.000000    0.00000   0.160314  1.199722e-03  9.322364e-06  ...   \n",
       "1149098   0.000000    0.00000   1.000000  5.276211e-02  7.937312e-07  ...   \n",
       "1149099   0.928852    0.00001   0.115950  1.000000e+00  3.698501e-06  ...   \n",
       "1149100   0.000000    0.00000   0.509813  1.013268e-06  2.486586e-06  ...   \n",
       "1149101   0.000000    1.00000   0.007203  1.393255e-02  1.446382e-05  ...   \n",
       "\n",
       "         feature_11    feature_12  feature_13  feature_14  feature_15  \\\n",
       "0               0.0  1.000000e+00    1.000000    0.998936    0.001565   \n",
       "1               0.0  1.000000e+00    1.000000    0.998936    0.001565   \n",
       "2               0.0  1.040388e-04    0.028460    0.859879    0.242375   \n",
       "3               0.0  9.179891e-05    0.022490    0.680028    1.000000   \n",
       "4               0.0  1.099598e-05    0.008395    0.300106    0.000536   \n",
       "...             ...           ...         ...         ...         ...   \n",
       "1149097         1.0  4.734385e-03    0.001017    0.706279    0.000131   \n",
       "1149098         0.0  1.587743e-08    0.000004    0.580702    0.000543   \n",
       "1149099         1.0  2.448698e-08    0.000063    0.208585    0.000009   \n",
       "1149100         0.0  9.179891e-05    0.022490    0.680028    1.000000   \n",
       "1149101         0.0  9.179891e-05    0.022490    0.680028    1.000000   \n",
       "\n",
       "         feature_16    feature_17    feature_18  feature_19  encoded_tags  \n",
       "0          0.153770  5.788697e-01  8.198362e-01    0.000041           124  \n",
       "1          0.153770  5.788697e-01  8.198362e-01    0.000041           124  \n",
       "2          0.361443  3.157241e-02  6.552889e-06    0.000009           194  \n",
       "3          0.459038  6.565172e-07  8.784210e-09    0.000003           184  \n",
       "4          0.002547  0.000000e+00  4.597327e-07    0.002466           214  \n",
       "...             ...           ...           ...         ...           ...  \n",
       "1149097    0.130509  3.088446e-02  4.192803e-07    0.000040           106  \n",
       "1149098    1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "1149099    0.176432  8.838643e-01  1.165525e-05    0.000031            99  \n",
       "1149100    0.459038  6.565172e-07  8.784210e-09    0.000003           184  \n",
       "1149101    0.459038  6.565172e-07  8.784210e-09    0.000003           184  \n",
       "\n",
       "[1149102 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed_data_expanded = pd.read_csv('./output/scaled_test_data.csv')\n",
    "# train_processed_data_expanded = train_processed_data_expanded.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "test_processed_data_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "594c02f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>encoded_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.566236</td>\n",
       "      <td>0.697855</td>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.972780e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.179891e-05</td>\n",
       "      <td>2.248993e-02</td>\n",
       "      <td>0.680028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459038</td>\n",
       "      <td>6.565172e-07</td>\n",
       "      <td>8.784210e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.395012</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.012381</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.524506e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012382</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>1.076902e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.002599e-05</td>\n",
       "      <td>6.486638e-03</td>\n",
       "      <td>0.730756</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>0.013356</td>\n",
       "      <td>6.395042e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>3.891505e-06</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.387087</td>\n",
       "      <td>0.560943</td>\n",
       "      <td>0.115950</td>\n",
       "      <td>3.422385e-09</td>\n",
       "      <td>7.597835e-01</td>\n",
       "      <td>0.928852</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.115950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.698501e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.437215e-09</td>\n",
       "      <td>1.528109e-08</td>\n",
       "      <td>0.184108</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.197636</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.319294e-05</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.481720</td>\n",
       "      <td>0.478761</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>4.569686e-06</td>\n",
       "      <td>1.391312e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>5.133540e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.723015e-06</td>\n",
       "      <td>3.776245e-05</td>\n",
       "      <td>0.094714</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>0.015916</td>\n",
       "      <td>2.773921e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123244</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>3.891505e-06</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123245</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>3.891505e-06</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123246</th>\n",
       "      <td>0.428620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509812</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.906781e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509813</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.486586e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.179891e-05</td>\n",
       "      <td>2.248993e-02</td>\n",
       "      <td>0.680028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459038</td>\n",
       "      <td>6.565172e-07</td>\n",
       "      <td>8.784210e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123247</th>\n",
       "      <td>0.288678</td>\n",
       "      <td>0.987561</td>\n",
       "      <td>0.033791</td>\n",
       "      <td>2.722036e-03</td>\n",
       "      <td>1.401579e-02</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.033779</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>4.493264e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.863601e-04</td>\n",
       "      <td>2.160720e-02</td>\n",
       "      <td>0.905640</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.066771</td>\n",
       "      <td>1.111779e-01</td>\n",
       "      <td>2.173034e-02</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123248</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>3.891505e-06</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1123249 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_0  feature_1  feature_2     feature_3     feature_4  \\\n",
       "0         0.566236   0.697855   0.009106  0.000000e+00  0.000000e+00   \n",
       "1         0.395012   0.999643   0.012381  0.000000e+00  9.524506e-04   \n",
       "2         0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "3         0.387087   0.560943   0.115950  3.422385e-09  7.597835e-01   \n",
       "4         0.481720   0.478761   0.001350  4.569686e-06  1.391312e-02   \n",
       "...            ...        ...        ...           ...           ...   \n",
       "1123244   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "1123245   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "1123246   0.428620   1.000000   0.509812  0.000000e+00  8.906781e-07   \n",
       "1123247   0.288678   0.987561   0.033791  2.722036e-03  1.401579e-02   \n",
       "1123248   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "\n",
       "         feature_5  feature_6  feature_7  feature_8     feature_9  ...  \\\n",
       "0         0.000000   0.000000   0.009106   0.000000  3.972780e-05  ...   \n",
       "1         0.000000   0.000000   0.012382   0.000697  1.076902e-04  ...   \n",
       "2         0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "3         0.928852   0.000010   0.115950   1.000000  3.698501e-06  ...   \n",
       "4         0.000000   0.000000   0.001350   0.003393  5.133540e-05  ...   \n",
       "...            ...        ...        ...        ...           ...  ...   \n",
       "1123244   0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "1123245   0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "1123246   0.000000   0.000000   0.509813   0.000001  2.486586e-06  ...   \n",
       "1123247   0.000009   0.000208   0.033779   0.001292  4.493264e-05  ...   \n",
       "1123248   0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "\n",
       "         feature_11    feature_12    feature_13  feature_14  feature_15  \\\n",
       "0               0.0  9.179891e-05  2.248993e-02    0.680028    1.000000   \n",
       "1               0.0  4.002599e-05  6.486638e-03    0.730756    0.007162   \n",
       "2               0.0  1.587743e-08  3.891505e-06    0.580702    0.000543   \n",
       "3               1.0  3.437215e-09  1.528109e-08    0.184108    0.000010   \n",
       "4               1.0  1.723015e-06  3.776245e-05    0.094714    0.017997   \n",
       "...             ...           ...           ...         ...         ...   \n",
       "1123244         0.0  1.587743e-08  3.891505e-06    0.580702    0.000543   \n",
       "1123245         0.0  1.587743e-08  3.891505e-06    0.580702    0.000543   \n",
       "1123246         0.0  9.179891e-05  2.248993e-02    0.680028    1.000000   \n",
       "1123247         1.0  8.863601e-04  2.160720e-02    0.905640    0.000995   \n",
       "1123248         0.0  1.587743e-08  3.891505e-06    0.580702    0.000543   \n",
       "\n",
       "         feature_16    feature_17    feature_18  feature_19  encoded_tags  \n",
       "0          0.459038  6.565172e-07  8.784210e-09    0.000003           184  \n",
       "1          0.013356  6.395042e-04  0.000000e+00    0.000405           180  \n",
       "2          1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "3          0.197636  1.000000e+00  1.319294e-05    0.000027           154  \n",
       "4          0.015916  2.773921e-01  0.000000e+00    0.000272            19  \n",
       "...             ...           ...           ...         ...           ...  \n",
       "1123244    1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "1123245    1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "1123246    0.459038  6.565172e-07  8.784210e-09    0.000003           184  \n",
       "1123247    0.066771  1.111779e-01  2.173034e-02    0.000083            75  \n",
       "1123248    1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "\n",
       "[1123249 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_processed_data = pd.read_csv('./output/non_nan_balanced_data.csv')\n",
    "val_processed_data_expanded = pd.read_csv('./output/scaled_val_data.csv') \n",
    "# processed_data_expanded = processed_data_expanded.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "val_processed_data_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9a26c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.566236</td>\n",
       "      <td>0.697855</td>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.972780e-05</td>\n",
       "      <td>0.171641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.179891e-05</td>\n",
       "      <td>2.248993e-02</td>\n",
       "      <td>0.680028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459038</td>\n",
       "      <td>6.565172e-07</td>\n",
       "      <td>8.784210e-09</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.395012</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.012381</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.524506e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012382</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>1.076902e-04</td>\n",
       "      <td>0.632633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.002599e-05</td>\n",
       "      <td>6.486638e-03</td>\n",
       "      <td>0.730756</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>0.013356</td>\n",
       "      <td>6.395042e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>0.376586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>3.891505e-06</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.387087</td>\n",
       "      <td>0.560943</td>\n",
       "      <td>0.115950</td>\n",
       "      <td>3.422385e-09</td>\n",
       "      <td>7.597835e-01</td>\n",
       "      <td>0.928852</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.115950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.698501e-06</td>\n",
       "      <td>0.203465</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.437215e-09</td>\n",
       "      <td>1.528109e-08</td>\n",
       "      <td>0.184108</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.197636</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.319294e-05</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.481720</td>\n",
       "      <td>0.478761</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>4.569686e-06</td>\n",
       "      <td>1.391312e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>5.133540e-05</td>\n",
       "      <td>0.032889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.723015e-06</td>\n",
       "      <td>3.776245e-05</td>\n",
       "      <td>0.094714</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>0.015916</td>\n",
       "      <td>2.773921e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123244</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>0.376586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>3.891505e-06</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123245</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>0.376586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>3.891505e-06</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123246</th>\n",
       "      <td>0.428620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509812</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.906781e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509813</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.486586e-06</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.179891e-05</td>\n",
       "      <td>2.248993e-02</td>\n",
       "      <td>0.680028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459038</td>\n",
       "      <td>6.565172e-07</td>\n",
       "      <td>8.784210e-09</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123247</th>\n",
       "      <td>0.288678</td>\n",
       "      <td>0.987561</td>\n",
       "      <td>0.033791</td>\n",
       "      <td>2.722036e-03</td>\n",
       "      <td>1.401579e-02</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.033779</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>4.493264e-05</td>\n",
       "      <td>0.720373</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.863601e-04</td>\n",
       "      <td>2.160720e-02</td>\n",
       "      <td>0.905640</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.066771</td>\n",
       "      <td>1.111779e-01</td>\n",
       "      <td>2.173034e-02</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123248</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>0.376586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>3.891505e-06</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1123249 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_0  feature_1  feature_2     feature_3     feature_4  \\\n",
       "0         0.566236   0.697855   0.009106  0.000000e+00  0.000000e+00   \n",
       "1         0.395012   0.999643   0.012381  0.000000e+00  9.524506e-04   \n",
       "2         0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "3         0.387087   0.560943   0.115950  3.422385e-09  7.597835e-01   \n",
       "4         0.481720   0.478761   0.001350  4.569686e-06  1.391312e-02   \n",
       "...            ...        ...        ...           ...           ...   \n",
       "1123244   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "1123245   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "1123246   0.428620   1.000000   0.509812  0.000000e+00  8.906781e-07   \n",
       "1123247   0.288678   0.987561   0.033791  2.722036e-03  1.401579e-02   \n",
       "1123248   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "\n",
       "         feature_5  feature_6  feature_7  feature_8     feature_9  feature_10  \\\n",
       "0         0.000000   0.000000   0.009106   0.000000  3.972780e-05    0.171641   \n",
       "1         0.000000   0.000000   0.012382   0.000697  1.076902e-04    0.632633   \n",
       "2         0.000000   0.000000   1.000000   0.052762  7.937312e-07    0.376586   \n",
       "3         0.928852   0.000010   0.115950   1.000000  3.698501e-06    0.203465   \n",
       "4         0.000000   0.000000   0.001350   0.003393  5.133540e-05    0.032889   \n",
       "...            ...        ...        ...        ...           ...         ...   \n",
       "1123244   0.000000   0.000000   1.000000   0.052762  7.937312e-07    0.376586   \n",
       "1123245   0.000000   0.000000   1.000000   0.052762  7.937312e-07    0.376586   \n",
       "1123246   0.000000   0.000000   0.509813   0.000001  2.486586e-06    0.601457   \n",
       "1123247   0.000009   0.000208   0.033779   0.001292  4.493264e-05    0.720373   \n",
       "1123248   0.000000   0.000000   1.000000   0.052762  7.937312e-07    0.376586   \n",
       "\n",
       "         feature_11    feature_12    feature_13  feature_14  feature_15  \\\n",
       "0               0.0  9.179891e-05  2.248993e-02    0.680028    1.000000   \n",
       "1               0.0  4.002599e-05  6.486638e-03    0.730756    0.007162   \n",
       "2               0.0  1.587743e-08  3.891505e-06    0.580702    0.000543   \n",
       "3               1.0  3.437215e-09  1.528109e-08    0.184108    0.000010   \n",
       "4               1.0  1.723015e-06  3.776245e-05    0.094714    0.017997   \n",
       "...             ...           ...           ...         ...         ...   \n",
       "1123244         0.0  1.587743e-08  3.891505e-06    0.580702    0.000543   \n",
       "1123245         0.0  1.587743e-08  3.891505e-06    0.580702    0.000543   \n",
       "1123246         0.0  9.179891e-05  2.248993e-02    0.680028    1.000000   \n",
       "1123247         1.0  8.863601e-04  2.160720e-02    0.905640    0.000995   \n",
       "1123248         0.0  1.587743e-08  3.891505e-06    0.580702    0.000543   \n",
       "\n",
       "         feature_16    feature_17    feature_18  feature_19  \n",
       "0          0.459038  6.565172e-07  8.784210e-09    0.000003  \n",
       "1          0.013356  6.395042e-04  0.000000e+00    0.000405  \n",
       "2          1.000000  8.483211e-01  1.026006e-03    0.000000  \n",
       "3          0.197636  1.000000e+00  1.319294e-05    0.000027  \n",
       "4          0.015916  2.773921e-01  0.000000e+00    0.000272  \n",
       "...             ...           ...           ...         ...  \n",
       "1123244    1.000000  8.483211e-01  1.026006e-03    0.000000  \n",
       "1123245    1.000000  8.483211e-01  1.026006e-03    0.000000  \n",
       "1123246    0.459038  6.565172e-07  8.784210e-09    0.000003  \n",
       "1123247    0.066771  1.111779e-01  2.173034e-02    0.000083  \n",
       "1123248    1.000000  8.483211e-01  1.026006e-03    0.000000  \n",
       "\n",
       "[1123249 rows x 20 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the features and the target\n",
    "# scale_pos_weight = len(processed_data_expanded[processed_data_expanded['encoded_label'] == 1]) / len(processed_data_expanded[processed_data_expanded['encoded_label'] == 0])\n",
    "X_test = test_processed_data_expanded.drop('encoded_tags', axis=1)\n",
    "y_test = test_processed_data_expanded['encoded_tags']\n",
    "\n",
    "X_val = val_processed_data_expanded.drop('encoded_tags', axis=1)\n",
    "y_val = val_processed_data_expanded['encoded_tags']\n",
    "\n",
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afb63ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Tag class with below 10 count, double check to make sure\n",
    "counts = y_val.value_counts()\n",
    "\n",
    "y_val = y_val[y_val.isin(counts[counts > 10].index)] # 10 is cutof as mentioned in Preprocessing step\n",
    "X_val = X_val.loc[y_val.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bb16c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_processed_data_expanded.drop('encoded_tags', axis=1)\n",
    "y_train = train_processed_data_expanded['encoded_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f870cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF TRY TRANSACTION FEATURES ONLY!!! ADDRESSES FEATURES ONLY\n",
    "# list of columns to be dropped\n",
    "# drop_columns = ['feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19']\n",
    "# # dropping columns for training set\n",
    "# X_train = X_train.drop(columns=drop_columns)\n",
    "\n",
    "# # dropping columns for test set\n",
    "# X_test = X_test.drop(columns=drop_columns)\n",
    "\n",
    "# # dropping columns for validation set\n",
    "# X_val = X_val.drop(columns=drop_columns)\n",
    "\n",
    "\n",
    "keep_columns = ['feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19']\n",
    "\n",
    "# dropping columns for training set\n",
    "X_train = X_train[keep_columns]\n",
    "\n",
    "# dropping columns for test set\n",
    "X_test = X_test[keep_columns]\n",
    "\n",
    "# dropping columns for validation set\n",
    "X_val = X_val[keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7eab47c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/3\n",
      "42097/42097 [==============================] - 350s 8ms/step - loss: 0.1037 - accuracy: 0.9746\n",
      "Epoch 2/3\n",
      "42097/42097 [==============================] - 345s 8ms/step - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 3/3\n",
      "42097/42097 [==============================] - 333s 8ms/step - loss: 0.0028 - accuracy: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb689a8c70>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "# Define your model architecture\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# LSTM\n",
    "# Assuming X_train is your training data\n",
    "n_samples = X_train.shape[0]    # Number of instances\n",
    "n_features = X_train.shape[1]   # Number of features\n",
    "\n",
    "# Reshape your data to be (samples, time steps, features)\n",
    "X_train_reshaped = X_train.values.reshape((n_samples, 1, n_features)) \n",
    "# Input layer\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(1, n_features)))\n",
    "\n",
    "# Additional LSTM layer\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "\n",
    "# Flatten the output of the LSTM to fit into Dense layers\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "# # # MLP\n",
    "# model.add(Dense(1024, input_dim=X_train.shape[1], activation='relu'))\n",
    "# model.add(Dropout(0.3)) # 20% dropout, increase from 20 to 30 help result by 1%\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.3)) # 20% dropout\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_reshaped, y_train, epochs=3, batch_size=128) # X_train_reshaped X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88209240",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 8s 882us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:10<00:32, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 8s 903us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:21<00:21, 10.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 9s 961us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:34<00:11, 11.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7785/7785 [==============================] - 9s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:45<00:00, 11.41s/it]\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3486\n",
      "           1       1.00      1.00      1.00      4293\n",
      "           2       1.00      1.00      1.00      2190\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       1.00      1.00      1.00       281\n",
      "           5       1.00      1.00      1.00      1265\n",
      "           6       1.00      1.00      1.00       381\n",
      "           7       1.00      1.00      1.00      4526\n",
      "           8       0.59      1.00      0.75        19\n",
      "           9       1.00      1.00      1.00      3493\n",
      "          10       0.00      0.00      0.00        31\n",
      "          11       1.00      1.00      1.00      2601\n",
      "          12       1.00      1.00      1.00        94\n",
      "          13       1.00      1.00      1.00        26\n",
      "          14       1.00      1.00      1.00      4877\n",
      "          15       1.00      1.00      1.00       743\n",
      "          16       1.00      1.00      1.00       348\n",
      "          17       1.00      1.00      1.00       284\n",
      "          18       1.00      1.00      1.00      5847\n",
      "          19       1.00      1.00      1.00       859\n",
      "          20       1.00      1.00      1.00     12421\n",
      "          21       1.00      1.00      1.00      7143\n",
      "          22       1.00      1.00      1.00       268\n",
      "          23       1.00      1.00      1.00      1845\n",
      "          24       0.00      0.00      0.00         9\n",
      "          25       0.00      0.00      0.00        70\n",
      "          26       0.00      0.00      0.00        78\n",
      "          27       1.00      1.00      1.00       183\n",
      "          28       1.00      1.00      1.00       125\n",
      "          29       1.00      1.00      1.00       278\n",
      "          30       0.80      1.00      0.89         8\n",
      "          31       0.52      1.00      0.68        76\n",
      "          32       0.00      0.00      0.00        13\n",
      "          33       1.00      1.00      1.00     10590\n",
      "          34       0.00      0.00      0.00         5\n",
      "          35       1.00      1.00      1.00        15\n",
      "          36       1.00      1.00      1.00       849\n",
      "          37       1.00      1.00      1.00      1094\n",
      "          38       1.00      1.00      1.00      2601\n",
      "          39       1.00      1.00      1.00        28\n",
      "          40       1.00      1.00      1.00       201\n",
      "          41       1.00      1.00      1.00      3006\n",
      "          42       1.00      1.00      1.00      7326\n",
      "          43       1.00      1.00      1.00        24\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       1.00      1.00      1.00       329\n",
      "          46       0.00      0.00      0.00         3\n",
      "          47       0.53      1.00      0.69       432\n",
      "          48       0.50      1.00      0.67         5\n",
      "          49       0.50      1.00      0.67         5\n",
      "          50       1.00      1.00      1.00       333\n",
      "          51       0.00      0.00      0.00         6\n",
      "          52       1.00      1.00      1.00       119\n",
      "          53       1.00      1.00      1.00       355\n",
      "          54       1.00      1.00      1.00       399\n",
      "          55       1.00      1.00      1.00      6392\n",
      "          56       1.00      1.00      1.00       360\n",
      "          57       1.00      1.00      1.00      9556\n",
      "          58       0.00      0.00      0.00        63\n",
      "          59       1.00      1.00      1.00     10016\n",
      "          60       1.00      1.00      1.00     13416\n",
      "          61       1.00      1.00      1.00         5\n",
      "          62       1.00      1.00      1.00         6\n",
      "          63       1.00      1.00      1.00       135\n",
      "          64       1.00      1.00      1.00       240\n",
      "          65       1.00      1.00      1.00     32139\n",
      "          66       1.00      1.00      1.00       137\n",
      "          67       1.00      1.00      1.00       178\n",
      "          68       1.00      1.00      1.00      1294\n",
      "          69       1.00      1.00      1.00      1394\n",
      "          70       0.54      1.00      0.70        75\n",
      "          71       0.54      1.00      0.70        26\n",
      "          72       1.00      1.00      1.00      1374\n",
      "          73       1.00      1.00      1.00         9\n",
      "          74       1.00      1.00      1.00      1797\n",
      "          75       1.00      1.00      1.00     25209\n",
      "          76       1.00      1.00      1.00        19\n",
      "          77       1.00      1.00      1.00       137\n",
      "          78       1.00      1.00      1.00      1719\n",
      "          79       0.30      1.00      0.46         3\n",
      "          80       1.00      1.00      1.00        35\n",
      "          81       1.00      1.00      1.00       237\n",
      "          82       1.00      1.00      1.00        45\n",
      "          83       1.00      1.00      1.00       131\n",
      "          84       1.00      1.00      1.00       178\n",
      "          85       1.00      1.00      1.00       535\n",
      "          86       0.49      1.00      0.66        30\n",
      "          87       1.00      1.00      1.00     23293\n",
      "          88       1.00      1.00      1.00        13\n",
      "          89       1.00      1.00      1.00        43\n",
      "          90       1.00      1.00      1.00      1348\n",
      "          91       1.00      1.00      1.00        93\n",
      "          92       0.53      1.00      0.70        16\n",
      "          93       0.00      0.00      0.00         9\n",
      "          94       1.00      1.00      1.00      1113\n",
      "          95       1.00      1.00      1.00       495\n",
      "          96       1.00      1.00      1.00        30\n",
      "          97       1.00      1.00      1.00        90\n",
      "          98       1.00      1.00      1.00      1534\n",
      "          99       1.00      1.00      1.00     13899\n",
      "         100       1.00      1.00      1.00       296\n",
      "         101       0.00      0.00      0.00        13\n",
      "         102       1.00      1.00      1.00     10459\n",
      "         103       1.00      1.00      1.00       926\n",
      "         104       0.00      0.00      0.00        10\n",
      "         105       1.00      1.00      1.00       198\n",
      "         106       1.00      1.00      1.00     38278\n",
      "         107       0.00      0.00      0.00         2\n",
      "         108       1.00      1.00      1.00        38\n",
      "         109       1.00      1.00      1.00        20\n",
      "         110       1.00      1.00      1.00       387\n",
      "         111       1.00      1.00      1.00      1240\n",
      "         112       1.00      1.00      1.00       195\n",
      "         113       1.00      1.00      1.00      1072\n",
      "         114       1.00      1.00      1.00       114\n",
      "         115       1.00      1.00      1.00       115\n",
      "         116       1.00      1.00      1.00     10724\n",
      "         117       1.00      1.00      1.00        80\n",
      "         118       1.00      1.00      1.00      6304\n",
      "         119       1.00      1.00      1.00      7617\n",
      "         120       1.00      1.00      1.00       181\n",
      "         121       1.00      1.00      1.00        13\n",
      "         122       1.00      1.00      1.00        32\n",
      "         123       0.58      1.00      0.73        18\n",
      "         124       1.00      1.00      1.00     52604\n",
      "         125       1.00      1.00      1.00       751\n",
      "         126       1.00      1.00      1.00       950\n",
      "         127       0.71      1.00      0.83        10\n",
      "         128       1.00      1.00      1.00        17\n",
      "         129       1.00      1.00      1.00      6771\n",
      "         130       1.00      1.00      1.00      3945\n",
      "         131       1.00      1.00      1.00       138\n",
      "         132       1.00      1.00      1.00       139\n",
      "         133       0.00      0.00      0.00         3\n",
      "         134       1.00      1.00      1.00       206\n",
      "         135       1.00      1.00      1.00        29\n",
      "         136       1.00      1.00      1.00       104\n",
      "         137       1.00      1.00      1.00       188\n",
      "         138       1.00      1.00      1.00      3609\n",
      "         139       1.00      1.00      1.00        36\n",
      "         140       0.00      0.00      0.00       176\n",
      "         141       1.00      1.00      1.00      4625\n",
      "         142       1.00      1.00      1.00     25145\n",
      "         143       1.00      1.00      1.00      6786\n",
      "         144       0.00      0.00      0.00         3\n",
      "         145       1.00      1.00      1.00        39\n",
      "         146       1.00      1.00      1.00       230\n",
      "         147       1.00      1.00      1.00      1466\n",
      "         148       1.00      1.00      1.00       136\n",
      "         149       1.00      1.00      1.00        21\n",
      "         150       0.00      0.00      0.00        22\n",
      "         151       1.00      1.00      1.00        71\n",
      "         152       1.00      1.00      1.00       223\n",
      "         153       1.00      1.00      1.00        38\n",
      "         154       1.00      1.00      1.00     13840\n",
      "         155       1.00      1.00      1.00      6249\n",
      "         156       1.00      1.00      1.00         2\n",
      "         157       1.00      1.00      1.00       295\n",
      "         158       1.00      1.00      1.00      5170\n",
      "         159       0.00      0.00      0.00         4\n",
      "         160       1.00      1.00      1.00      1666\n",
      "         161       1.00      1.00      1.00       547\n",
      "         162       1.00      1.00      1.00       801\n",
      "         163       0.00      0.00      0.00       150\n",
      "         164       0.00      0.00      0.00         6\n",
      "         165       1.00      1.00      1.00       562\n",
      "         166       1.00      1.00      1.00       181\n",
      "         167       1.00      1.00      1.00         6\n",
      "         168       1.00      1.00      1.00         6\n",
      "         169       1.00      1.00      1.00       303\n",
      "         170       1.00      1.00      1.00       128\n",
      "         171       1.00      1.00      1.00       158\n",
      "         172       0.00      0.00      0.00        14\n",
      "         173       1.00      1.00      1.00       156\n",
      "         174       0.00      0.00      0.00       384\n",
      "         175       1.00      1.00      1.00       199\n",
      "         176       0.00      0.00      0.00         7\n",
      "         177       1.00      1.00      1.00       315\n",
      "         178       0.35      1.00      0.52         6\n",
      "         179       1.00      1.00      1.00        66\n",
      "         180       1.00      1.00      1.00      4415\n",
      "         181       1.00      1.00      1.00      2235\n",
      "         182       1.00      1.00      1.00         3\n",
      "         183       1.00      1.00      1.00      5989\n",
      "         184       1.00      1.00      1.00    189368\n",
      "         185       1.00      1.00      1.00       137\n",
      "         186       1.00      1.00      1.00       529\n",
      "         187       0.00      0.00      0.00         3\n",
      "         188       0.45      1.00      0.62         5\n",
      "         189       1.00      1.00      1.00      5814\n",
      "         190       0.00      0.00      0.00         5\n",
      "         191       0.00      0.00      0.00         2\n",
      "         192       0.50      1.00      0.67         5\n",
      "         193       1.00      1.00      1.00       328\n",
      "         194       1.00      1.00      1.00    145887\n",
      "         195       0.28      1.00      0.43        10\n",
      "         196       1.00      1.00      1.00      5013\n",
      "         197       1.00      1.00      1.00       142\n",
      "         198       1.00      1.00      1.00       142\n",
      "         199       1.00      1.00      1.00        25\n",
      "         200       1.00      1.00      1.00       202\n",
      "         201       0.52      1.00      0.68        83\n",
      "         202       0.50      1.00      0.66       173\n",
      "         203       1.00      1.00      1.00    240741\n",
      "         204       0.00      0.00      0.00         2\n",
      "         205       1.00      1.00      1.00       320\n",
      "         206       1.00      1.00      1.00      5040\n",
      "         207       1.00      1.00      1.00        18\n",
      "         208       1.00      1.00      1.00        66\n",
      "         209       1.00      1.00      1.00      8177\n",
      "         210       1.00      1.00      1.00       187\n",
      "         211       1.00      1.00      1.00     65211\n",
      "         212       1.00      1.00      1.00     14220\n",
      "         213       1.00      1.00      1.00      1152\n",
      "         214       1.00      1.00      1.00       302\n",
      "         215       1.00      1.00      1.00         4\n",
      "         216       1.00      1.00      1.00       226\n",
      "         217       1.00      1.00      1.00         8\n",
      "         218       1.00      1.00      1.00        27\n",
      "         219       1.00      1.00      1.00        47\n",
      "         220       1.00      1.00      1.00        43\n",
      "         221       0.33      1.00      0.50         3\n",
      "\n",
      "    accuracy                           1.00   1149102\n",
      "   macro avg       0.82      0.87      0.84   1149102\n",
      "weighted avg       1.00      1.00      1.00   1149102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define a batch size for prediction\n",
    "batch_size = 300000\n",
    "\n",
    "# Initialize an empty list to store the predictions\n",
    "predictions = []\n",
    "\n",
    "n_samples = X_test.shape[0]    # Number of instances\n",
    "n_features = X_test.shape[1]   # Number of features\n",
    "X_test_reshaped = X_test.values.reshape((n_samples, 1, n_features))  \n",
    "\n",
    "# Iterate over the test data in batches\n",
    "for i in tqdm(range(0, X_test.shape[0], batch_size)): # X_test\n",
    "    # Get the current batch of test data\n",
    "    batch_X_test = X_test[i:i+batch_size] # X_test_reshaped\n",
    "\n",
    "    # Predict the probabilities for the current batch and add to the list\n",
    "    batch_pred_prob = model.predict(batch_X_test)\n",
    "    predictions.append(batch_pred_prob)\n",
    "\n",
    "# Concatenate all the predictions together\n",
    "y_pred_prob = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Predict the classes for the test data\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2d7dc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.794558300659263\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Binarize the output\n",
    "lb = LabelBinarizer()\n",
    "y_test_bin = lb.fit_transform(y_test)\n",
    "y_test_pred_bin = lb.transform(y_pred)\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test_bin, y_test_pred_bin, average='macro')\n",
    "print(f\"ROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8503271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('./output/lstm_transaction_features_only_3r.h5')  # mlp_1r mlp_addresses_features_only_3r lstm_addresses_features_only_3r lstm_1r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea7e5b",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7ebdcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model('./output/mlp_addresses_features_only_3r.h5') # mlp_1r mlp_addresses_features_only_3r lstm_addresses_features_only_3r lstm_1r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac576cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 12s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:15<00:45, 15.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 12s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:29<00:29, 14.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 13s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:45<00:15, 15.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6971/6971 [==============================] - 13s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:59<00:00, 14.98s/it]\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3407\n",
      "           1       1.00      1.00      1.00      4197\n",
      "           2       1.00      1.00      1.00      2141\n",
      "           4       1.00      1.00      1.00       275\n",
      "           5       1.00      1.00      1.00      1237\n",
      "           6       1.00      1.00      1.00       372\n",
      "           7       1.00      1.00      1.00      4424\n",
      "           8       1.00      1.00      1.00        18\n",
      "           9       1.00      1.00      1.00      3414\n",
      "          10       0.51      1.00      0.67        30\n",
      "          11       1.00      1.00      1.00      2543\n",
      "          12       1.00      1.00      1.00        92\n",
      "          13       1.00      1.00      1.00        26\n",
      "          14       1.00      1.00      1.00      4768\n",
      "          15       1.00      1.00      1.00       727\n",
      "          16       1.00      1.00      1.00       340\n",
      "          17       1.00      1.00      1.00       278\n",
      "          18       1.00      1.00      1.00      5715\n",
      "          19       1.00      1.00      1.00       840\n",
      "          20       1.00      1.00      1.00     12142\n",
      "          21       1.00      1.00      1.00      6983\n",
      "          22       1.00      1.00      1.00       262\n",
      "          23       1.00      1.00      1.00      1804\n",
      "          25       1.00      1.00      1.00        68\n",
      "          26       0.48      1.00      0.65        76\n",
      "          27       1.00      1.00      1.00       178\n",
      "          28       1.00      1.00      1.00       122\n",
      "          29       1.00      1.00      1.00       272\n",
      "          31       1.00      1.00      1.00        74\n",
      "          32       1.00      1.00      1.00        13\n",
      "          33       1.00      1.00      1.00     10352\n",
      "          35       0.26      1.00      0.41        15\n",
      "          36       1.00      1.00      1.00       830\n",
      "          37       1.00      1.00      1.00      1069\n",
      "          38       1.00      1.00      1.00      2543\n",
      "          39       1.00      1.00      1.00        27\n",
      "          40       1.00      1.00      1.00       197\n",
      "          41       1.00      1.00      1.00      2938\n",
      "          42       1.00      1.00      1.00      7161\n",
      "          43       1.00      1.00      1.00        23\n",
      "          45       1.00      1.00      1.00       322\n",
      "          47       1.00      1.00      1.00       422\n",
      "          48       0.00      0.00      0.00         0\n",
      "          50       1.00      1.00      1.00       326\n",
      "          52       1.00      1.00      1.00       116\n",
      "          53       1.00      1.00      1.00       347\n",
      "          54       1.00      1.00      1.00       390\n",
      "          55       1.00      1.00      1.00      6248\n",
      "          56       1.00      1.00      1.00       351\n",
      "          57       1.00      1.00      1.00      9342\n",
      "          58       1.00      1.00      1.00        62\n",
      "          59       1.00      1.00      1.00      9790\n",
      "          60       1.00      1.00      1.00     13114\n",
      "          63       1.00      1.00      1.00       132\n",
      "          64       1.00      1.00      1.00       234\n",
      "          65       1.00      1.00      1.00     31416\n",
      "          66       1.00      1.00      1.00       134\n",
      "          67       1.00      1.00      1.00       174\n",
      "          68       1.00      1.00      1.00      1265\n",
      "          69       1.00      1.00      1.00      1362\n",
      "          70       1.00      1.00      1.00        74\n",
      "          71       1.00      1.00      1.00        25\n",
      "          72       1.00      1.00      1.00      1343\n",
      "          74       1.00      1.00      1.00      1757\n",
      "          75       1.00      1.00      1.00     24642\n",
      "          76       1.00      1.00      1.00        18\n",
      "          77       1.00      1.00      1.00       134\n",
      "          78       1.00      1.00      1.00      1681\n",
      "          80       1.00      1.00      1.00        35\n",
      "          81       1.00      1.00      1.00       232\n",
      "          82       1.00      1.00      1.00        44\n",
      "          83       1.00      1.00      1.00       128\n",
      "          84       1.00      1.00      1.00       174\n",
      "          85       1.00      1.00      1.00       524\n",
      "          86       0.00      0.00      0.00        29\n",
      "          87       1.00      1.00      1.00     22769\n",
      "          88       0.00      0.00      0.00        13\n",
      "          89       1.00      1.00      1.00        42\n",
      "          90       1.00      1.00      1.00      1318\n",
      "          91       1.00      1.00      1.00        91\n",
      "          92       0.00      0.00      0.00        16\n",
      "          94       1.00      1.00      1.00      1088\n",
      "          95       1.00      1.00      1.00       484\n",
      "          96       1.00      1.00      1.00        29\n",
      "          97       1.00      1.00      1.00        88\n",
      "          98       1.00      1.00      1.00      1499\n",
      "          99       1.00      1.00      1.00     13587\n",
      "         100       1.00      1.00      1.00       289\n",
      "         101       0.00      0.00      0.00        12\n",
      "         102       1.00      1.00      1.00     10224\n",
      "         103       1.00      1.00      1.00       905\n",
      "         105       1.00      1.00      1.00       193\n",
      "         106       1.00      1.00      1.00     37416\n",
      "         108       1.00      1.00      1.00        37\n",
      "         109       1.00      1.00      1.00        19\n",
      "         110       1.00      1.00      1.00       378\n",
      "         111       1.00      1.00      1.00      1212\n",
      "         112       1.00      1.00      1.00       190\n",
      "         113       1.00      1.00      1.00      1048\n",
      "         114       1.00      1.00      1.00       111\n",
      "         115       1.00      1.00      1.00       112\n",
      "         116       1.00      1.00      1.00     10482\n",
      "         117       0.00      0.00      0.00        78\n",
      "         118       1.00      1.00      1.00      6162\n",
      "         119       1.00      1.00      1.00      7446\n",
      "         120       1.00      1.00      1.00       177\n",
      "         121       1.00      1.00      1.00        13\n",
      "         122       1.00      1.00      1.00        32\n",
      "         123       1.00      1.00      1.00        17\n",
      "         124       1.00      1.00      1.00     51420\n",
      "         125       1.00      1.00      1.00       734\n",
      "         126       1.00      1.00      1.00       929\n",
      "         128       1.00      1.00      1.00        16\n",
      "         129       1.00      1.00      1.00      6619\n",
      "         130       1.00      1.00      1.00      3857\n",
      "         131       1.00      1.00      1.00       135\n",
      "         132       1.00      1.00      1.00       136\n",
      "         134       1.00      1.00      1.00       202\n",
      "         135       1.00      1.00      1.00        29\n",
      "         136       1.00      1.00      1.00       102\n",
      "         137       1.00      1.00      1.00       184\n",
      "         138       1.00      1.00      1.00      3528\n",
      "         139       1.00      1.00      1.00        35\n",
      "         140       1.00      1.00      1.00       172\n",
      "         141       1.00      1.00      1.00      4521\n",
      "         142       1.00      1.00      1.00     24579\n",
      "         143       1.00      1.00      1.00      6633\n",
      "         145       1.00      1.00      1.00        38\n",
      "         146       1.00      1.00      1.00       225\n",
      "         147       1.00      1.00      1.00      1433\n",
      "         148       1.00      1.00      1.00       133\n",
      "         149       1.00      1.00      1.00        21\n",
      "         150       1.00      1.00      1.00        21\n",
      "         151       0.47      1.00      0.64        69\n",
      "         152       1.00      1.00      1.00       219\n",
      "         153       1.00      1.00      1.00        37\n",
      "         154       1.00      1.00      1.00     13528\n",
      "         155       1.00      1.00      1.00      6109\n",
      "         157       1.00      1.00      1.00       288\n",
      "         158       1.00      1.00      1.00      5054\n",
      "         160       1.00      1.00      1.00      1629\n",
      "         161       1.00      1.00      1.00       535\n",
      "         162       1.00      1.00      1.00       783\n",
      "         163       1.00      1.00      1.00       147\n",
      "         165       1.00      1.00      1.00       550\n",
      "         166       1.00      1.00      1.00       177\n",
      "         169       1.00      1.00      1.00       296\n",
      "         170       1.00      1.00      1.00       126\n",
      "         171       1.00      1.00      1.00       155\n",
      "         172       0.00      0.00      0.00        14\n",
      "         173       1.00      1.00      1.00       152\n",
      "         174       1.00      1.00      1.00       376\n",
      "         175       1.00      1.00      1.00       194\n",
      "         177       1.00      1.00      1.00       308\n",
      "         179       1.00      1.00      1.00        65\n",
      "         180       1.00      1.00      1.00      4316\n",
      "         181       1.00      1.00      1.00      2185\n",
      "         183       1.00      1.00      1.00      5854\n",
      "         184       1.00      1.00      1.00    185107\n",
      "         185       1.00      1.00      1.00       134\n",
      "         186       1.00      1.00      1.00       518\n",
      "         189       1.00      1.00      1.00      5683\n",
      "         193       1.00      1.00      1.00       321\n",
      "         194       1.00      1.00      1.00    142605\n",
      "         196       1.00      1.00      1.00      4901\n",
      "         197       1.00      1.00      1.00       139\n",
      "         198       1.00      1.00      1.00       139\n",
      "         199       1.00      1.00      1.00        24\n",
      "         200       1.00      1.00      1.00       198\n",
      "         201       0.00      0.00      0.00        81\n",
      "         202       1.00      1.00      1.00       169\n",
      "         203       1.00      1.00      1.00    235324\n",
      "         205       1.00      1.00      1.00       312\n",
      "         206       1.00      1.00      1.00      4926\n",
      "         207       1.00      1.00      1.00        18\n",
      "         208       1.00      1.00      1.00        64\n",
      "         209       1.00      1.00      1.00      7993\n",
      "         210       1.00      1.00      1.00       183\n",
      "         211       1.00      1.00      1.00     63744\n",
      "         212       1.00      1.00      1.00     13900\n",
      "         213       1.00      1.00      1.00      1126\n",
      "         214       1.00      1.00      1.00       296\n",
      "         216       1.00      1.00      1.00       221\n",
      "         218       1.00      1.00      1.00        26\n",
      "         219       1.00      1.00      1.00        46\n",
      "         220       1.00      1.00      1.00        42\n",
      "\n",
      "    accuracy                           1.00   1123065\n",
      "   macro avg       0.94      0.96      0.95   1123065\n",
      "weighted avg       1.00      1.00      1.00   1123065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the predictions\n",
    "predictions = []\n",
    "# Define a batch size for prediction\n",
    "batch_size = 300000\n",
    "\n",
    "n_samples = X_val.shape[0]    # Number of instances\n",
    "n_features = X_val.shape[1]   # Number of features\n",
    "X_val_reshaped = X_val.values.reshape((n_samples, 1, n_features))\n",
    "\n",
    "# Iterate over the test data in batches\n",
    "for i in tqdm(range(0, X_val.shape[0], batch_size)): # X_val\n",
    "    # Get the current batch of test data\n",
    "    batch_X_test = X_val_reshaped[i:i+batch_size] # X_val_reshaped\n",
    "\n",
    "    # Predict the probabilities for the current batch and add to the list\n",
    "    batch_pred_prob = model.predict(batch_X_test)\n",
    "    predictions.append(batch_pred_prob)\n",
    "\n",
    "# # Predict the probabilities for the test data\n",
    "# y_val_pred_prob = model.predict(X_val)\n",
    "\n",
    "# Predict the classes for the test data\n",
    "# Concatenate all the predictions together\n",
    "y_val_pred_prob = np.concatenate(predictions, axis=0)\n",
    "y_val_pred = np.argmax(y_val_pred_prob, axis=1)\n",
    "\n",
    "# Note: since multiclass tags are imbalanced, weighted avg should be used\n",
    "# 1111111   MLP only, trained time 4.5mins for 3r, 90s for 1r\n",
    "# If only use addresses' features, 3r yields 93% weighted precision, 93 recall, 93 f1, 84.8 ROC AUC\n",
    "# If use both addresses and tag features, 1r yields 94 macro avg and 1 for weighted avg, 98 ROC AUC\n",
    "#\n",
    "# Note: LSTM only, train time 15 mins for 3r, 264s for 1r\n",
    "# If only use addresses' features, 3r yields 94% weighted precision, 94 recall, 93 f1, 87.5 ROC AUC (better macro than MLP)\n",
    "# If use both addresses and tag features, 1r yields 89 macro avg and 1 for weighted avg, 94 ROC AUC\n",
    "\n",
    "# =====> If main goal is to detect live transactions, the address features only is good enough to detect popular crimes\n",
    "# =====> If main goal is to do audit or investigation, both type of features are needed\n",
    "# LSTM is good for live transaction in this case, while MLP is good for audit/investigation\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e82126ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.981080525141987\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Binarize the output\n",
    "lb = LabelBinarizer()\n",
    "y_val_bin = lb.fit_transform(y_val)\n",
    "y_val_pred_bin = lb.transform(y_val_pred)\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_val_bin, y_val_pred_bin, average='macro')\n",
    "print(f\"ROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edb6f342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "n_classes = y_val_bin.shape[1]\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_val_bin[:, i], y_val_pred_bin[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot average ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"], color='darkorange', lw=2, label='Average ROC curve (area = %0.2f)' % roc_auc[\"macro\"])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.savefig('./output/lstm_transaction_features_only_3r.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d245961e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
