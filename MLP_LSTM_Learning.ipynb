{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b61c5998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f9335d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "605a487b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>encoded_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509812</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.906781e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509813</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.486586e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.179891e-05</td>\n",
       "      <td>0.022490</td>\n",
       "      <td>0.680028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459038</td>\n",
       "      <td>6.565172e-07</td>\n",
       "      <td>8.784210e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.578240</td>\n",
       "      <td>0.999839</td>\n",
       "      <td>0.016088</td>\n",
       "      <td>6.101171e-03</td>\n",
       "      <td>3.595742e-01</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.016082</td>\n",
       "      <td>0.037998</td>\n",
       "      <td>6.038352e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.081934e-03</td>\n",
       "      <td>0.039148</td>\n",
       "      <td>0.764455</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.019570</td>\n",
       "      <td>2.624302e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.467841</td>\n",
       "      <td>0.996626</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.092086e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.040388e-04</td>\n",
       "      <td>0.028460</td>\n",
       "      <td>0.859879</td>\n",
       "      <td>0.242375</td>\n",
       "      <td>0.361443</td>\n",
       "      <td>3.157241e-02</td>\n",
       "      <td>6.552889e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.322503</td>\n",
       "      <td>0.989857</td>\n",
       "      <td>0.023677</td>\n",
       "      <td>1.015950e-06</td>\n",
       "      <td>7.954423e-01</td>\n",
       "      <td>0.412684</td>\n",
       "      <td>0.127934</td>\n",
       "      <td>0.015942</td>\n",
       "      <td>0.116336</td>\n",
       "      <td>6.150468e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.787286e-04</td>\n",
       "      <td>0.033901</td>\n",
       "      <td>0.751330</td>\n",
       "      <td>0.049434</td>\n",
       "      <td>0.032961</td>\n",
       "      <td>4.568948e-02</td>\n",
       "      <td>1.137700e-03</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388330</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388331</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388332</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388333</th>\n",
       "      <td>0.293524</td>\n",
       "      <td>0.951149</td>\n",
       "      <td>0.006017</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.639506e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006017</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.380474e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.850077e-05</td>\n",
       "      <td>0.009008</td>\n",
       "      <td>0.996098</td>\n",
       "      <td>0.070973</td>\n",
       "      <td>0.048470</td>\n",
       "      <td>1.586959e-01</td>\n",
       "      <td>6.269141e-01</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388334</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5388335 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_0  feature_1  feature_2     feature_3     feature_4  \\\n",
       "0         0.428620   1.000000   0.509812  0.000000e+00  8.906781e-07   \n",
       "1         0.578240   0.999839   0.016088  6.101171e-03  3.595742e-01   \n",
       "2         0.467841   0.996626   0.002890  0.000000e+00  0.000000e+00   \n",
       "3         0.322503   0.989857   0.023677  1.015950e-06  7.954423e-01   \n",
       "4         0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "...            ...        ...        ...           ...           ...   \n",
       "5388330   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "5388331   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "5388332   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "5388333   0.293524   0.951149   0.006017  0.000000e+00  4.639506e-07   \n",
       "5388334   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "\n",
       "         feature_5  feature_6  feature_7  feature_8     feature_9  ...  \\\n",
       "0         0.000000   0.000000   0.509813   0.000001  2.486586e-06  ...   \n",
       "1         0.000223   0.000125   0.016082   0.037998  6.038352e-05  ...   \n",
       "2         0.000000   0.000000   0.002891   0.000000  4.092086e-04  ...   \n",
       "3         0.412684   0.127934   0.015942   0.116336  6.150468e-05  ...   \n",
       "4         0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "...            ...        ...        ...        ...           ...  ...   \n",
       "5388330   0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "5388331   0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "5388332   0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "5388333   0.000000   0.000000   0.006017   0.000001  2.380474e-04  ...   \n",
       "5388334   0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "\n",
       "         feature_11    feature_12  feature_13  feature_14  feature_15  \\\n",
       "0               0.0  9.179891e-05    0.022490    0.680028    1.000000   \n",
       "1               1.0  5.081934e-03    0.039148    0.764455    0.000006   \n",
       "2               0.0  1.040388e-04    0.028460    0.859879    0.242375   \n",
       "3               0.0  2.787286e-04    0.033901    0.751330    0.049434   \n",
       "4               0.0  1.587743e-08    0.000004    0.580702    0.000543   \n",
       "...             ...           ...         ...         ...         ...   \n",
       "5388330         0.0  1.587743e-08    0.000004    0.580702    0.000543   \n",
       "5388331         0.0  1.587743e-08    0.000004    0.580702    0.000543   \n",
       "5388332         0.0  1.587743e-08    0.000004    0.580702    0.000543   \n",
       "5388333         0.0  8.850077e-05    0.009008    0.996098    0.070973   \n",
       "5388334         0.0  1.587743e-08    0.000004    0.580702    0.000543   \n",
       "\n",
       "         feature_16    feature_17    feature_18  feature_19  encoded_tags  \n",
       "0          0.459038  6.565172e-07  8.784210e-09    0.000003           184  \n",
       "1          0.019570  2.624302e-01  0.000000e+00    0.000404           141  \n",
       "2          0.361443  3.157241e-02  6.552889e-06    0.000009           194  \n",
       "3          0.032961  4.568948e-02  1.137700e-03    0.000133            60  \n",
       "4          1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "...             ...           ...           ...         ...           ...  \n",
       "5388330    1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "5388331    1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "5388332    1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "5388333    0.048470  1.586959e-01  6.269141e-01    0.000092           142  \n",
       "5388334    1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "\n",
       "[5388335 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed_data_expanded = pd.read_csv('./output/scaled_train_data.csv')\n",
    "# train_processed_data_expanded = train_processed_data_expanded.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "train_processed_data_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed7f7364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>encoded_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.327324</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.219593</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.189355e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.219594</td>\n",
       "      <td>5.066213e-02</td>\n",
       "      <td>6.685087e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998936</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.153770</td>\n",
       "      <td>5.788697e-01</td>\n",
       "      <td>8.198362e-01</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.327324</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.219593</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.189355e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.219594</td>\n",
       "      <td>5.066213e-02</td>\n",
       "      <td>6.685087e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998936</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.153770</td>\n",
       "      <td>5.788697e-01</td>\n",
       "      <td>8.198362e-01</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.268661</td>\n",
       "      <td>0.999726</td>\n",
       "      <td>0.011852</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.806285e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.011853</td>\n",
       "      <td>1.266585e-07</td>\n",
       "      <td>1.335921e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.040388e-04</td>\n",
       "      <td>0.028460</td>\n",
       "      <td>0.859879</td>\n",
       "      <td>0.242375</td>\n",
       "      <td>0.361443</td>\n",
       "      <td>3.157241e-02</td>\n",
       "      <td>6.552889e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.428620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509812</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.906781e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.509813</td>\n",
       "      <td>1.013268e-06</td>\n",
       "      <td>2.486586e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.179891e-05</td>\n",
       "      <td>0.022490</td>\n",
       "      <td>0.680028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459038</td>\n",
       "      <td>6.565172e-07</td>\n",
       "      <td>8.784210e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.387329</td>\n",
       "      <td>0.612336</td>\n",
       "      <td>0.001213</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.001214</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.416578e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.099598e-05</td>\n",
       "      <td>0.008395</td>\n",
       "      <td>0.300106</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.597327e-07</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149097</th>\n",
       "      <td>0.296351</td>\n",
       "      <td>0.983435</td>\n",
       "      <td>0.160314</td>\n",
       "      <td>4.718805e-03</td>\n",
       "      <td>4.475495e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.160314</td>\n",
       "      <td>1.199722e-03</td>\n",
       "      <td>9.322364e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.734385e-03</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.706279</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.130509</td>\n",
       "      <td>3.088446e-02</td>\n",
       "      <td>4.192803e-07</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149098</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.276211e-02</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149099</th>\n",
       "      <td>0.387087</td>\n",
       "      <td>0.560943</td>\n",
       "      <td>0.115950</td>\n",
       "      <td>3.422385e-09</td>\n",
       "      <td>7.597835e-01</td>\n",
       "      <td>0.928852</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.115950</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.698501e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.448698e-08</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.208585</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.176432</td>\n",
       "      <td>8.838643e-01</td>\n",
       "      <td>1.165525e-05</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149100</th>\n",
       "      <td>0.428620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509812</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.906781e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.509813</td>\n",
       "      <td>1.013268e-06</td>\n",
       "      <td>2.486586e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.179891e-05</td>\n",
       "      <td>0.022490</td>\n",
       "      <td>0.680028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459038</td>\n",
       "      <td>6.565172e-07</td>\n",
       "      <td>8.784210e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149101</th>\n",
       "      <td>0.510120</td>\n",
       "      <td>0.939192</td>\n",
       "      <td>0.067684</td>\n",
       "      <td>3.353653e-11</td>\n",
       "      <td>6.993792e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.007203</td>\n",
       "      <td>1.393255e-02</td>\n",
       "      <td>1.446382e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.179891e-05</td>\n",
       "      <td>0.022490</td>\n",
       "      <td>0.680028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459038</td>\n",
       "      <td>6.565172e-07</td>\n",
       "      <td>8.784210e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1149102 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_0  feature_1  feature_2     feature_3     feature_4  \\\n",
       "0         0.327324   0.999999   0.219593  1.000000e+00  4.189355e-01   \n",
       "1         0.327324   0.999999   0.219593  1.000000e+00  4.189355e-01   \n",
       "2         0.268661   0.999726   0.011852  0.000000e+00  4.806285e-08   \n",
       "3         0.428620   1.000000   0.509812  0.000000e+00  8.906781e-07   \n",
       "4         0.387329   0.612336   0.001213  0.000000e+00  0.000000e+00   \n",
       "...            ...        ...        ...           ...           ...   \n",
       "1149097   0.296351   0.983435   0.160314  4.718805e-03  4.475495e-02   \n",
       "1149098   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "1149099   0.387087   0.560943   0.115950  3.422385e-09  7.597835e-01   \n",
       "1149100   0.428620   1.000000   0.509812  0.000000e+00  8.906781e-07   \n",
       "1149101   0.510120   0.939192   0.067684  3.353653e-11  6.993792e-03   \n",
       "\n",
       "         feature_5  feature_6  feature_7     feature_8     feature_9  ...  \\\n",
       "0         0.000000    0.00000   0.219594  5.066213e-02  6.685087e-06  ...   \n",
       "1         0.000000    0.00000   0.219594  5.066213e-02  6.685087e-06  ...   \n",
       "2         0.000000    0.00000   0.011853  1.266585e-07  1.335921e-04  ...   \n",
       "3         0.000000    0.00000   0.509813  1.013268e-06  2.486586e-06  ...   \n",
       "4         0.000000    0.00000   0.001214  0.000000e+00  4.416578e-04  ...   \n",
       "...            ...        ...        ...           ...           ...  ...   \n",
       "1149097   0.000000    0.00000   0.160314  1.199722e-03  9.322364e-06  ...   \n",
       "1149098   0.000000    0.00000   1.000000  5.276211e-02  7.937312e-07  ...   \n",
       "1149099   0.928852    0.00001   0.115950  1.000000e+00  3.698501e-06  ...   \n",
       "1149100   0.000000    0.00000   0.509813  1.013268e-06  2.486586e-06  ...   \n",
       "1149101   0.000000    1.00000   0.007203  1.393255e-02  1.446382e-05  ...   \n",
       "\n",
       "         feature_11    feature_12  feature_13  feature_14  feature_15  \\\n",
       "0               0.0  1.000000e+00    1.000000    0.998936    0.001565   \n",
       "1               0.0  1.000000e+00    1.000000    0.998936    0.001565   \n",
       "2               0.0  1.040388e-04    0.028460    0.859879    0.242375   \n",
       "3               0.0  9.179891e-05    0.022490    0.680028    1.000000   \n",
       "4               0.0  1.099598e-05    0.008395    0.300106    0.000536   \n",
       "...             ...           ...         ...         ...         ...   \n",
       "1149097         1.0  4.734385e-03    0.001017    0.706279    0.000131   \n",
       "1149098         0.0  1.587743e-08    0.000004    0.580702    0.000543   \n",
       "1149099         1.0  2.448698e-08    0.000063    0.208585    0.000009   \n",
       "1149100         0.0  9.179891e-05    0.022490    0.680028    1.000000   \n",
       "1149101         0.0  9.179891e-05    0.022490    0.680028    1.000000   \n",
       "\n",
       "         feature_16    feature_17    feature_18  feature_19  encoded_tags  \n",
       "0          0.153770  5.788697e-01  8.198362e-01    0.000041           124  \n",
       "1          0.153770  5.788697e-01  8.198362e-01    0.000041           124  \n",
       "2          0.361443  3.157241e-02  6.552889e-06    0.000009           194  \n",
       "3          0.459038  6.565172e-07  8.784210e-09    0.000003           184  \n",
       "4          0.002547  0.000000e+00  4.597327e-07    0.002466           214  \n",
       "...             ...           ...           ...         ...           ...  \n",
       "1149097    0.130509  3.088446e-02  4.192803e-07    0.000040           106  \n",
       "1149098    1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "1149099    0.176432  8.838643e-01  1.165525e-05    0.000031            99  \n",
       "1149100    0.459038  6.565172e-07  8.784210e-09    0.000003           184  \n",
       "1149101    0.459038  6.565172e-07  8.784210e-09    0.000003           184  \n",
       "\n",
       "[1149102 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_processed_data_expanded = pd.read_csv('./output/scaled_test_data.csv')\n",
    "# train_processed_data_expanded = train_processed_data_expanded.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "test_processed_data_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "594c02f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>encoded_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.566236</td>\n",
       "      <td>0.697855</td>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.972780e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.179891e-05</td>\n",
       "      <td>2.248993e-02</td>\n",
       "      <td>0.680028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459038</td>\n",
       "      <td>6.565172e-07</td>\n",
       "      <td>8.784210e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.395012</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.012381</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.524506e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012382</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>1.076902e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.002599e-05</td>\n",
       "      <td>6.486638e-03</td>\n",
       "      <td>0.730756</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>0.013356</td>\n",
       "      <td>6.395042e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>3.891505e-06</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.387087</td>\n",
       "      <td>0.560943</td>\n",
       "      <td>0.115950</td>\n",
       "      <td>3.422385e-09</td>\n",
       "      <td>7.597835e-01</td>\n",
       "      <td>0.928852</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.115950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.698501e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.437215e-09</td>\n",
       "      <td>1.528109e-08</td>\n",
       "      <td>0.184108</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.197636</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.319294e-05</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.481720</td>\n",
       "      <td>0.478761</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>4.569686e-06</td>\n",
       "      <td>1.391312e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>5.133540e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.723015e-06</td>\n",
       "      <td>3.776245e-05</td>\n",
       "      <td>0.094714</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>0.015916</td>\n",
       "      <td>2.773921e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123244</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>3.891505e-06</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123245</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>3.891505e-06</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123246</th>\n",
       "      <td>0.428620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509812</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.906781e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509813</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.486586e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.179891e-05</td>\n",
       "      <td>2.248993e-02</td>\n",
       "      <td>0.680028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459038</td>\n",
       "      <td>6.565172e-07</td>\n",
       "      <td>8.784210e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123247</th>\n",
       "      <td>0.288678</td>\n",
       "      <td>0.987561</td>\n",
       "      <td>0.033791</td>\n",
       "      <td>2.722036e-03</td>\n",
       "      <td>1.401579e-02</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.033779</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>4.493264e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.863601e-04</td>\n",
       "      <td>2.160720e-02</td>\n",
       "      <td>0.905640</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.066771</td>\n",
       "      <td>1.111779e-01</td>\n",
       "      <td>2.173034e-02</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123248</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>3.891505e-06</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1123249 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_0  feature_1  feature_2     feature_3     feature_4  \\\n",
       "0         0.566236   0.697855   0.009106  0.000000e+00  0.000000e+00   \n",
       "1         0.395012   0.999643   0.012381  0.000000e+00  9.524506e-04   \n",
       "2         0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "3         0.387087   0.560943   0.115950  3.422385e-09  7.597835e-01   \n",
       "4         0.481720   0.478761   0.001350  4.569686e-06  1.391312e-02   \n",
       "...            ...        ...        ...           ...           ...   \n",
       "1123244   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "1123245   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "1123246   0.428620   1.000000   0.509812  0.000000e+00  8.906781e-07   \n",
       "1123247   0.288678   0.987561   0.033791  2.722036e-03  1.401579e-02   \n",
       "1123248   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "\n",
       "         feature_5  feature_6  feature_7  feature_8     feature_9  ...  \\\n",
       "0         0.000000   0.000000   0.009106   0.000000  3.972780e-05  ...   \n",
       "1         0.000000   0.000000   0.012382   0.000697  1.076902e-04  ...   \n",
       "2         0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "3         0.928852   0.000010   0.115950   1.000000  3.698501e-06  ...   \n",
       "4         0.000000   0.000000   0.001350   0.003393  5.133540e-05  ...   \n",
       "...            ...        ...        ...        ...           ...  ...   \n",
       "1123244   0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "1123245   0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "1123246   0.000000   0.000000   0.509813   0.000001  2.486586e-06  ...   \n",
       "1123247   0.000009   0.000208   0.033779   0.001292  4.493264e-05  ...   \n",
       "1123248   0.000000   0.000000   1.000000   0.052762  7.937312e-07  ...   \n",
       "\n",
       "         feature_11    feature_12    feature_13  feature_14  feature_15  \\\n",
       "0               0.0  9.179891e-05  2.248993e-02    0.680028    1.000000   \n",
       "1               0.0  4.002599e-05  6.486638e-03    0.730756    0.007162   \n",
       "2               0.0  1.587743e-08  3.891505e-06    0.580702    0.000543   \n",
       "3               1.0  3.437215e-09  1.528109e-08    0.184108    0.000010   \n",
       "4               1.0  1.723015e-06  3.776245e-05    0.094714    0.017997   \n",
       "...             ...           ...           ...         ...         ...   \n",
       "1123244         0.0  1.587743e-08  3.891505e-06    0.580702    0.000543   \n",
       "1123245         0.0  1.587743e-08  3.891505e-06    0.580702    0.000543   \n",
       "1123246         0.0  9.179891e-05  2.248993e-02    0.680028    1.000000   \n",
       "1123247         1.0  8.863601e-04  2.160720e-02    0.905640    0.000995   \n",
       "1123248         0.0  1.587743e-08  3.891505e-06    0.580702    0.000543   \n",
       "\n",
       "         feature_16    feature_17    feature_18  feature_19  encoded_tags  \n",
       "0          0.459038  6.565172e-07  8.784210e-09    0.000003           184  \n",
       "1          0.013356  6.395042e-04  0.000000e+00    0.000405           180  \n",
       "2          1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "3          0.197636  1.000000e+00  1.319294e-05    0.000027           154  \n",
       "4          0.015916  2.773921e-01  0.000000e+00    0.000272            19  \n",
       "...             ...           ...           ...         ...           ...  \n",
       "1123244    1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "1123245    1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "1123246    0.459038  6.565172e-07  8.784210e-09    0.000003           184  \n",
       "1123247    0.066771  1.111779e-01  2.173034e-02    0.000083            75  \n",
       "1123248    1.000000  8.483211e-01  1.026006e-03    0.000000           203  \n",
       "\n",
       "[1123249 rows x 21 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_processed_data = pd.read_csv('./output/non_nan_balanced_data.csv')\n",
    "val_processed_data_expanded = pd.read_csv('./output/scaled_val_data.csv') \n",
    "# processed_data_expanded = processed_data_expanded.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "val_processed_data_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9a26c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>feature_16</th>\n",
       "      <th>feature_17</th>\n",
       "      <th>feature_18</th>\n",
       "      <th>feature_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.566236</td>\n",
       "      <td>0.697855</td>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.972780e-05</td>\n",
       "      <td>0.171641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.179891e-05</td>\n",
       "      <td>2.248993e-02</td>\n",
       "      <td>0.680028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459038</td>\n",
       "      <td>6.565172e-07</td>\n",
       "      <td>8.784210e-09</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.395012</td>\n",
       "      <td>0.999643</td>\n",
       "      <td>0.012381</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.524506e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012382</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>1.076902e-04</td>\n",
       "      <td>0.632633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.002599e-05</td>\n",
       "      <td>6.486638e-03</td>\n",
       "      <td>0.730756</td>\n",
       "      <td>0.007162</td>\n",
       "      <td>0.013356</td>\n",
       "      <td>6.395042e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>0.376586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>3.891505e-06</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.387087</td>\n",
       "      <td>0.560943</td>\n",
       "      <td>0.115950</td>\n",
       "      <td>3.422385e-09</td>\n",
       "      <td>7.597835e-01</td>\n",
       "      <td>0.928852</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.115950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.698501e-06</td>\n",
       "      <td>0.203465</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.437215e-09</td>\n",
       "      <td>1.528109e-08</td>\n",
       "      <td>0.184108</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.197636</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.319294e-05</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.481720</td>\n",
       "      <td>0.478761</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>4.569686e-06</td>\n",
       "      <td>1.391312e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>5.133540e-05</td>\n",
       "      <td>0.032889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.723015e-06</td>\n",
       "      <td>3.776245e-05</td>\n",
       "      <td>0.094714</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>0.015916</td>\n",
       "      <td>2.773921e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123244</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>0.376586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>3.891505e-06</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123245</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>0.376586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>3.891505e-06</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123246</th>\n",
       "      <td>0.428620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509812</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.906781e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509813</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>2.486586e-06</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.179891e-05</td>\n",
       "      <td>2.248993e-02</td>\n",
       "      <td>0.680028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459038</td>\n",
       "      <td>6.565172e-07</td>\n",
       "      <td>8.784210e-09</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123247</th>\n",
       "      <td>0.288678</td>\n",
       "      <td>0.987561</td>\n",
       "      <td>0.033791</td>\n",
       "      <td>2.722036e-03</td>\n",
       "      <td>1.401579e-02</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.033779</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>4.493264e-05</td>\n",
       "      <td>0.720373</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.863601e-04</td>\n",
       "      <td>2.160720e-02</td>\n",
       "      <td>0.905640</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.066771</td>\n",
       "      <td>1.111779e-01</td>\n",
       "      <td>2.173034e-02</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123248</th>\n",
       "      <td>0.668298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.884876e-09</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>7.937312e-07</td>\n",
       "      <td>0.376586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587743e-08</td>\n",
       "      <td>3.891505e-06</td>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.483211e-01</td>\n",
       "      <td>1.026006e-03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1123249 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_0  feature_1  feature_2     feature_3     feature_4  \\\n",
       "0         0.566236   0.697855   0.009106  0.000000e+00  0.000000e+00   \n",
       "1         0.395012   0.999643   0.012381  0.000000e+00  9.524506e-04   \n",
       "2         0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "3         0.387087   0.560943   0.115950  3.422385e-09  7.597835e-01   \n",
       "4         0.481720   0.478761   0.001350  4.569686e-06  1.391312e-02   \n",
       "...            ...        ...        ...           ...           ...   \n",
       "1123244   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "1123245   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "1123246   0.428620   1.000000   0.509812  0.000000e+00  8.906781e-07   \n",
       "1123247   0.288678   0.987561   0.033791  2.722036e-03  1.401579e-02   \n",
       "1123248   0.668298   1.000000   1.000000  6.884876e-09  1.000000e+00   \n",
       "\n",
       "         feature_5  feature_6  feature_7  feature_8     feature_9  feature_10  \\\n",
       "0         0.000000   0.000000   0.009106   0.000000  3.972780e-05    0.171641   \n",
       "1         0.000000   0.000000   0.012382   0.000697  1.076902e-04    0.632633   \n",
       "2         0.000000   0.000000   1.000000   0.052762  7.937312e-07    0.376586   \n",
       "3         0.928852   0.000010   0.115950   1.000000  3.698501e-06    0.203465   \n",
       "4         0.000000   0.000000   0.001350   0.003393  5.133540e-05    0.032889   \n",
       "...            ...        ...        ...        ...           ...         ...   \n",
       "1123244   0.000000   0.000000   1.000000   0.052762  7.937312e-07    0.376586   \n",
       "1123245   0.000000   0.000000   1.000000   0.052762  7.937312e-07    0.376586   \n",
       "1123246   0.000000   0.000000   0.509813   0.000001  2.486586e-06    0.601457   \n",
       "1123247   0.000009   0.000208   0.033779   0.001292  4.493264e-05    0.720373   \n",
       "1123248   0.000000   0.000000   1.000000   0.052762  7.937312e-07    0.376586   \n",
       "\n",
       "         feature_11    feature_12    feature_13  feature_14  feature_15  \\\n",
       "0               0.0  9.179891e-05  2.248993e-02    0.680028    1.000000   \n",
       "1               0.0  4.002599e-05  6.486638e-03    0.730756    0.007162   \n",
       "2               0.0  1.587743e-08  3.891505e-06    0.580702    0.000543   \n",
       "3               1.0  3.437215e-09  1.528109e-08    0.184108    0.000010   \n",
       "4               1.0  1.723015e-06  3.776245e-05    0.094714    0.017997   \n",
       "...             ...           ...           ...         ...         ...   \n",
       "1123244         0.0  1.587743e-08  3.891505e-06    0.580702    0.000543   \n",
       "1123245         0.0  1.587743e-08  3.891505e-06    0.580702    0.000543   \n",
       "1123246         0.0  9.179891e-05  2.248993e-02    0.680028    1.000000   \n",
       "1123247         1.0  8.863601e-04  2.160720e-02    0.905640    0.000995   \n",
       "1123248         0.0  1.587743e-08  3.891505e-06    0.580702    0.000543   \n",
       "\n",
       "         feature_16    feature_17    feature_18  feature_19  \n",
       "0          0.459038  6.565172e-07  8.784210e-09    0.000003  \n",
       "1          0.013356  6.395042e-04  0.000000e+00    0.000405  \n",
       "2          1.000000  8.483211e-01  1.026006e-03    0.000000  \n",
       "3          0.197636  1.000000e+00  1.319294e-05    0.000027  \n",
       "4          0.015916  2.773921e-01  0.000000e+00    0.000272  \n",
       "...             ...           ...           ...         ...  \n",
       "1123244    1.000000  8.483211e-01  1.026006e-03    0.000000  \n",
       "1123245    1.000000  8.483211e-01  1.026006e-03    0.000000  \n",
       "1123246    0.459038  6.565172e-07  8.784210e-09    0.000003  \n",
       "1123247    0.066771  1.111779e-01  2.173034e-02    0.000083  \n",
       "1123248    1.000000  8.483211e-01  1.026006e-03    0.000000  \n",
       "\n",
       "[1123249 rows x 20 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the features and the target\n",
    "# scale_pos_weight = len(processed_data_expanded[processed_data_expanded['encoded_label'] == 1]) / len(processed_data_expanded[processed_data_expanded['encoded_label'] == 0])\n",
    "X_test = test_processed_data_expanded.drop('encoded_tags', axis=1)\n",
    "y_test = test_processed_data_expanded['encoded_tags']\n",
    "\n",
    "X_val = val_processed_data_expanded.drop('encoded_tags', axis=1)\n",
    "y_val = val_processed_data_expanded['encoded_tags']\n",
    "\n",
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afb63ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the Tag class with below 10 count, double check to make sure\n",
    "counts = y_val.value_counts()\n",
    "\n",
    "y_val = y_val[y_val.isin(counts[counts > 10].index)] # 10 is cutof as mentioned in Preprocessing step\n",
    "X_val = X_val.loc[y_val.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bb16c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_processed_data_expanded.drop('encoded_tags', axis=1)\n",
    "y_train = train_processed_data_expanded['encoded_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f870cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF TRY ADDRESSES FEATURES ONLY\n",
    "# list of columns to be dropped\n",
    "drop_columns = ['feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19']\n",
    "\n",
    "# dropping columns for training set\n",
    "X_train = X_train.drop(columns=drop_columns)\n",
    "\n",
    "# dropping columns for test set\n",
    "X_test = X_test.drop(columns=drop_columns)\n",
    "\n",
    "# dropping columns for validation set\n",
    "X_val = X_val.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7eab47c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "42097/42097 [==============================] - 118s 3ms/step - loss: 0.3991 - accuracy: 0.8779\n",
      "Epoch 2/3\n",
      "42097/42097 [==============================] - 116s 3ms/step - loss: 0.2779 - accuracy: 0.9089\n",
      "Epoch 3/3\n",
      "42097/42097 [==============================] - 117s 3ms/step - loss: 0.2570 - accuracy: 0.9159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e02b8713a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "# Define your model architecture\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# # LSTM\n",
    "# # Assuming X_train is your training data\n",
    "# n_samples = X_train.shape[0]    # Number of instances\n",
    "# n_features = X_train.shape[1]   # Number of features\n",
    "\n",
    "# # Reshape your data to be (samples, time steps, features)\n",
    "# X_train_reshaped = X_train.values.reshape((n_samples, 1, n_features)) \n",
    "# # Input layer\n",
    "# model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(1, n_features)))\n",
    "\n",
    "# # Additional LSTM layer\n",
    "# model.add(LSTM(50, activation='relu'))\n",
    "\n",
    "# # Flatten the output of the LSTM to fit into Dense layers\n",
    "# model.add(Flatten())\n",
    "\n",
    "\n",
    "# # MLP\n",
    "model.add(Dense(1024, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.3)) # 20% dropout, increase from 20 to 30 help result by 1%\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3)) # 20% dropout\n",
    "model.add(Dense(256, activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=128) # X_train_reshaped X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "88209240",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 8s 812us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:10<00:30, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 8s 839us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:20<00:20, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 8s 816us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:30<00:10, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7785/7785 [==============================] - 6s 825us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:39<00:00,  9.83s/it]\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      3486\n",
      "           1       1.00      0.98      0.99      4293\n",
      "           2       1.00      0.84      0.91      2190\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       1.00      0.42      0.59       281\n",
      "           5       1.00      0.82      0.90      1265\n",
      "           6       0.69      0.78      0.73       381\n",
      "           7       0.85      0.87      0.86      4526\n",
      "           8       0.00      0.00      0.00        19\n",
      "           9       0.88      0.82      0.85      3493\n",
      "          10       0.00      0.00      0.00        31\n",
      "          11       0.65      0.54      0.59      2601\n",
      "          12       1.00      0.96      0.98        94\n",
      "          13       0.84      1.00      0.91        26\n",
      "          14       0.99      0.77      0.87      4877\n",
      "          15       0.94      1.00      0.97       743\n",
      "          16       1.00      1.00      1.00       348\n",
      "          17       1.00      1.00      1.00       284\n",
      "          18       0.98      1.00      0.99      5847\n",
      "          19       0.99      1.00      1.00       859\n",
      "          20       1.00      1.00      1.00     12421\n",
      "          21       1.00      1.00      1.00      7143\n",
      "          22       0.53      0.97      0.68       268\n",
      "          23       0.96      0.95      0.95      1845\n",
      "          24       0.00      0.00      0.00         9\n",
      "          25       1.00      0.96      0.98        70\n",
      "          26       1.00      1.00      1.00        78\n",
      "          27       0.00      0.00      0.00       183\n",
      "          28       1.00      1.00      1.00       125\n",
      "          29       0.48      0.18      0.27       278\n",
      "          30       0.00      0.00      0.00         8\n",
      "          31       0.51      0.71      0.59        76\n",
      "          32       0.00      0.00      0.00        13\n",
      "          33       0.98      0.91      0.95     10590\n",
      "          34       0.00      0.00      0.00         5\n",
      "          35       1.00      1.00      1.00        15\n",
      "          36       1.00      1.00      1.00       849\n",
      "          37       0.99      1.00      0.99      1094\n",
      "          38       1.00      0.99      1.00      2601\n",
      "          39       0.00      0.00      0.00        28\n",
      "          40       1.00      0.94      0.97       201\n",
      "          41       0.64      1.00      0.78      3006\n",
      "          42       1.00      0.81      0.90      7326\n",
      "          43       0.00      0.00      0.00        24\n",
      "          44       0.00      0.00      0.00         5\n",
      "          45       0.95      0.80      0.87       329\n",
      "          46       0.00      0.00      0.00         3\n",
      "          47       1.00      1.00      1.00       432\n",
      "          48       0.00      0.00      0.00         5\n",
      "          49       0.00      0.00      0.00         5\n",
      "          50       0.00      0.00      0.00       333\n",
      "          51       0.00      0.00      0.00         6\n",
      "          52       0.90      1.00      0.95       119\n",
      "          53       0.81      0.45      0.58       355\n",
      "          54       0.86      0.96      0.90       399\n",
      "          55       0.98      0.93      0.95      6392\n",
      "          56       1.00      0.94      0.97       360\n",
      "          57       0.97      0.93      0.95      9556\n",
      "          58       0.00      0.00      0.00        63\n",
      "          59       0.97      0.88      0.92     10016\n",
      "          60       0.97      0.71      0.82     13416\n",
      "          61       0.00      0.00      0.00         5\n",
      "          62       0.00      0.00      0.00         6\n",
      "          63       1.00      1.00      1.00       135\n",
      "          64       0.77      0.41      0.54       240\n",
      "          65       1.00      1.00      1.00     32139\n",
      "          66       1.00      0.75      0.86       137\n",
      "          67       0.30      0.79      0.44       178\n",
      "          68       0.88      0.87      0.88      1294\n",
      "          69       1.00      0.88      0.94      1394\n",
      "          70       0.44      0.96      0.61        75\n",
      "          71       0.00      0.00      0.00        26\n",
      "          72       0.72      0.89      0.80      1374\n",
      "          73       0.60      1.00      0.75         9\n",
      "          74       1.00      1.00      1.00      1797\n",
      "          75       1.00      0.93      0.96     25209\n",
      "          76       0.95      1.00      0.97        19\n",
      "          77       1.00      0.10      0.19       137\n",
      "          78       1.00      1.00      1.00      1719\n",
      "          79       0.00      0.00      0.00         3\n",
      "          80       0.85      0.97      0.91        35\n",
      "          81       0.48      0.07      0.12       237\n",
      "          82       0.00      0.00      0.00        45\n",
      "          83       0.45      0.88      0.59       131\n",
      "          84       1.00      0.96      0.98       178\n",
      "          85       1.00      0.93      0.97       535\n",
      "          86       0.39      0.50      0.44        30\n",
      "          87       0.99      0.94      0.97     23293\n",
      "          88       0.00      0.00      0.00        13\n",
      "          89       0.98      1.00      0.99        43\n",
      "          90       1.00      1.00      1.00      1348\n",
      "          91       0.00      0.00      0.00        93\n",
      "          92       1.00      1.00      1.00        16\n",
      "          93       0.00      0.00      0.00         9\n",
      "          94       1.00      0.98      0.99      1113\n",
      "          95       0.59      0.46      0.52       495\n",
      "          96       0.00      0.00      0.00        30\n",
      "          97       1.00      0.74      0.85        90\n",
      "          98       1.00      0.86      0.93      1534\n",
      "          99       0.50      1.00      0.67     13899\n",
      "         100       1.00      1.00      1.00       296\n",
      "         101       0.00      0.00      0.00        13\n",
      "         102       0.98      0.98      0.98     10459\n",
      "         103       1.00      1.00      1.00       926\n",
      "         104       0.00      0.00      0.00        10\n",
      "         105       0.61      0.58      0.59       198\n",
      "         106       1.00      1.00      1.00     38278\n",
      "         107       0.00      0.00      0.00         2\n",
      "         108       1.00      1.00      1.00        38\n",
      "         109       0.00      0.00      0.00        20\n",
      "         110       0.81      0.79      0.80       387\n",
      "         111       1.00      0.85      0.92      1240\n",
      "         112       0.00      0.00      0.00       195\n",
      "         113       0.78      0.13      0.22      1072\n",
      "         114       1.00      1.00      1.00       114\n",
      "         115       0.00      0.00      0.00       115\n",
      "         116       1.00      1.00      1.00     10724\n",
      "         117       1.00      1.00      1.00        80\n",
      "         118       0.99      0.99      0.99      6304\n",
      "         119       1.00      0.95      0.97      7617\n",
      "         120       0.68      0.93      0.78       181\n",
      "         121       0.00      0.00      0.00        13\n",
      "         122       0.00      0.00      0.00        32\n",
      "         123       1.00      1.00      1.00        18\n",
      "         124       1.00      1.00      1.00     52604\n",
      "         125       1.00      0.86      0.92       751\n",
      "         126       1.00      0.53      0.70       950\n",
      "         127       0.00      0.00      0.00        10\n",
      "         128       0.00      0.00      0.00        17\n",
      "         129       1.00      1.00      1.00      6771\n",
      "         130       0.97      0.84      0.90      3945\n",
      "         131       0.43      0.84      0.57       138\n",
      "         132       0.61      1.00      0.76       139\n",
      "         133       0.00      0.00      0.00         3\n",
      "         134       0.00      0.00      0.00       206\n",
      "         135       0.91      0.69      0.78        29\n",
      "         136       1.00      0.81      0.89       104\n",
      "         137       1.00      0.85      0.92       188\n",
      "         138       1.00      0.99      0.99      3609\n",
      "         139       0.00      0.00      0.00        36\n",
      "         140       0.43      0.22      0.29       176\n",
      "         141       1.00      1.00      1.00      4625\n",
      "         142       0.96      0.75      0.85     25145\n",
      "         143       0.99      1.00      1.00      6786\n",
      "         144       0.00      0.00      0.00         3\n",
      "         145       1.00      1.00      1.00        39\n",
      "         146       1.00      0.92      0.96       230\n",
      "         147       1.00      0.45      0.62      1466\n",
      "         148       1.00      0.93      0.96       136\n",
      "         149       0.00      0.00      0.00        21\n",
      "         150       0.00      0.00      0.00        22\n",
      "         151       1.00      1.00      1.00        71\n",
      "         152       0.57      0.37      0.45       223\n",
      "         153       0.00      0.00      0.00        38\n",
      "         154       0.00      0.00      0.00     13840\n",
      "         155       1.00      0.91      0.96      6249\n",
      "         156       0.00      0.00      0.00         2\n",
      "         157       1.00      0.76      0.86       295\n",
      "         158       1.00      0.95      0.98      5170\n",
      "         159       0.00      0.00      0.00         4\n",
      "         160       1.00      0.09      0.17      1666\n",
      "         161       1.00      0.91      0.95       547\n",
      "         162       1.00      1.00      1.00       801\n",
      "         163       0.50      0.99      0.66       150\n",
      "         164       0.00      0.00      0.00         6\n",
      "         165       1.00      0.70      0.82       562\n",
      "         166       0.00      0.00      0.00       181\n",
      "         167       0.00      0.00      0.00         6\n",
      "         168       0.00      0.00      0.00         6\n",
      "         169       0.67      1.00      0.80       303\n",
      "         170       0.56      0.23      0.33       128\n",
      "         171       0.00      0.00      0.00       158\n",
      "         172       0.00      0.00      0.00        14\n",
      "         173       1.00      0.76      0.86       156\n",
      "         174       1.00      0.95      0.97       384\n",
      "         175       0.88      0.40      0.55       199\n",
      "         176       0.00      0.00      0.00         7\n",
      "         177       0.93      0.95      0.94       315\n",
      "         178       0.00      0.00      0.00         6\n",
      "         179       0.47      1.00      0.64        66\n",
      "         180       0.97      0.89      0.93      4415\n",
      "         181       0.96      0.67      0.79      2235\n",
      "         182       0.00      0.00      0.00         3\n",
      "         183       1.00      0.90      0.95      5989\n",
      "         184       0.87      0.98      0.92    189368\n",
      "         185       1.00      0.85      0.92       137\n",
      "         186       1.00      0.29      0.46       529\n",
      "         187       0.00      0.00      0.00         3\n",
      "         188       0.00      0.00      0.00         5\n",
      "         189       0.99      0.90      0.94      5814\n",
      "         190       1.00      0.60      0.75         5\n",
      "         191       0.00      0.00      0.00         2\n",
      "         192       0.00      0.00      0.00         5\n",
      "         193       1.00      1.00      1.00       328\n",
      "         194       0.87      0.89      0.88    145887\n",
      "         195       0.00      0.00      0.00        10\n",
      "         196       0.93      0.93      0.93      5013\n",
      "         197       1.00      1.00      1.00       142\n",
      "         198       0.00      0.00      0.00       142\n",
      "         199       1.00      1.00      1.00        25\n",
      "         200       1.00      0.80      0.89       202\n",
      "         201       0.25      0.93      0.40        83\n",
      "         202       1.00      0.17      0.30       173\n",
      "         203       1.00      1.00      1.00    240741\n",
      "         204       0.00      0.00      0.00         2\n",
      "         205       0.48      0.47      0.47       320\n",
      "         206       1.00      1.00      1.00      5040\n",
      "         207       0.50      0.11      0.18        18\n",
      "         208       0.54      0.30      0.39        66\n",
      "         209       1.00      0.94      0.97      8177\n",
      "         210       1.00      0.65      0.79       187\n",
      "         211       0.91      0.97      0.94     65211\n",
      "         212       1.00      0.85      0.92     14220\n",
      "         213       0.93      0.91      0.92      1152\n",
      "         214       1.00      0.95      0.97       302\n",
      "         215       1.00      0.50      0.67         4\n",
      "         216       1.00      1.00      1.00       226\n",
      "         217       0.00      0.00      0.00         8\n",
      "         218       0.31      1.00      0.47        27\n",
      "         219       0.29      0.89      0.44        47\n",
      "         220       0.00      0.00      0.00        43\n",
      "         221       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.93   1149102\n",
      "   macro avg       0.62      0.59      0.59   1149102\n",
      "weighted avg       0.93      0.93      0.93   1149102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Define a batch size for prediction\n",
    "batch_size = 300000\n",
    "\n",
    "# Initialize an empty list to store the predictions\n",
    "predictions = []\n",
    "\n",
    "n_samples = X_test.shape[0]    # Number of instances\n",
    "n_features = X_test.shape[1]   # Number of features\n",
    "X_test_reshaped = X_test.values.reshape((n_samples, 1, n_features))  \n",
    "\n",
    "# Iterate over the test data in batches\n",
    "for i in tqdm(range(0, X_test.shape[0], batch_size)): # X_test\n",
    "    # Get the current batch of test data\n",
    "    batch_X_test = X_test[i:i+batch_size] # X_test_reshaped\n",
    "\n",
    "    # Predict the probabilities for the current batch and add to the list\n",
    "    batch_pred_prob = model.predict(batch_X_test)\n",
    "    predictions.append(batch_pred_prob)\n",
    "\n",
    "# Concatenate all the predictions together\n",
    "y_pred_prob = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Predict the classes for the test data\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c2d7dc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.794558300659263\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Binarize the output\n",
    "lb = LabelBinarizer()\n",
    "y_test_bin = lb.fit_transform(y_test)\n",
    "y_test_pred_bin = lb.transform(y_pred)\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test_bin, y_test_pred_bin, average='macro')\n",
    "print(f\"ROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8503271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('./output/mlp_addresses_features_only_3r.h5')  # mlp_1r mlp_addresses_features_only_3r lstm_addresses_features_only_3r lstm_1r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea7e5b",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7ebdcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "model = load_model('./output/mlp_addresses_features_only_3r.h5') # mlp_1r mlp_addresses_features_only_3r lstm_addresses_features_only_3r lstm_1r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac576cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 9s 938us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:11<00:34, 11.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 9s 944us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:23<00:23, 11.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 9s 948us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:34<00:11, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6971/6971 [==============================] - 7s 957us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:43<00:00, 10.82s/it]\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      3407\n",
      "           1       1.00      0.98      0.99      4197\n",
      "           2       0.86      0.81      0.84      2141\n",
      "           4       0.69      0.89      0.78       275\n",
      "           5       1.00      0.84      0.91      1237\n",
      "           6       0.55      0.40      0.46       372\n",
      "           7       0.98      0.79      0.87      4424\n",
      "           8       0.00      0.00      0.00        18\n",
      "           9       0.87      0.87      0.87      3414\n",
      "          10       0.00      0.00      0.00        30\n",
      "          11       0.65      0.55      0.59      2543\n",
      "          12       0.00      0.00      0.00        92\n",
      "          13       1.00      1.00      1.00        26\n",
      "          14       0.99      0.77      0.87      4768\n",
      "          15       0.80      1.00      0.89       727\n",
      "          16       1.00      1.00      1.00       340\n",
      "          17       1.00      1.00      1.00       278\n",
      "          18       0.98      1.00      0.99      5715\n",
      "          19       1.00      1.00      1.00       840\n",
      "          20       1.00      1.00      1.00     12142\n",
      "          21       1.00      0.99      1.00      6983\n",
      "          22       0.48      0.96      0.64       262\n",
      "          23       0.99      0.94      0.96      1804\n",
      "          25       1.00      0.93      0.96        68\n",
      "          26       0.50      1.00      0.66        76\n",
      "          27       0.00      0.00      0.00       178\n",
      "          28       0.73      1.00      0.84       122\n",
      "          29       0.00      0.00      0.00       272\n",
      "          31       0.00      0.00      0.00        74\n",
      "          32       0.00      0.00      0.00        13\n",
      "          33       1.00      0.90      0.95     10352\n",
      "          35       1.00      1.00      1.00        15\n",
      "          36       1.00      1.00      1.00       830\n",
      "          37       0.99      1.00      1.00      1069\n",
      "          38       1.00      0.99      1.00      2543\n",
      "          39       0.00      0.00      0.00        27\n",
      "          40       0.64      0.94      0.76       197\n",
      "          41       0.64      1.00      0.78      2938\n",
      "          42       0.99      0.79      0.88      7161\n",
      "          43       0.00      0.00      0.00        23\n",
      "          45       1.00      0.63      0.77       322\n",
      "          47       1.00      1.00      1.00       422\n",
      "          50       1.00      0.99      1.00       326\n",
      "          52       0.91      1.00      0.95       116\n",
      "          53       0.56      0.48      0.52       347\n",
      "          54       1.00      0.94      0.97       390\n",
      "          55       1.00      0.91      0.95      6248\n",
      "          56       0.51      0.94      0.66       351\n",
      "          57       0.90      0.97      0.93      9342\n",
      "          58       0.00      0.00      0.00        62\n",
      "          59       1.00      0.88      0.94      9790\n",
      "          60       0.94      0.73      0.82     13114\n",
      "          63       0.36      1.00      0.53       132\n",
      "          64       0.25      0.13      0.17       234\n",
      "          65       1.00      1.00      1.00     31416\n",
      "          66       1.00      0.72      0.84       134\n",
      "          67       0.00      0.00      0.00       174\n",
      "          68       0.82      0.82      0.82      1265\n",
      "          69       1.00      0.88      0.94      1362\n",
      "          70       0.55      0.92      0.69        74\n",
      "          71       0.00      0.00      0.00        25\n",
      "          72       0.92      0.71      0.80      1343\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.99      1.00      0.99      1757\n",
      "          75       1.00      0.93      0.96     24642\n",
      "          76       0.90      1.00      0.95        18\n",
      "          77       0.00      0.00      0.00       134\n",
      "          78       1.00      1.00      1.00      1681\n",
      "          80       0.78      1.00      0.88        35\n",
      "          81       0.57      0.12      0.20       232\n",
      "          82       0.00      0.00      0.00        44\n",
      "          83       0.00      0.00      0.00       128\n",
      "          84       0.52      0.95      0.67       174\n",
      "          85       1.00      0.94      0.97       524\n",
      "          86       0.39      0.52      0.45        29\n",
      "          87       0.96      0.96      0.96     22769\n",
      "          88       0.00      0.00      0.00        13\n",
      "          89       1.00      1.00      1.00        42\n",
      "          90       1.00      1.00      1.00      1318\n",
      "          91       0.16      0.05      0.08        91\n",
      "          92       0.00      0.00      0.00        16\n",
      "          94       1.00      0.98      0.99      1088\n",
      "          95       0.91      0.29      0.43       484\n",
      "          96       0.00      0.00      0.00        29\n",
      "          97       0.65      0.82      0.73        88\n",
      "          98       0.93      0.89      0.91      1499\n",
      "          99       0.69      0.00      0.01     13587\n",
      "         100       0.77      1.00      0.87       289\n",
      "         101       0.00      0.00      0.00        12\n",
      "         102       0.99      0.98      0.99     10224\n",
      "         103       1.00      1.00      1.00       905\n",
      "         105       0.95      0.44      0.60       193\n",
      "         106       1.00      1.00      1.00     37416\n",
      "         108       0.55      0.97      0.70        37\n",
      "         109       1.00      1.00      1.00        19\n",
      "         110       0.48      0.81      0.60       378\n",
      "         111       1.00      0.84      0.92      1212\n",
      "         112       0.00      0.00      0.00       190\n",
      "         113       0.80      0.20      0.32      1048\n",
      "         114       1.00      1.00      1.00       111\n",
      "         115       0.00      0.00      0.00       112\n",
      "         116       1.00      1.00      1.00     10482\n",
      "         117       1.00      0.41      0.58        78\n",
      "         118       0.99      0.99      0.99      6162\n",
      "         119       1.00      0.94      0.97      7446\n",
      "         120       0.69      0.93      0.79       177\n",
      "         121       0.00      0.00      0.00        13\n",
      "         122       0.00      0.00      0.00        32\n",
      "         123       1.00      1.00      1.00        17\n",
      "         124       1.00      1.00      1.00     51420\n",
      "         125       0.65      0.88      0.75       734\n",
      "         126       1.00      0.52      0.69       929\n",
      "         128       0.00      0.00      0.00        16\n",
      "         129       1.00      1.00      1.00      6619\n",
      "         130       0.99      0.82      0.90      3857\n",
      "         131       0.61      0.86      0.71       135\n",
      "         132       1.00      1.00      1.00       136\n",
      "         134       0.00      0.00      0.00       202\n",
      "         135       0.74      0.79      0.77        29\n",
      "         136       0.94      0.76      0.84       102\n",
      "         137       1.00      0.86      0.93       184\n",
      "         138       1.00      0.95      0.98      3528\n",
      "         139       0.00      0.00      0.00        35\n",
      "         140       0.53      0.69      0.60       172\n",
      "         141       1.00      1.00      1.00      4521\n",
      "         142       0.93      0.71      0.81     24579\n",
      "         143       1.00      1.00      1.00      6633\n",
      "         145       0.29      1.00      0.46        38\n",
      "         146       1.00      0.88      0.94       225\n",
      "         147       1.00      0.71      0.83      1433\n",
      "         148       1.00      0.86      0.92       133\n",
      "         149       0.00      0.00      0.00        21\n",
      "         150       0.26      1.00      0.41        21\n",
      "         151       1.00      1.00      1.00        69\n",
      "         152       0.51      0.42      0.46       219\n",
      "         153       0.18      0.11      0.14        37\n",
      "         154       0.50      1.00      0.67     13528\n",
      "         155       1.00      0.92      0.96      6109\n",
      "         157       1.00      0.99      1.00       288\n",
      "         158       1.00      0.95      0.97      5054\n",
      "         160       1.00      0.41      0.59      1629\n",
      "         161       1.00      0.93      0.96       535\n",
      "         162       1.00      1.00      1.00       783\n",
      "         163       0.34      0.99      0.50       147\n",
      "         165       0.93      0.73      0.82       550\n",
      "         166       0.00      0.00      0.00       177\n",
      "         169       0.68      0.99      0.81       296\n",
      "         170       0.30      0.33      0.31       126\n",
      "         171       0.64      0.72      0.68       155\n",
      "         172       0.00      0.00      0.00        14\n",
      "         173       1.00      0.68      0.81       152\n",
      "         174       1.00      0.95      0.97       376\n",
      "         175       0.87      0.40      0.54       194\n",
      "         177       0.97      0.90      0.93       308\n",
      "         179       1.00      1.00      1.00        65\n",
      "         180       1.00      0.88      0.94      4316\n",
      "         181       0.85      0.63      0.72      2185\n",
      "         183       1.00      0.91      0.95      5854\n",
      "         184       0.87      0.98      0.92    185107\n",
      "         185       0.56      0.87      0.68       134\n",
      "         186       0.87      0.82      0.85       518\n",
      "         189       1.00      0.92      0.96      5683\n",
      "         190       0.00      0.00      0.00         0\n",
      "         193       1.00      1.00      1.00       321\n",
      "         194       0.87      0.88      0.87    142605\n",
      "         196       0.93      0.96      0.94      4901\n",
      "         197       0.33      1.00      0.49       139\n",
      "         198       1.00      0.42      0.59       139\n",
      "         199       1.00      1.00      1.00        24\n",
      "         200       1.00      0.84      0.92       198\n",
      "         201       0.00      0.00      0.00        81\n",
      "         202       1.00      1.00      1.00       169\n",
      "         203       1.00      1.00      1.00    235324\n",
      "         205       0.50      0.54      0.52       312\n",
      "         206       1.00      1.00      1.00      4926\n",
      "         207       0.40      0.33      0.36        18\n",
      "         208       0.00      0.00      0.00        64\n",
      "         209       1.00      0.93      0.97      7993\n",
      "         210       0.00      0.00      0.00       183\n",
      "         211       0.94      0.96      0.95     63744\n",
      "         212       1.00      0.81      0.90     13900\n",
      "         213       0.88      0.79      0.83      1126\n",
      "         214       1.00      0.95      0.98       296\n",
      "         216       1.00      1.00      1.00       221\n",
      "         218       0.90      1.00      0.95        26\n",
      "         219       0.24      0.85      0.37        46\n",
      "         220       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.93   1123065\n",
      "   macro avg       0.69      0.68      0.67   1123065\n",
      "weighted avg       0.93      0.93      0.93   1123065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the predictions\n",
    "predictions = []\n",
    "# Define a batch size for prediction\n",
    "batch_size = 300000\n",
    "\n",
    "n_samples = X_val.shape[0]    # Number of instances\n",
    "n_features = X_val.shape[1]   # Number of features\n",
    "X_val_reshaped = X_val.values.reshape((n_samples, 1, n_features))\n",
    "\n",
    "# Iterate over the test data in batches\n",
    "for i in tqdm(range(0, X_val.shape[0], batch_size)): # X_val\n",
    "    # Get the current batch of test data\n",
    "    batch_X_test = X_val[i:i+batch_size] # X_val_reshaped\n",
    "\n",
    "    # Predict the probabilities for the current batch and add to the list\n",
    "    batch_pred_prob = model.predict(batch_X_test)\n",
    "    predictions.append(batch_pred_prob)\n",
    "\n",
    "# # Predict the probabilities for the test data\n",
    "# y_val_pred_prob = model.predict(X_val)\n",
    "\n",
    "# Predict the classes for the test data\n",
    "# Concatenate all the predictions together\n",
    "y_val_pred_prob = np.concatenate(predictions, axis=0)\n",
    "y_val_pred = np.argmax(y_val_pred_prob, axis=1)\n",
    "\n",
    "# Note: since multiclass tags are imbalanced, weighted avg should be used\n",
    "# 1111111   MLP only, trained time 4.5mins for 3r, 90s for 1r\n",
    "# If only use addresses' features, 3r yields 93% weighted precision, 93 recall, 93 f1, 84.8 ROC AUC\n",
    "# If use both addresses and tag features, 1r yields 94 macro avg and 1 for weighted avg, 98 ROC AUC\n",
    "#\n",
    "# Note: LSTM only, train time 15 mins for 3r, 264s for 1r\n",
    "# If only use addresses' features, 3r yields 94% weighted precision, 94 recall, 93 f1, 87.5 ROC AUC (better macro than MLP)\n",
    "# If use both addresses and tag features, 1r yields 89 macro avg and 1 for weighted avg, 94 ROC AUC\n",
    "\n",
    "# =====> If main goal is to detect live transactions, the address features only is good enough to detect popular crimes\n",
    "# =====> If main goal is to do audit or investigation, both type of features are needed\n",
    "# LSTM is good for live transaction in this case, while MLP is good for audit/investigation\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e82126ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.845493485233725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Binarize the output\n",
    "lb = LabelBinarizer()\n",
    "y_val_bin = lb.fit_transform(y_val)\n",
    "y_val_pred_bin = lb.transform(y_val_pred)\n",
    "\n",
    "# Calculate the ROC AUC score\n",
    "roc_auc = roc_auc_score(y_val_bin, y_val_pred_bin, average='macro')\n",
    "print(f\"ROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edb6f342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAHFCAYAAAAe+pb9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAACEDUlEQVR4nO3dd3xN9/8H8NdNcnOzExkyjCASYm9CUWrGqFVUbEqqilBKKVXF94fWaGs0NglaRFGjaVF7hJiJWiFGIpKQRHbu/fz+uM3hypBEkpvkvp6PRx7t/ZzzOfd974l73/lMmRBCgIiIiEgH6Wk7ACIiIiJtYSJEREREOouJEBEREeksJkJERESks5gIERERkc5iIkREREQ6i4kQERER6SwmQkRERKSzmAgRERGRzmIiRCXexo0bIZPJpB8DAwM4Ojpi4MCBuH37trbDAwBUqVIFw4cP13YYWSQmJuJ///sfGjZsCDMzM5iamqJBgwZYsGABEhMTtR1eni1YsAB79uzJUn7s2DHIZDIcO3as2GPKdO/ePYwfPx5ubm4wNjaGiYkJateujVmzZuHx48fSee+//z7q1KmjtTjfhb+/P5YtW1Zk1y/Iv5/Tp0/jm2++wYsXL7Ice//99/H+++8XSmxU9sm4xQaVdBs3bsSIESOwYcMG1KxZEykpKTh16hTmz58Pc3Nz3Lx5E+XKldNqjMHBwbCwsICLi4tW43jd06dP0aFDB9y9excTJkzABx98AAA4cuQIli9fDhcXF/z111+wt7fXcqRvZ2Zmhn79+mHjxo0a5fHx8QgJCUGtWrVgYWFR7HHt378fAwcOhK2tLcaPH4+GDRtCJpPh2rVrWL9+PfT09BAcHAxA/eUcHR2N69evF3uc76p79+64fv067t+/XyTXL8i/nyVLlmDq1KkICwtDlSpVNI6FhIQAAGrVqlWYYVIZZaDtAIjyqk6dOmjSpAkA9ZeKUqnEnDlzsGfPHowYMUKrsTVs2LDYn1OpVCIjIwMKhSLb40OHDsXNmzdx9OhRvPfee1J5x44d0a1bN7Rr1w7Dhg3DoUOHiitkAG+POz8sLCzQokWLQogq/8LCwjBw4EC4ubnh6NGjsLS0lI61b98eEyZMQEBAQLHGJIRASkoKjI2Ni/V5Cyo5ORnGxsaF/u+HCRDlB7vGqNTKTIqePn2qUR4UFISePXvC2toaRkZGaNiwIX799dcs9R8/fowxY8agUqVKMDQ0hJOTE/r166dxvfj4eHzxxReoWrUqDA0NUaFCBUyaNClLt9LrTfvPnj2DoaEhvv766yzPefPmTchkMqxYsUIqi4yMxNixY1GxYkUYGhqiatWqmDt3LjIyMqRz7t+/D5lMhkWLFuG7775D1apVoVAocPTo0Wzfm6CgIPz5558YNWqURhKU6b333sPIkSNx+PBhXLx4USqXyWQYP3481qxZAzc3NygUCtSqVQvbt2/Pco13jTslJQVTpkxBgwYNYGlpCWtra3h4eOD333/XeB6ZTIbExERs2rRJ6h7N7PbIrmts+PDhMDMzw507d+Dp6QkzMzNUqlQJU6ZMQWpqqsa1Hz16hH79+sHc3BxWVlbw8vLChQsXIJPJsrQ+vemHH35AYmIiVq5cqZEEvR53nz59spRfuHABrVu3homJCapVq4b//e9/UKlU0vG8vi+ZzzF+/HisXr0a7u7uUCgU2LRpEwBg7ty5aN68OaytrWFhYYFGjRph3bp1yK4TwN/fHx4eHjAzM4OZmRkaNGiAdevWAVD/0fHHH3/gwYMHGl3UmdLS0vDdd9+hZs2aUCgUsLOzw4gRI/Ds2TON56hSpQq6d++O3bt3o2HDhjAyMsLcuXOlY693jalUKnz33XeoUaMGjI2NYWVlhXr16mH58uUAgG+++QZTp04FAFStWlWKKfP3ILuusdTUVHz77bdwd3eHkZERbGxs0K5dO5w+fTrL+0G6hS1CVGqFhYUBANzc3KSyo0ePokuXLmjevDlWr14NS0tLbN++HQMGDEBSUpL0Yfv48WM0bdoU6enp+Oqrr1CvXj3ExMTg8OHDeP78Oezt7ZGUlIS2bdvi0aNH0jk3btzA7Nmzce3aNfz1118aXwiZ7Ozs0L17d2zatAlz586Fnt6rvzc2bNgAQ0NDeHl5AVAnE82aNYOenh5mz54NFxcXnDlzBt999x3u37+PDRs2aFx7xYoVcHNzw5IlS2BhYQFXV9ds35vAwEAAQK9evXJ8/3r16oVffvkFgYGBaNy4sVS+d+9eHD16FN9++y1MTU2xcuVKfPzxxzAwMEC/fv0KLe7U1FTExsbiiy++QIUKFZCWloa//voLffr0wYYNGzB06FAAwJkzZ9C+fXu0a9dOSi7f1g2Wnp6Onj17YtSoUZgyZQqOHz+OefPmwdLSErNnzwagHj/Vrl07xMbG4v/+7/9QvXp1HDp0CAMGDMj12pn+/PNP2Nvb56tFKjIyEl5eXpgyZQrmzJmDgIAAzJgxA05OTtLrzev7kmnPnj04ceIEZs+eDQcHB5QvXx6AOgkdO3YsKleuDAA4e/YsPv/8czx+/Fh6DwBg9uzZmDdvHvr06YMpU6bA0tIS169fx4MHDwAAK1euxJgxY3D37t0sLVwqlQoffvghTpw4gWnTpqFly5Z48OAB5syZg/fffx9BQUEarVOXLl1CaGgoZs2ahapVq8LU1DTb92nRokX45ptvMGvWLLRp0wbp6em4efOmNB5o9OjRiI2NxY8//ojdu3fD0dERQM4tQRkZGejatStOnDiBSZMmoX379sjIyMDZs2cRHh6Oli1b5un+URkliEq4DRs2CADi7NmzIj09XSQkJIhDhw4JBwcH0aZNG5Geni6dW7NmTdGwYUONMiGE6N69u3B0dBRKpVIIIcTIkSOFXC4XISEhOT7vwoULhZ6enrhw4YJG+c6dOwUAceDAAanM2dlZDBs2THq8d+9eAUD8+eefUllGRoZwcnISffv2lcrGjh0rzMzMxIMHDzSeY8mSJQKAuHHjhhBCiLCwMAFAuLi4iLS0tLe9ZcLb21sAEDdv3szxnNDQUAFAfPrpp1IZAGFsbCwiIyM14q5Zs6aoXr16kcadkZEh0tPTxahRo0TDhg01jpmammq8v5mOHj0qAIijR49KZcOGDRMAxK+//qpxrqenp6hRo4b0+OeffxYAxMGDBzXOGzt2rAAgNmzYkGu8RkZGokWLFrme87q2bdsKAOLcuXMa5bVq1RKdO3fOsV5u7wsAYWlpKWJjY3N9bqVSKdLT08W3334rbGxshEqlEkIIce/ePaGvry+8vLxyrd+tWzfh7OycpXzbtm0CgNi1a5dG+YULFwQAsXLlSqnM2dlZ6Ovri3///TfLdd7899O9e3fRoEGDXGNavHixACDCwsKyHGvbtq1o27at9Hjz5s0CgPD19c31mqSb2DVGpUaLFi0gl8thbm6OLl26oFy5cvj9999hYKBu2Lxz5w5u3rwptbZkZGRIP56enoiIiMC///4LADh48CDatWsHd3f3HJ9v//79qFOnDho0aKBxrc6dO791plLXrl3h4OCg0TJy+PBhPHnyBCNHjtR4jnbt2sHJyUnjObp27QoA+OeffzSu27NnT8jl8vy9cTkQ/3WRvNmq9cEHH2gMoNbX18eAAQNw584dPHr0qFDj/u2339CqVSuYmZnBwMAAcrkc69atQ2ho6Du9NplMhh49emiU1atXT2rlyIwx83fpdR9//PE7PXduHBwc0KxZs1zjAvL3vrRv3z7byQJHjhxBhw4dYGlpCX19fcjlcsyePRsxMTGIiooCoG45VCqV+Oyzzwr0evbv3w8rKyv06NFD4/egQYMGcHBwyPJvpF69ehotuDlp1qwZrly5gnHjxuHw4cOIj48vUHyZDh48CCMjI41/e0SZmAhRqbF582ZcuHABR44cwdixYxEaGqrxpZU5tueLL76AXC7X+Bk3bhwAIDo6GoB6HE/FihVzfb6nT5/i6tWrWa5lbm4OIYR0rewYGBhgyJAhCAgIkJrzN27cCEdHR3Tu3FnjOfbt25flOWrXrq0Rb6bMLoC3yewOyew+zE7mDKBKlSpplDs4OGQ5N7MsJiam0OLevXs3+vfvjwoVKmDr1q04c+YMLly4gJEjRyIlJSVPrzMnJiYmMDIy0ihTKBQa142Jicl2xlxeZ9FVrlw51/c3OzY2NlnKFAoFkpOTpcf5fV+ye2/Pnz+PTp06AQB8fX1x6tQpXLhwATNnzgQA6fkyx/G87d9CTp4+fYoXL17A0NAwy+9CZGRkgX9/Z8yYgSVLluDs2bPo2rUrbGxs8MEHHyAoKKhAcT579gxOTk4a3dREmThGiEoNd3d3aYB0u3btoFQqsXbtWuzcuRP9+vWDra0tAPWHaHaDVAGgRo0aANTjeDJbN3Jia2sLY2NjrF+/PsfjuRkxYgQWL14sjVHau3cvJk2aBH19fY1r1KtXD/Pnz8/2Gk5OThqPsxuTlJ2OHTviq6++wp49e7K0eGTKXJenY8eOGuWRkZFZzs0sy/wiL4y4t27diqpVq2LHjh0ax98c0FxUbGxscP78+Szl2b3+7HTu3Bk//vgjzp49W6gz1/L7vmT33m7fvh1yuRz79+/XSAjfXIvJzs4OgHrQ+JsJcV7Y2trCxsYmx5mH5ubmb401OwYGBpg8eTImT56MFy9e4K+//sJXX32Fzp074+HDhzAxMclXnHZ2djh58iRUKhWTIcqCiRCVWosWLcKuXbswe/Zs9OnTBzVq1ICrqyuuXLmCBQsW5Fq3a9eu2LJlC/79918pOXpT9+7dsWDBAtjY2KBq1ar5js/d3R3NmzfHhg0boFQqkZqammWaf/fu3XHgwAG4uLgU6lpITZo0QadOnbBu3ToMGTIErVq10jh+8uRJrF+/Hl26dNEYKA0Af//9N54+fSq1jCiVSuzYsQMuLi5Sy0FhxC2TyWBoaKjx5RgZGZnt7Kg3W00KQ9u2bfHrr7/i4MGDUpcegGxnyGXHx8cH69evx7hx47JMnwfUXY979uxB79698xVXft6X3K5hYGCgkXQnJydjy5YtGud16tQJ+vr6WLVqFTw8PHK8Xk7vf/fu3bF9+3YolUo0b948z/Hlh5WVFfr164fHjx9j0qRJuH//PmrVqiUtv5CX34uuXbti27Zt2LhxI7vHKAsmQlRqlStXDjNmzMC0adPg7++PwYMHY82aNejatSs6d+6M4cOHo0KFCoiNjUVoaCguXbqE3377DQDw7bff4uDBg2jTpg2++uor1K1bFy9evMChQ4cwefJk1KxZE5MmTcKuXbvQpk0b+Pj4oF69elCpVAgPD8eff/6JKVOmvPXDf+TIkRg7diyePHmCli1bZkm6vv32WwQGBqJly5aYMGECatSogZSUFNy/fx8HDhzA6tWrC9xtsXnzZnTo0AGdOnXKdkHFmjVrZjtF3NbWFu3bt8fXX38tzRq7efOmRoJQGHFnTqUeN24c+vXrh4cPH2LevHlwdHTMsmJ43bp1cezYMezbtw+Ojo4wNzfPMYHNq2HDhmHp0qUYPHgwvvvuO1SvXh0HDx7E4cOHAeCtLQdVq1aVWvsaNGggLagIqBf0W79+PYQQ+U6E8vO+5KRbt2744YcfMGjQIIwZMwYxMTFYsmRJlrWbqlSpgq+++grz5s1DcnIyPv74Y1haWiIkJATR0dHS9Pa6deti9+7dWLVqFRo3bgw9PT00adIEAwcOhJ+fHzw9PTFx4kQ0a9YMcrkcjx49wtGjR/Hhhx/m+/UDQI8ePaR1w+zs7PDgwQMsW7YMzs7O0kzJunXrAgCWL1+OYcOGQS6Xo0aNGllaoQD1uK8NGzbA29sb//77L9q1aweVSoVz587B3d0dAwcOzHeMVIZod6w20dtlzhp7c/aWEEIkJyeLypUrC1dXV5GRkSGEEOLKlSuif//+onz58kIulwsHBwfRvn17sXr1ao26Dx8+FCNHjhQODg5CLpcLJycn0b9/f/H06VPpnJcvX4pZs2aJGjVqCENDQ2FpaSnq1q0rfHx8NGZWvTnrJVNcXJwwNjbOdcbKs2fPxIQJE0TVqlWFXC4X1tbWonHjxmLmzJni5cuXQohXs68WL16cr/fu5cuXYsGCBaJBgwbCxMREmJiYiHr16onvvvtOuvbrAIjPPvtMrFy5Uri4uAi5XC5q1qwp/Pz8iiTu//3vf6JKlSpCoVAId3d34evrK+bMmSPe/Gi6fPmyaNWqlTAxMREApBlBOc0aMzU1zfJc2V03PDxc9OnTR5iZmQlzc3PRt29fceDAAQFA/P7777m+t5nu3r0rxo0bJ6pXry4UCoUwNjYWtWrVEpMnT9aY0dS2bVtRu3btLPWHDRuWZUZWXt+XzPuVnfXr14saNWoIhUIhqlWrJhYuXCjWrVuX7UyrzZs3i6ZNmwojIyNhZmYmGjZsqDFrLjY2VvTr109YWVkJmUymEUd6erpYsmSJqF+/vlS/Zs2aYuzYseL27dvSec7OzqJbt27Zxvrmv5/vv/9etGzZUtja2gpDQ0NRuXJlMWrUKHH//n2NejNmzBBOTk5CT09P4/fgzVljQqg/K2bPni1cXV2FoaGhsLGxEe3btxenT5/ONibSHdxig4gkMpkMn332GX766Sdth6I1CxYswKxZsxAeHl7g1jgiKj3YNUZEOisz4atZsybS09Nx5MgRrFixAoMHD2YSRKQjmAgRkc4yMTHB0qVLcf/+faSmpqJy5cr48ssvMWvWLG2HRkTFhF1jREREpLO4oAIRERHpLCZCREREpLOYCBEREZHO0rnB0iqVCk+ePIG5uXmel3snIiIi7RJCICEhodD3jdO5ROjJkycF2lOHiIiItO/hw4eFuryFziVCmcuvP3z4EBYWFlqOhoiIiPIiPj4elSpVynYblXehc4lQZneYhYUFEyEiIqJSprCHtXCwNBEREeksJkJERESks5gIERERkc5iIkREREQ6i4kQERER6SwmQkRERKSzmAgRERGRzmIiRERERDqLiRARERHpLCZCREREpLO0mggdP34cPXr0gJOTE2QyGfbs2fPWOv/88w8aN24MIyMjVKtWDatXry76QImIiKhM0moilJiYiPr16+Onn37K0/lhYWHw9PRE69atERwcjK+++goTJkzArl27ijhSIiIiKou0uulq165d0bVr1zyfv3r1alSuXBnLli0DALi7uyMoKAhLlixB3759iyhKIiIiKqtK1RihM2fOoFOnThplnTt3RlBQENLT07UUFRERERWZ5Bgg7CCu+y8okstrtUUovyIjI2Fvb69RZm9vj4yMDERHR8PR0TFLndTUVKSmpkqP4+PjizxOIiIiKgBVBvDsGhBxVvqJe/IA4wM8sfVSjSJ5ylKVCAGATCbTeCyEyLY808KFCzF37twij4uIiIjy6WWERtKDyCAgI0k6fCqsEgb7e+P+83IAUookhFKVCDk4OCAyMlKjLCoqCgYGBrCxscm2zowZMzB58mTpcXx8PCpVqlSkcRIREdEbMlKAqGB1wvPkv8QnITzH01Mz9DHQ7yM8emEBADA31UNCYuGHVaoSIQ8PD+zbt0+j7M8//0STJk0gl8uzraNQKKBQKIojPCIiIgIAIYD4B5qtPVHBgDIt93oWVQDHFoBTCygcW2BdPUt09tyBVq0qYdWqDqhXr/DHCWk1EXr58iXu3LkjPQ4LC8Ply5dhbW2NypUrY8aMGXj8+DE2b94MAPD29sZPP/2EyZMn45NPPsGZM2ewbt06bNu2TVsvgYiIiNJeAk+DXrX0RJwFkp7mXsfABHBspk58HFtAODRDir4tjI1fNWx0cgQOHx6M9u2rIinpZZGErtVEKCgoCO3atZMeZ3ZhDRs2DBs3bkRERATCw181m1WtWhUHDhyAj48Pfv75Zzg5OWHFihWcOk9ERFRchAqIvaXZ2hN9TV2em3I1AKcWgKOHOvmxrQ3oqdOQ2NhkeI/cj+TkDOzdO1Bj3G+nTi5F+WogE5mjjXVEfHw8LC0tERcXBwsLC22HQ0REVLKlPAciz79q7Yk8py7LjcIKcGwutfbAoRlgbJ3tqUePhmHIkAA8fpwAAFi50hOffto0y3lF9f1dqsYIERERURFSZQDRNzRbe2Jv5l5HpgfY1n2V9Di2AKzd1OW5SEtTYtasI1iy5DQym2TKlTOCg4NZIb2YvGEiREREpKsSn74xff0CkP6WqVkm5V91bzm1AOybAIb5S15u3ozGoEG7EBz8aiZ4+/ZVsWlTL1SsWLy9NUyEiIiIdIEyDYi6rJn4xIXlXkdPDpRv+Kqlx6mFemZXDmv3vY0QAmvWXMTkyYeRnJwBAJDL9bBw4Qfw8fGAnl7BrvsumAgRERGVNUIACQ9fJTxPzgJRlwBlau71zCu/SngcW6iTIAOjQgkpNTUDH330G/btuyWVubvbws+vDxo2zLozRHFhIkRERFTapScCTy9qTl9PjMi9joGxulvL6b9uLsfmgJlTkYWoUBjA3PzVun7jxjXB4sWdYGKS/TqAxYWJEBERUWkiBPDizmsrNJ8Bnl0FhDL3euVcNQc029YF9Is3Cfn5Z0/cvh2D2bPbont3t2J97pwwESIiIirJUuOAiPOaY3tSYnOvY2iRdfq6iW3xxPufq1ef4smTBHTpUl0qs7Iywrlzo3PcH1QbmAgRERGVFColEBOimfTEhALIbck/GWBbR3NAs3XNt05fLyoqlcDy5WcxffrfMDWV4+rVTzVmgpWkJAhgIkRERKQ9Sc+AiHOvTV8/D6Ql5F7H2Fazi8uhKaAoGQsEP3mSgOHD9yAw8B4A9VpBCxacwMqV3bQcWc6YCBERERUHZZp6LM/rrT0v7uZeR88AsGugOZPLslqBp68XpT17bmL06L2IiUmWyqZM8cD8+e21GNXbMREiIiIqCgmPXhvQfBaIughkpORex6zCa7O4WgDlGwFy4+KJt4ASE9Pg43MYvr6XpDJHRzNs3twbHTpU02JkecNEiIiI6F2lJ6vX6Yk4Czw5o/7vy8e51zEwAso31mztMa9YPPEWkqCgJ/Dy2o1bt2Kkst69a8LXtwdsbEy0GFneMREiIiLKDyGAuHuarT3PLqv36cqNlYvm2B67eoC+YbGEXBRSUjLQs+c2RES8BACYmMixYkUXjBzZsMQNiM4NEyEiIqLcpMar9+B6fWxPcnTudeRmmtPXHZsDJnbFE28xMTIywMqV3dC79w40beoEP78+cHW10XZY+cZEiIiIKJNQqXdbl1ZoPqPejT3X6esAbGpptvbY1AL09Isl5OKUlqaEoeGr19WrV00EBAxAt26ukMtL5+tlIkRERLorOUZz+nrEOSAtPvc6RtZZp68bWRVLuNoSF5eC8eMPIjU1Azt29NPo+urVq6YWI3t3TISIiEg3KNOB6GuaXVzPb+deR6YP2NXXHNBsVb1ETl8vKqdOhWPw4ADcv/8CANCt2xUMG9ZAqzEVJiZCRERUNr2M0Ex6Ii8AGcm51zF1ABw9XiU+9k0AeemY/VTY0tOVmDfvOObPPwGVSt01aGGhgJFR2UodytarISIi3ZSRAkQFa87kSgjPvY6+oXr6utNr3VzmlXSqtScnd+7EYvDg3Th37tUSAK1aVcLWrX1QpYqV9gIrAkyEiIiodBECiL//2oDms+okSJWeez3Lqm9MX68PGCiKJeTSQgiBjRsv4/PPDyIxUf1+6uvL8M0372P69PdgYKCd/cuKEhMhIiIq2dJeAk+D/kt8/lusMCkq9zpyU/Ug5tenr5s6FE+8pVRKSgaGDAnAzp0hUpmLSzn4+fVB8+ala6HH/GAiREREJYdQAbG3NMf2RF9Tl+fGuqZma49tbfU+XZRnCoU+0tOV0uNRoxpi2bIuMDMrvYs+5gV/S4iISHtSnmedvp76Ivc6CqtXCY9TC8ChGWBUrjiiLdNkMhnWru2JO3c2Yu7c99G3by1th1QsmAgREVHxUGWoFyfMXKjwyVng+b+515HpAbZ1X0t8PIByrupyeic3b0bj6dOXaNu2ilRma2uCq1c/hZ6e7gwYZyJERERFIzFSs7Un8gKQnph7HZPyWaevG5oVT7w6QgiBNWsuYvLkwzA3V+DqVW/Y2796j3UpCQKYCBERUWHISFVvPPr69PX4+7nX0ZMD9o00x/ZYOHP6ehGKikrE6NF7sW/fLQBAcnIG5s07jp9+8tRyZNrDRIiIiPJHCCDh4auWnidngahLgDI193rmlV9bodkDKN8AMDAqlpAJOHjwNkaM+B1Pn75qlfvss6ZYtKijFqPSPiZCRESUu/RE4OlFzXV7EiNyr2NgnHX6uplT8cRLGpKT0/Hll3/hxx/PS2Xly5ti/fqe6NbNTYuRlQxMhIiI6BUh1PtvvT59/dlVQChzr1fO7Y3p63UAfXnxxEw5unIlEl5eu3HjxjOpzNPTFevX99QYF6TLmAgREemy1Lis09dTYnOvY2ihbuF5vbXH2KZ44qU8S05OR6dOWxEVpe4KMzIywJIlHTFuXFON3eN1HRMhIiJdoVICMSGarT0xoQBELpVk6tad19ftsa7J6eulgLGxHEuXdoaX127Ur28Pf/++qFXLTtthlThMhIiIyqqkqDdae84D6S9zr2Nsqx7InLkRqX0TQGFRPPHSO1MqVdDXf5WkDhpUF0II9OtXCwoFv/Kzw3eFiKgsUKapx/JEnAWe/LcfV9y93OvoGQB2DdSLFGa2+FhW5fT1UigxMQ0+PoeRnq7Chg0fahzz8qqnpahKByZCRESlUcIjzTV7oi4CGSm51zGr+Kqlx7EFUL4RIDcunnipyAQFPYGX127cuhUDAPD0rI6PPqqt5ahKDyZCREQlXXqyevr662N7Xj7OvY6Bkbpb6/UBzeZldwdxXaRUqrBo0SnMnn0MGRnqTWlNTORITX3LDD/SwESIiKgkEULdpSW19pwBnl1R79OVGyuX/xKe/8b32Nbj9PUyLDw8DkOGBOD48QdSWZMmTvDz6wM3N87gyw8mQkRE2pQar96D6/XWnuTo3OsYmqt3XH+9tceEs4F0xfbt1+HtvR9xceqVvGUy4KuvWmPOnLaQy/W1HF3pw0SIiKi4CJV6uvrrSU/0Dbx1+rpNrTemr7sDevzC0zXJyekYO3Y/tmy5KpVVrmyJrVt7o3VrZy1GVroxESIiKirJMZr7cUWeB9Lic69jZP1fwvPfTC6HpoDCsnjipRJNoTDQ2Cds0KC6+PlnT1hZcb+2d8FEiIioMCjTgehrmq09z2/nXkemD9jVf20j0haAVXVOX6ds6enJsHHjh2jdegPmzn2f0+ILCRMhIqKCePlEc/r60yAgIzn3OqaOmmv22DcG5CbFEy+VOnfuxCImJgnNm7+a7efoaI6bN8fDwIArexcWJkJERG+TkQJEBb9aqDDiLJDwMPc6+gp1ovP6RqTmFdnaQ28lhMDGjZfx+ecHYWVlhKtXP4W19av1npgEFS4mQkRErxMCiL//qqUn4qw6CVKl517Psqpm0mNXHzBQFEvIVHbExiZj7Nj92LkzBACQmJiOuXOPYfnyrlqOrOxiIkREui3tZdbp60lRudeRm2advm5qXzzxUpl19GgYhgwJwOPHCVLZqFENMX/+B1qMquxjIkREukOogNhb6kUKpenr19XlubGuqbkRqU1tTl+nQpOWpsSsWUewZMlpiP9WUihXzgi+vj3Qt28t7QanA5gIEVHZlRyrnrIutfacA1Jf5F5HYaW5Zo9DM8CoXHFESzro5s1oDBq0C8HBkVJZ+/ZVsWlTL1SsaKHFyHQHEyEiKhtUGerWndfX7Xn+b+51ZHrqrShe34i0nKu6nKiIJSWlo02bDXj2LAkAIJfrYeHCD+Dj4wE9PQ6qLy5MhIiodEqM1BzQHHkByEjKvY6Jfdbp64ZmxRMv0RtMTOSYP789xozZD3d3W/j790WDBg7aDkvnMBEiopIvIxV4dllz3Z74+7nX0ZMD9o00Z3JZOHP6OmmVEAKy134HR49uBCGAwYPrwcSEm+RqAxMhIipZhAASwt+Yvn4JUKblXs/CWTPpKd8AMODWA1QyJCen48sv/4IQAj/+6CmVy2QyjBnTWIuRERMhItKu9EQgMkhz+npiZO51DEzUe3C9Pn3dzLF44iXKpytXIuHltRs3bjwDAHTpUh3durlpOSrKxESIiIqPEOr9t15Pep5dBYQy93rl3N5YrLAuoMePLyrZVCqB5cvPYvr0v5GWpv4dNzIykAZHU8nATxIiKjopL7JOX0+Jzb2OwhJwaK45fd3YpljCJSosT54kYPjwPQgMvCeV1a9vD3//vqhVy06LkdGbmAgRUeFQKYGYEPVihZnje2JDc68j0wNs62i29ljX4PR1KtUCAkLxySf7EBPzahPeKVM8MH9+eygU/NotaXhHiKhgkqLULTxSa895IP1l7nWM7V619Di2UI/zMTQvnniJilhKSgYmTDgIX99LUpmTkzk2beqFDh2qaTEyyg0TISJ6O2Ua8OyK5kyuuHu519EzAMo31GztsazK6etUZsnlerh5M1p63Lt3Tfj69oCNjYkWo6K3YSJERFnFP9Qc0Pz0IqBMzb2OeaU3pq83BOTGxRMvUQmgr6+HLVt6o1Wr9Zg7932MHNlQY80gKpmYCBHpuvQk4OklzcTn5ePc6xgYAfZNNBMf8wrFEy9RCfHgwQs8f56isRq0s7MV7t6dwLFApQjvFJEuEQJ4cfeN6etX1Pt05caquuZGpLb1AH2ugku6a9u2a/j00z9gbW2My5e9YWGhkI4xCSpdeLeIyrLUeM3p60/OAikxudcxNFdPX5cGNDcHTGyLJ16iEi4uLgXjxx/E1q1X/3ucirlzj+H77ztrOTIqKK0nQitXrsTixYsRERGB2rVrY9myZWjdunWO5/v5+WHRokW4ffs2LC0t0aVLFyxZsgQ2NlxnhHScUAExoZqtPdE3AIhcKskAm1qarT3W7oCefnFFTVRqnDoVjsGDA3D//gupbNCgupg9u632gqJ3ptVEaMeOHZg0aRJWrlyJVq1aYc2aNejatStCQkJQuXLlLOefPHkSQ4cOxdKlS9GjRw88fvwY3t7eGD16NAICArTwCoi0KCkaiDz3qqUn8jyQFp97HSObVy09mdPXFZbFEy9RKZWersS8eccxf/4JqFTqPywsLBRYudITXl71tBwdvSuZECK3PxeLVPPmzdGoUSOsWrVKKnN3d0evXr2wcOHCLOcvWbIEq1atwt27d6WyH3/8EYsWLcLDhw/z9Jzx8fGwtLREXFwcLCws3v1FEBUHZToQfVVz+vqLO7nXkemrNx59fUCzlQunrxPlw927sfDy2o1z515NIHjvvcrYsqU3qlSx0l5gOqiovr+11iKUlpaGixcvYvr06RrlnTp1wunTp7Ot07JlS8ycORMHDhxA165dERUVhZ07d6Jbt245Pk9qaipSU19N+42Pf8tfzEQlwcsnr1p6Is4AT4OAjJTc65g6Ak4egKOHOumxbwTIuX4JUUElJqahRYt1iI5W7w2mry/D3LnvY/r096Cvz9XPywqtJULR0dFQKpWwt7fXKLe3t0dkZPY7T7ds2RJ+fn4YMGAAUlJSkJGRgZ49e+LHH3/M8XkWLlyIuXPnFmrsRIUqIyXr9PWEt7Rw6isA+8ZvTF+vyNYeokJkamqIWbNaY9Kkw3BxKQd//75o1ozLRJQ1Wh8s/eZiU0KIHBegCgkJwYQJEzB79mx07twZERERmDp1Kry9vbFu3bps68yYMQOTJ0+WHsfHx6NSpUqF9wKI8kMIIC5MM+mJugyo0nOvZ1lNc0CzXX1A37BYQibSJW9+B33+eXOoVAKffNIYZmb8N1cWaS0RsrW1hb6+fpbWn6ioqCytRJkWLlyIVq1aYerUqQCAevXqwdTUFK1bt8Z3330HR0fHLHUUCgUUCkWWcqJikZYARAZpJj5JUbnXkZuqd1x3bPFfV1dzwKR88cRLpKPS0pSYNesI9PRk+N//Okjlenoy+Ph4aDEyKmpaS4QMDQ3RuHFjBAYGonfv3lJ5YGAgPvzww2zrJCUlwcBAM2R9ffU0Xy2O+SZSEyog9t83pq9fV5fnxtpdcyNSm9qcvk5UjEJDn8HLazeCgyMhkwGdO7ugXbuq2g6LiolWu8YmT56MIUOGoEmTJvDw8MAvv/yC8PBweHt7A1B3az1+/BibN28GAPTo0QOffPIJVq1aJXWNTZo0Cc2aNYOTk5M2XwrpouRY9fT1zJlckeeA1Ljc6xiV0xzX49AMMLIqlnCJSJMQAqtXB2HKlD+RnKxeXd3AQA937z5nIqRDtJoIDRgwADExMfj2228RERGBOnXq4MCBA3B2dgYAREREIDw8XDp/+PDhSEhIwE8//YQpU6bAysoK7du3x//93/9p6yWQrlBlqFt3Xl+h+fm/udeR6am3onBq8WomVzlXDmgmKgGiohIxatRe7N9/Sypzd7eFv39fjb3DqOzT6jpC2sB1hChPEiM11+yJvABkJOVex8T+vzE9/7X22DcGDM2KJ14iyrODB29j+PDfERWVKJWNG9cEixd3gokJ99ArqcrcOkJEJUZGKhAVrDm2J/5B7nX0DYHyjTRncplXZmsPUQmWkpKBadMC8eOP56UyOzsTrF//Ibp3d9NiZKRNTIRItwgBJIS/1tpzRp0EKdNyr2fhrO7eyhzQbNcAMOBsRKLSRF9fhrNnH0mPPT1dsX59T9jbs+VWlzERorItPTHr9PXE7BfslBiYqPfgkgY1NwfMsi7NQESli1yuDz+/PmjZcj2++aYtxo1rmuO6daQ7mAhR2SEE8PyW5oDm6GuAUOZer1wNzY1IbesAevynQVTaPXmSgLi4FLi720llrq42uH9/IkxNuTgiqfHTnkqvlBfqHdcjzgJPzqinr6c8z72OwhJwaP5qsUKHZoCxdbGES0TFJyAgFJ98sg/ly5siKGiMxiBoJkH0OiZCVDqolEDMjdc2Ij0LxIbmXkemp27deX3dHusa6nIiKpMSE9Pg43MYvr6XAAAxMcn49tt/NFaLJnodEyEqmZKisk5fT3+Zex1jO83p6w5NAEPz4omXiLQuKOgJvLx249atGKmsd++amDq1pRajopKOiRBpnzINeHZFM/GJu5d7HT05UL6h5vR1iyqcvk6kg5RKFRYtOoXZs48hI0O9pY2JiRwrVnTByJENOSCacsVEiIqXEEDCI81ZXE8vAsrU3OuZV9Ls4irfEJAbF0/MRFRihYfHYciQABw//mrtr6ZNneDn1weurjZajIxKCyZCVLTSk9SJzuuJz8snudcxMAbsm7xq6XFoDphXKJ54iajUSEhIRZMmv+DZM/Wq7zIZ8NVXrTFnTlvI5dy4mPKGiRAVHiGAF3fVixRmdnM9u/L26etW1TXH9tjWBfS5zD0R5c7cXIFJk1pg5swjqFzZElu39kbr1s7aDotKGSZCVHCpcepBzK+v25MSk3sdQ3N1C0/muj0OzQET2+KJl4jKnC+/bAWVSmD8+GawsjLSdjhUCjERorxRKdXT1V8f0BwTAiC3PXtlgG3tN6av1wT02GRNRPmTkaHCvHn/wMBAD19/3VYq19fXw6xZbbQYGZV2TIQoe0nR6gUKpcUKzwNpCbnXMbL5r6Xnv24uh6aAovB2CCYi3XT3biy8vHbj3LnH0NOToUOHavDwqKTtsKiMYCJEgDIdiL6q2drz4k7udfQMALv6mq09Vi6cvk5EhUYIgU2bruDzzw/i5Uv1xsgyGXDlylMmQlRomAjpooTHb0xfDwIyUnKvY+b0qqXHsQVg3wiQmxRPvESkc2JjkzF27H7s3Bkilbm4lIOfXx80b15Ri5FRWcNEqKzLSAGeXlLP5Moc0PzyUe519BWa09cdWwDm/OAhouJx9GgYhgwJwOPHr7rjR41qiGXLusDMjPuEUeFiIlSWCAHEhWm29kRdBlTpudezrKa5QrNdfUCfHzZEVLzS0pT4+usjWLz4NMR/8zDKlTOCr28P9O1bS7vBUZnFRKg0S0t4NX09c3xP8rPc68jNAMdmr43taQ6YlC+eeImIcqFSCRw8eEdKgtq3r4pNm3qhYkVOuqCiw0SotBAqIPZf9Qwuafr6DXV5bmxqaQ5otqnF6etEVCIZGRnA378vWrVaj9mz28DHxwN6epyAQUWLiVBJlRyrnr6e2dITeU69gGFujMppJj0OzQAjq2IJl4gov6KiEpGQkAoXF2uprE6d8njwYBIXR6Riw0SoJFBlAM+uaY7teX4r9zoyfcCunmbiU86V09eJqFQ4ePA2hg//HU5O5jh7dhQUildfR0yCqDgxEdKGlxFAxLlXM7kig4CMpNzrmDq8mr7u1AKwbwzITYsnXiKiQpKcnI4vv/wLP/54HoC6VWj+/BP49tt2Wo6MdBUToaKWkQpEBWu29sQ/yL2OviFQvtF/Sc9/yY95Jbb2EFGpduVKJLy8duPGjVeTOjw9XfHZZ021GBXpOiZChUkIdZKjMX09GFCm5V7Poormmj12DQADRXFETERU5FQqgeXLz2L69L+RlqYEoB4YvWRJR4wb1xQy/pFHWsRE6F2kJ6q7tV6fyZX0NPc6BiZZp6+bOhRPvERExezJkwQMG7YHf/11TyqrX98e/v59UauWnRYjI1JjIpQfL+4Bj0+8Wrcn+urbp6+Xq/GqpcfRQ70bux7fdiIq++LiUtCgwWo8e/ZqDOSUKR6YP7+9xuBoIm3ib+LbJDwC/t0B3NwGPL2Y+7kKK3ULz+vT142tc69DRFRGWVoaYcyYxpg//wScnMyxaVMvdOhQTdthEWlgIpQdZRoQshUI2QQ8OgFAZD1HpgfY1tWcvm7tpi4nIiIAwJw5baFSCUyZ4gEbG27UTCVPgRKhjIwMHDt2DHfv3sWgQYNgbm6OJ0+ewMLCAmZmZoUdY/FRKYFQP+DMN+o9u95UvhHg2htwagU4NAUMS/FrJSIqREqlCosWnYKRkQF8fDykcrlcHwsWfKDFyIhyl+9E6MGDB+jSpQvCw8ORmpqKjh07wtzcHIsWLUJKSgpWr15dFHEWvQd/AUcmALGhmuXlagA1P1b/WLtpJzYiohIsPDwOQ4YE4PjxB5DL9fD++1XQsKGjtsMiypN89+NMnDgRTZo0wfPnz2FsbCyV9+7dG3///XehBlcshAAuLgN2ddZMgpw7Ah+fAUaEAi3nMAkiIsrG9u3XUa/eKhw/rl4fLSNDhdOnH2o5KqK8y3eL0MmTJ3Hq1CkYGhpqlDs7O+Px48eFFlixUKYBf48Hrvm+KnNqCby3AKjUVntxERGVcPHxqRg//gC2bLkqlVWubImtW3ujdWtnLUZGlD/5ToRUKhWUSmWW8kePHsHc3LxQgioWybHAweHAo39elTWfCbT6lgOeiYhycepUOAYPDsD9+y+kskGD6uLnnz25TxiVOvn+xu/YsSOWLVsmPZbJZHj58iXmzJkDT0/PwoytaO3s+CoJ0lcAnn7Ae98xCSIiykF6uhKzZx9FmzYbpSTIwkKBrVt7w8+vD5MgKpXy3SK0dOlStGvXDrVq1UJKSgoGDRqE27dvw9bWFtu2bSuKGIvGizuAEQATe6DX7+r1f4iIKEdpaUrs2HEDKpV6SZH33quMLVt6o0oVK+0GRvQOZEKIbBbJyV1ycjK2b9+OixcvQqVSoVGjRvDy8tIYPF1SxcfHw9LSEnHfARYmBsCw64B1DW2HRURUKgQFPUGbNhswc2ZrTJ/+HvT12YpOxUP6/o6Lg4WFRaFdN9+J0PHjx9GyZUsYGGg2JmVkZOD06dNo06ZNoQVXFDQSoWZjgY6ldLo/EVERi41NRmJiGipVstQoj4pKRPnyplqKinRVUSVC+U7l27Vrh9jY2CzlcXFxaNeuXaEEVWyqddN2BEREJdLRo2GoV28V+vffiYwMzT0VmQRRWZLvREgIAZlMlqU8JiYGpqal7B+HWUVtR0BEVKKkpSkxbVogPvhgMx4/TsDZs4/wf/93UtthERWZPA+W7tOnDwD1LLHhw4dDoVBIx5RKJa5evYqWLVsWfoRFychK2xEQEZUYoaHP4OW1G8HBkVJZ+/ZVMWxYA+0FRVTE8pwIWVqq+4iFEDA3N9cYGG1oaIgWLVrgk08+KfwIi5Jh4fUxEhGVVkIIrFlzEZMnH0ZycgYAQC7Xw4IFH2DyZA/o6WXtBSAqK/KcCG3YsAEAUKVKFXzxxRelrxssO3JumkpEui0qKhGjR+/Fvn23pDJ3d1v4+fXhfmGkE/K9jtCcOXOKIo7iJ5MB+oZvP4+IqIx68SIF9euvRmTkS6ls3LgmWLy4E0xM5FqMjKj45DsRAoCdO3fi119/RXh4ONLS0jSOXbp0qVACK3L6RupkiIhIR1lZGWHgwNpYtuwc7OxMsH79h+jenRtMk27J96yxFStWYMSIEShfvjyCg4PRrFkz2NjY4N69e+jatWtRxFg09NgaRES0cGEHTJjQDNeufcokiHRSvhOhlStX4pdffsFPP/0EQ0NDTJs2DYGBgZgwYQLi4uKKIsaiwT3FiEiHqFQCS5eewS+/XNQoNzIywPLlXWFvzzGTpJvynQ2Eh4dL0+SNjY2RkJAAABgyZEjp2muMiRAR6YgnTxLQpctWTJ78JyZOPITQ0GfaDomoxMh3NuDg4ICYmBgAgLOzM86ePQsACAsLQwG2LdMeJkJEpAMCAkJRr94qBAbeAwCkpGRI/09EBRgs3b59e+zbtw+NGjXCqFGj4OPjg507dyIoKEhadLFUYCJERGVYYmIafHwOw9f31QQWJydzbNrUCx06VNNiZEQlS74ToV9++QUqlXrfGW9vb1hbW+PkyZPo0aMHvL29Cz3AIsNEiIjKqKCgJ/Dy2o1bt2Kkst69a8LXtwdsbEy0GBlRyZPvREhPTw96eq+SiP79+6N///4AgMePH6NChQqFF12R4tR5IipblEoVFi06hdmzj0kbpZqYyLFiRReMHNkw230iiXRdoTSLREZG4vPPP0f16tUL43LFgy1CRFTGJCamY82ai1IS1LSpEy5fHotRoxoxCSLKQZ6zgRcvXsDLywt2dnZwcnLCihUroFKpMHv2bFSrVg1nz57F+vXrizLWwsUPBSIqYywsFNiypTfkcj3MnNkap06NhKurjbbDIirR8tw19tVXX+H48eMYNmwYDh06BB8fHxw6dAgpKSk4ePAg2rZtW5RxFgEmQkRUusXHpyIpKR0ODq/WAGrd2hl3705ApUqWWoyMqPTIc4vQH3/8gQ0bNmDJkiXYu3cvhBBwc3PDkSNHSmESBLYIEVGpdupUOOrXX41Bg3ZBpdJcuoRJEFHe5TkRevLkCWrVqgUAqFatGoyMjDB69OgiC6zoMREiotInPV2J2bOPok2bjbh//wWOHr2PpUvPaDssolIrz11jKpUKcvmr3Yj19fVhampaJEEVC7YIEVEpc+dOLAYP3o1z5x5LZe+9Vxl9+9bSYlREpVueEyEhBIYPHw6FQgEASElJgbe3d5ZkaPfu3YUbYZFhIkREpYMQAhs3Xsbnnx9EYmI6AEBfX4a5c9/H9OnvQV+fs2CJCirP/3qGDRuG8uXLw9LSEpaWlhg8eDCcnJykx5k/+bVy5UpUrVoVRkZGaNy4MU6cOJHr+ampqZg5cyacnZ2hUCjg4uJSsNlqbBEiolIgNjYZ/fvvxMiRe6UkyMWlHE6fHoWZM9swCSJ6R3luEdqwYUOhP/mOHTswadIkrFy5Eq1atcKaNWvQtWtXhISEoHLlytnW6d+/P54+fYp169ahevXqiIqKQkZGRqHHRkSkbc+fJ6N+/dV49CheKhs1qiGWLesCMzNDLUZGVHbIhBZ3Sm3evDkaNWqEVatWSWXu7u7o1asXFi5cmOX8Q4cOYeDAgbh37x6sra0L9Jzx8fGwtLRE3E/VYfHZ7QLHTkRUHMaO3YdffrmEcuWM4Ovbg+OBSGdJ399xcbCwsCi062qtTTUtLQ0XL15Ep06dNMo7deqE06dPZ1tn7969aNKkCRYtWoQKFSrAzc0NX3zxBZKTk/MfALvGiKgU+OGHzhg1qiGuXv2USRBREcj3XmOFJTo6GkqlEvb29hrl9vb2iIyMzLbOvXv3cPLkSRgZGSEgIADR0dEYN24cYmNjcxwnlJqaitTUVOlxfHx8tucREWmTEAJr1lyEmZkhBg+uJ5Wbmhpi7dqeWoyMqGzTWiKU6c39b4QQOe6Jo1KpIJPJ4OfnJw3M/uGHH9CvXz/8/PPPMDY2zlJn4cKFmDt3bnbP/M6xExEVhqioRIwevRf79t2CmZkhPDwqwsWlYN3/RJQ/Wusas7W1hb6+fpbWn6ioqCytRJkcHR1RoUIFjdlp7u7uEELg0aNH2daZMWMG4uLipJ+HDx8W3osgInpHBw/eRr16q7Bv3y0AwMuXadi//5aWoyLSHQVKhLZs2YJWrVrByckJDx48AAAsW7YMv//+e56vYWhoiMaNGyMwMFCjPDAwEC1btsy2TqtWrfDkyRO8fPlSKrt16xb09PRQsWLFbOsoFApYWFho/ADgGCEi0qrk5HRMmHAQnp7+ePo0EQBgZ2eCffs+xsSJLbQcHZHuyHcitGrVKkyePBmenp548eIFlEolAMDKygrLli3L17UmT56MtWvXYv369QgNDYWPjw/Cw8Ph7e0NQN2aM3ToUOn8QYMGwcbGBiNGjEBISAiOHz+OqVOnYuTIkdl2ixERlURXrz5F06a++PHH81KZp6crrl37FN27u2kxMiLdk+9E6Mcff4Svry9mzpwJfX19qbxJkya4du1avq41YMAALFu2DN9++y0aNGiA48eP48CBA3B2dgYAREREIDw8XDrfzMwMgYGBePHiBZo0aQIvLy/06NEDK1asyO/LICIqdiqVwNKlZ9C0qS9u3HgGADAyMsBPP3XF/v0fw97e7C1XIKLClu91hIyNjXHz5k04OzvD3NwcV65cQbVq1XD79m3Uq1evYFPZi5G0DsHKmrD4NFTb4RCRDnn+PBm1a69ERIS6e79ePXv4+/dB7drltRwZUclXYtYRqlq1Ki5fvpyl/ODBg9Lu9KUCxwgRUTErV84Ymzb1gp6eDFOmeOD8+dFMgoi0LN/T56dOnYrPPvsMKSkpEELg/Pnz2LZtGxYuXIi1a9cWRYxERKVSYmIaUlIyYGNjIpV17OiCf/8dj+rVOT2eqCTIdyI0YsQIZGRkYNq0aUhKSsKgQYNQoUIFLF++HAMHDiyKGImISp2goCfw8tqN6tWtsX//xxrrozEJIio53mmvsejoaKhUKpQvX3qadqU+xlXusPAO0XY4RFTGKJUqLFp0CrNnH0NGhgoA8PPPnhg3rqmWIyMq3UrMGKG5c+fi7t27ANSLIpamJEgTxwgRUeEKD49D+/ab8dVXR6QkqGlTJ3TsWE3LkRFRTvKdCO3atQtubm5o0aIFfvrpJzx79qwo4iIiKlW2b7+OevVW4fhx9SKzenoyzJzZGqdOjYSrq42WoyOinOQ7Ebp69SquXr2K9u3b44cffkCFChXg6ekJf39/JCUlFUWMREQlVnx8KoYODcDHH+9CXJx6g+fKlS1x7NgwfPdde8jl+m+5AhFp0zuNEQKAU6dOwd/fH7/99htSUlJK/O7ur8YI1YKF9w1th0NEpVhMTBKaNvVFWNgLqWzQoLr4+WdPWFkZaS8wojKoxIwRepOpqSmMjY1haGiI9PT0woiJiKhUsLExQatWlQEAFhYKbN3aG35+fZgEEZUi+Z4+DwBhYWHw9/eHn58fbt26hTZt2uCbb77BRx99VNjxFR0uqEhEheCnn7pCqVRhwYIPUKWKlbbDIaJ8ynci5OHhgfPnz6Nu3boYMWKEtI4QEVFZJoTApk1XYGGhQJ8+7lK5paUR/P37ajEyInoX+U6E2rVrh7Vr16J27dpFEQ8RUYkTG5uMsWP3Y+fOEFhZGaFpUydUqmSp7bCIqBDke4zQggULykgSxK4xInq7o0fDUK/eKuzcqV6A9cWLFOn/iaj0y1OL0OTJkzFv3jyYmppi8uTJuZ77ww8/FEpgRETalJamxKxZR7BkyWlkzq0tV84Ivr490LdvKdpgmohyladEKDg4WJoRFhwcXKQBERFp282b0Rg0aBeCgyOlsvbtq2LTpl6oWLHwpu0SkfblKRE6evRotv9PRFSWCCGwZs1FTJ58GMnJGQAAuVwPCxd+AB8fD+jpsUudqKzJ9xihkSNHIiEhIUt5YmIiRo4cWShBERFpQ2xsMr7++qiUBLm72+L8+U8wZUpLJkFEZVS+E6FNmzYhOTk5S3lycjI2b95cKEEREWmDjY0J1q7tAQAYN64JgoLGoEEDBy1HRURFKc/T5+Pj4yGEgBACCQkJMDJ6tXKqUqnEgQMHSvFO9ESki5KT05GWpoSl5avPsw8/rImrV71Rt669FiMjouKS50TIysoKMpkMMpkMbm5uWY7LZDLMnTu3UIMrWmzmJtJlV68+xaBBu+Dubodff+0H2WurzTMJItIdeU6Ejh49CiEE2rdvj127dsHa2lo6ZmhoCGdnZzg5ORVJkEREhUWlEli+/CymT/8baWlK3LjxDJs2XcHw4Q20HRoRaUGeE6G2bdsCUO8zVrlyZY2/noiISoMnTxIwfPgeBAbek8rq17dHs2bcJohIV+UpEbp69Srq1KkDPT09xMXF4dq1azmeW69evUILjoiosAQEhOKTT/YhJubVZI8pUzwwf357KBQF2n+aiMqAPP3rb9CgASIjI1G+fHk0aNAAMpkMInOp1dfIZDIolcpCD5KIqKASE9Pg43MYvr6XpDInJ3Ns2tQLHTpU02JkRFQS5CkRCgsLg52dnfT/RESlwbNniXjvvQ24dStGKuvduyZ8fXvAxsZEi5ERUUmRp0TI2dk52/8v1TjGiajMs7U1Qe3adrh1KwYmJnKsWNEFI0c25BhHIpIUaEHFP/74Q3o8bdo0WFlZoWXLlnjw4EGhBkdE9C5kMhl8fXugZ88auHx5LEaNasQkiIg05DsRWrBgAYyNjQEAZ86cwU8//YRFixbB1tYWPj4+hR4gEVFebd9+HQcP3tYos7Exwe+/D4Srq42WoiKikizfUyUePnyI6tWrAwD27NmDfv36YcyYMWjVqhXef//9wo6PiOit4uNTMX78AWzZchV2dia4du1T2NubaTssIioF8t0iZGZmhpgY9cDDP//8Ex06dAAAGBkZZbsHGRFRUTp1Khz166/Gli1XAQDPniXBzy/nJT6IiF6X7xahjh07YvTo0WjYsCFu3bqFbt26AQBu3LiBKlWqFHZ8RETZSk9XYt6845g//wRUKvVyHhYWCqxc6QkvL65nRkR5k+8WoZ9//hkeHh549uwZdu3aBRsbdb/7xYsX8fHHHxd6gEREb7pzJxatW2/AvHnHpSTovfcq48oVbyZBRJQvMpHdyohlWHx8PCwtLRG3ph4sxlzRdjhElA9CCGzceBmff34QiYnpAAB9fRnmzn0f06e/B339fP9tR0SlhPT9HRcHCwuLQrtugdaVf/HiBdatW4fQ0FDIZDK4u7tj1KhRsLS0LLTAiIje9OxZEnx8DktJkItLOfj59UHz5hW1HBkRlVb5/vMpKCgILi4uWLp0KWJjYxEdHY2lS5fCxcUFly5devsFiIgKqHx5U6xe3R0AMGpUQ1y+7M0kiIjeSb67xlq3bo3q1avD19cXBgbqBqWMjAyMHj0a9+7dw/Hjx4sk0MLyqmusPizGXNZ2OESUi7Q0JdLTlTA1NdQoP3/+MXeMJ9IxRdU1VqAWoS+//FJKggDAwMAA06ZNQ1BQUKEFRkS67ebNaHh4rMNnnx3IcoxJEBEVlnwnQhYWFggPD89S/vDhQ5ibmxdKUESku4QQWL06CI0arcGlSxHYtOkKfv31hrbDIqIyKt+DpQcMGIBRo0ZhyZIlaNmyJWQyGU6ePImpU6dy+jwRvZNnzxIxatRe7Nt3Sypzd7eFq6u1FqMiorIs34nQkiVLIJPJMHToUGRkZAAA5HI5Pv30U/zvf/8r9ACJSDccOnQHw4fvwdOniVLZuHFNsHhxJ5iYyLUYGRGVZQVeRygpKQl3796FEALVq1eHiYlJYcdWJDhYmqhkSU5Ox/Tpf2HFivNSmZ2dCdav/xDdu7tpMTIiKkm0vo5QUlISpk6dij179iA9PR0dOnTAihUrYGtrW2jBEJFuiYpKxAcfbMb161FSmaenK9av78lNU4moWOR5sPScOXOwceNGdOvWDQMHDkRgYCA+/fTTooyNiMo4W1sTVKignmRhZGSAn37qiv37P2YSRETFJs8tQrt378a6deswcOBAAMDgwYPRqlUrKJVK6OvrF1mARFR26enJsGHDhxg6dA+WL++CWrXstB0SEemYPLcIPXz4EK1bt5YeN2vWDAYGBnjy5EmRBEZEZc+ePTdx7Nh9jTJHR3MEBg5hEkREWpHnREipVMLQUHN1VwMDA2nmWKkjk2k7AiKdkZiYhjFj9qF37x0YPHg3YmOTtR0SERGAfHSNCSEwfPhwKBQKqSwlJQXe3t4wNTWVynbv3l24ERJRqRYU9AReXrtx61YMAODx4wRs3HgZkyd7aDkyIqJ8JELDhg3LUjZ48OBCDYaIyg6lUoVFi05h9uxjyMhQAQBMTORYsaILRo5sqOXoiIjU8pwIbdiwoSjjIKIyJDw8DkOGBOD48QdSWZMmTvDz6wM3NxstRkZEpCnfK0sTEeVm+/br8Pbej7i4VADq4XhffdUac+a0hVzOGaZEVLIwESKiQhMZ+RKjR+9FYmI6AKByZUts3dobrVs7azkyIqLs5Xv3eSKinDg4mGH58i4AgI8/roMrV7yZBBFRicYWISIqsPR0JZRKASOjVx8lI0c2RLVq5dCuXVUtRkZElDdsESKiArlzJxatW2/AlCmHNcplMhmTICIqNQqUCG3ZsgWtWrWCk5MTHjxQzwpZtmwZfv/990INjohKHiEENmwIRoMGq3Hu3GOsXBmE/ftvaTssIqICyXcitGrVKkyePBmenp548eIFlEolAMDKygrLli0r7PiIqASJjU1G//47MXLkqwHRLi7lUL686VtqEhGVTPlOhH788Uf4+vpi5syZGputNmnSBNeuXSvU4Iio5Dh6NAz16q3Czp0hUtmoUQ1x+bI3mjWroMXIiIgKLt+DpcPCwtCwYdZVYRUKBRITEwslKCIqOdLSlJg16wiWLDkNIdRl5coZwde3B/r2raXd4IiI3lG+E6GqVavi8uXLcHbWnBJ78OBB1KrFD0WisiQqKhFdumxFcHCkVPbBB1WxaVMvVKhgocXIiIgKR74ToalTp+Kzzz5DSkoKhBA4f/48tm3bhoULF2Lt2rVFESMRaYmNjTHMzdUbLcvleli48AP4+HhAT0+m5ciIiApHvscIjRgxAnPmzMG0adOQlJSEQYMGYfXq1Vi+fDkGDhyY7wBWrlyJqlWrwsjICI0bN8aJEyfyVO/UqVMwMDBAgwYN8v2cRJQ3+vp62LKlN1q2rITz5z/BlCktmQQRUZkiEyKz1z//oqOjoVKpUL58+QLV37FjB4YMGYKVK1eiVatWWLNmDdauXYuQkBBUrlw5x3pxcXFo1KgRqlevjqdPn+Ly5ct5fs74+HhYWloi7pcGsPgkuEBxE5VVBw/eRrlyxmjRoqJGuRACMhkTICLSHun7Oy4OFhaF1zX/Tgsq2traFjgJAoAffvgBo0aNwujRo+Hu7o5ly5ahUqVKWLVqVa71xo4di0GDBsHDw6PAzw3wQ50oU3JyOiZMOAhPT38MGrQL8fGpGseZBBFRWVWgwdK5fSjeu3cvT9dJS0vDxYsXMX36dI3yTp064fTp0znW27BhA+7evYutW7fiu+++e+vzpKamIjX11Yd6fHx8nuIj0hVXrkTCy2s3btx4BgAIC3uBdesuwcfnXf7QICIqHfKdCE2aNEnjcXp6OoKDg3Ho0CFMnTo1z9eJjo6GUqmEvb29Rrm9vT0iIyOzrXP79m1Mnz4dJ06cgIFB3kJfuHAh5s6dm+e4iHSFSiWwfPlZTJ/+N9LS1AujGhkZ4PvvO+HTT5toOToiouKR70Ro4sSJ2Zb//PPPCAoKyncAb7Yu5TQWQalUYtCgQZg7dy7c3NzyfP0ZM2Zg8uTJ0uP4+HhUqlQp33ESlSVPniRg+PA9CAx81YJbv749/P37olYtOy1GRkRUvApt09WuXbti165deT7f1tYW+vr6WVp/oqKisrQSAUBCQgKCgoIwfvx4GBgYwMDAAN9++y2uXLkCAwMDHDlyJNvnUSgUsLCw0Pgh0mUBAaGoV2+VRhI0ZYoHzp0bzSSIiHROvluEcrJz505YW1vn+XxDQ0M0btwYgYGB6N27t1QeGBiIDz/8MMv5FhYWWbbwWLlyJY4cOYKdO3eialXudk30Nk+eJODjj3chNVXdFebkZI5Nm3qhQ4dqWo6MiEg78p0INWzYUKPrSgiByMhIPHv2DCtXrszXtSZPnowhQ4agSZMm8PDwwC+//ILw8HB4e3sDUHdrPX78GJs3b4aenh7q1KmjUb98+fIwMjLKUk5E2XNyMsfixR0xYcIh9O5dE76+PWBjY6LtsIiItCbfiVCvXr00Huvp6cHOzg7vv/8+atasma9rDRgwADExMfj2228RERGBOnXq4MCBA9L2HREREQgPD89viET0H6VSBZVKQC5/tUHy+PHNUK1aOXh6unJaPBHpvHwtqJiRkQE/Pz907twZDg4ORRlXkXm1oGJDWHxySdvhEBWZ8PA4DBkSgObNK2DRoo7aDoeI6J2UiAUVDQwM8Omnn2qsy0NEJc/27ddRr94qHD/+AIsXn8bff+dtfS8iIl2T71ljzZs3R3Awt6YgKoni41MxdGgAPv54F+Li1H+wVK5sCSOjQpsXQURUpuT703HcuHGYMmUKHj16hMaNG8PU1FTjeL169QotOCLKu1OnwjF4cADu338hlQ0aVBc//+wJKysj7QVGRFSC5TkRGjlyJJYtW4YBAwYAACZMmCAdk8lk0kKISqWy8KMkohylpysxb95xzJ9/AiqVesifhYUCK1d6wsuLf5gQEeUmz4nQpk2b8L///Q9hYWFFGQ8R5UNUVCJ69tyGc+ceS2XvvVcZW7b0RpUqVtoLjIiolMhzIpQ5uSxzajsRaV+5ckbInPepry/D3LnvY/r096CvX2iLxhMRlWn5+rTkmiNEJYtcrg8/vz5o0MABp0+PwsyZbZgEERHlQ74GS7u5ub01GYqNjX2ngIgoZ0ePhqFcOWM0aPBqHa/q1a1x6dIY/qFCRFQA+UqE5s6dC0tLy6KKhYhykJamxKxZR7BkyWnUqGGLixfHwMRELh1nEkREVDD5SoQGDhyI8uXLF1UsRJSNmzejMWjQLgQHR0qPfX0vYuLEFlqOjIio9MvzYAL+xUlUvIQQWL06CI0arZGSILlcD0uWdMTnnzfXcnRERGVDvmeNEVHRi4pKxOjRe7Fv3y2pzN3dFv7+fTXGBxER0bvJcyKkUqmKMg4i+s/Bg7cxYsTvePo0USobN64JFi/upDEuiIiI3h03ICIqQR49iseHH25Herr6Dw87OxOsX/8hund303JkRERlExccISpBKla0wLfftgMAdO1aHdeufcokiIioCLFFiEiLVCoBIYTGIohTp7aEi0s59OtXi5MUiIiKGFuEiLTkyZMEdOmyFfPmHdco19fXw0cf1WYSRERUDNgiRKQFAQGh+OSTfYiJScbff4ehUycXtGxZSdthERHpHCZCRMUoMTENPj6H4et7SSqztzdFerpSi1EREekuJkJExSQo6Am8vHbj1q0Yqax375rw9e0BGxsTLUZGRKS7mAgRFTGlUoVFi05h9uxjyMhQT4s3MZFjxYouGDmyIccCERFpERMhoiIUFZWIjz76DcePP5DKmjZ1gp9fH7i62mgxMiIiAjhrjKhIWVgo8OJFCgBAJgNmzmyNU6dGMgkiIiohmAgRFSEjIwP4+/dBjRo2+Oef4fjuu/aQy/W1HRYREf2HXWNEhejUqXCUK2eMWrXspLLatcvjxo1xGosmEhFRycBPZqJCkJ6uxOzZR9GmzUYMGrQLqakZGseZBBERlUz8dCZ6R3fvxqJ16w2YN+84VCqBK1ee4pdfLmo7LCIiygN2jREVkBACmzZdweefH8TLl2kAAH19GebOfR/jxjXVbnBERJQnTISICiA2Nhljx+7Hzp0hUpmLSzn4+/dFs2YVtBgZERHlBxMhonw6ciQMQ4cG4PHjBKls1KiGWLasC8zMDLUYGRER5RcTIaJ8CA+PQ+fOW6UVosuVM4Kvbw/07VtLy5EREVFBcLA0UT5UrmyJGTPeAwC0b18VV69+yiSIiKgUY4sQUS6EEBAC0NN7tR/Y11+3gYtLOQwZUl+jnIiISh+2CBHlICoqER9+uB3ff39ao1wu18ewYQ2YBBERlQFsESLKxsGDtzFixO94+jQRhw7dwQcfVEOjRo7aDouIiAoZEyGi1yQnp+PLL//Cjz+el8qsrIzw/HmyFqMiIqKioruJkKmDtiOgEubKlUh4ee3GjRvPpLKuXatjw4YPYW9vpsXIiIioqOhuItR9u7YjoBJCpRJYvvwspk//G2lpSgDqXeMXL+6Izz5rCpmMY4GIiMoq3U2EiAA8e5aIQYN246+/7kll9erZw9+/D2rXLq/FyIiIqDhw1hjpNBMTOcLD46THU6Z44Pz50UyCiIh0BBMh0mmmpobw9++DKlWsEBg4BEuWdIJCwYZSIiJdwU980ilBQU9QrpwRXFyspbLGjZ1w69Z4yOX6WoyMiIi0gS1CpBOUShUWLjwBD4918PLajfR0pcZxJkFERLqJiRCVeeHhcWjffjO++uoIMjJUOHfuMdauvaTtsIiIqARg1xiVadu3X4e3937ExaUCAGQy4KuvWmP06EZajoyIiEoCJkJUJsXHp2L8+APYsuWqVFa5siW2bu2N1q2dtRgZERGVJEyEqMw5ffohBg/ejbCwF1LZoEF18fPPnrCyMtJeYEREVOIwEaIy5f79F2jbdiMyMlQAAAsLBVau9ISXVz0tR0ZERCURB0tTmVKlihU+/7wZAKBVq0q4csWbSRAREeWILUJUqgkhAEBjP7AFCz5A9erWGDOmMQwMmOsTEVHO+C1BpVZsbDL699+JlSsvaJQbGRlg3LimTIKIiOit2CJEpdLRo2EYMiQAjx8nYP/+W3j//SrcH4yIiPKNfzJTqZKWpsS0aYH44IPNePw4AQBgbGwg/T8REVF+sEWISo3Q0Gfw8tqN4OBIqax9+6rYtKkXKla00GJkRERUWjERohJPCIHVq4MwZcqfSE7OAADI5XpYuPAD+Ph4QE9P9pYrEBERZY+JEJVoMTFJGD78d+zff0sqc3e3hZ9fHzRs6KjFyIiIqCzgGCEq0QwM9HDt2lPp8bhxTRAUNIZJEBERFQomQlSiWVoaYevWPnB0NMO+fR/j55+7wcREru2wiIiojGDXGJUoV65EwtraGJUqWUpl771XGffuTYSREX9diYiocGm9RWjlypWoWrUqjIyM0LhxY5w4cSLHc3fv3o2OHTvCzs4OFhYW8PDwwOHDh4sxWioqKpXA0qVn0KzZWgwZEgClUqVxnEkQEREVBa0mQjt27MCkSZMwc+ZMBAcHo3Xr1ujatSvCw8OzPf/48ePo2LEjDhw4gIsXL6Jdu3bo0aMHgoODizlyKkxPniSgS5etmDz5T6SlKfHPPw+wfj3vKRERFT2ZyNysSQuaN2+ORo0aYdWqVVKZu7s7evXqhYULF+bpGrVr18aAAQMwe/bsPJ0fHx8PS0tLxMXFwcKCa89oW0BAKD75ZB9iYpKlsilTPDB/fnsoFGwFIiIitaL6/tbaN01aWhouXryI6dOna5R36tQJp0+fztM1VCoVEhISYG1tneM5qampSE1NlR7Hx8cXLGAqVImJafDxOQxf30tSmZOTOTZt6oUOHappMTIiItIlWusai46OhlKphL29vUa5vb09IiMjc6il6fvvv0diYiL69++f4zkLFy6EpaWl9FOpUqV3ipveXVDQEzRq9ItGEtSnjzuuXvVmEkRERMVK64OlZTLNVYGFEFnKsrNt2zZ888032LFjB8qXz3mzzRkzZiAuLk76efjw4TvHTAV3795zeHisw61bMQAAU1M51q3riZ07P4KNjYmWoyMiIl2jtUTI1tYW+vr6WVp/oqKisrQSvWnHjh0YNWoUfv31V3To0CHXcxUKBSwsLDR+SHuqVSuHUaMaAgCaNnVCcPBYjBzZME/JLxERUWHTWiJkaGiIxo0bIzAwUKM8MDAQLVu2zLHetm3bMHz4cPj7+6Nbt25FHSYVge+/74QlSzri1KmRcHW10XY4RESkw7TaNTZ58mSsXbsW69evR2hoKHx8fBAeHg5vb28A6m6toUOHSudv27YNQ4cOxffff48WLVogMjISkZGRiIuL09ZLoFzEx6di6NAAbNigORXe1NQQU6a0hFyur6XIiIiI1LQ6P3nAgAGIiYnBt99+i4iICNSpUwcHDhyAs7MzACAiIkJjTaE1a9YgIyMDn332GT777DOpfNiwYdi4cWNxh0+5OH36IQYP3o2wsBcICLiJ1q2dUb16zrP7iIiItEGr6whpA9cRKloZGSrMm/cPvvvuBFQq9a+WhYUCO3b0Q5cu1bUcHRERlVZlbh0hKnvu3o2Fl9dunDv3WCp7773K2LKlN6pUsdJeYERERDlgIkTvTAiBTZuu4PPPD+LlyzQAgL6+DHPnvo/p09+Dvr7WV2kgIiLKFhMheifPnydjzJj92LkzRCpzcSkHf/++aNasghYjIyIiejsmQvROVCqB06dfLVI5alRDLFvWBWZmhlqMioiIKG/YZ0HvxMbGBJs29YKNjTF27vwIa9f2ZBJERESlBluEKF9CQ5/B2toY9vZmUlmHDtUQFjYR5uYKLUZGRESUf2wRojwRQmD16iA0bvwLRoz4HW+uusAkiIiISiMmQvRWUVGJ+PDD7fj00z+QnJyBgwfvYNOmK9oOi4iI6J2xa4xydejQHQwfvgdPnyZKZePGNUH//rW1GBUREVHhYCJE2UpOTsf06X9hxYrzUpmdnQnWr/8Q3bu7aTEyIiKiwsNEiLK4du0pBg3ajevXo6QyT09XrF/fU2OQNBERUWnHRIg03LkTiyZNfJGWpgQAGBkZYMmSjhg3rilkMpmWoyMiIipcHCxNGqpXt8aAAerxP/Xr2+PixTH47LNmTIKIiKhMYosQZfHTT55wdbXGtGmtoFDwV4SIiMoutgjpsMTENIwZsw87dlzXKLewUODrr9syCSIiojKP33Q6KijoCby8duPWrRj89lsIWrashEqVLLUdFhERUbFii5COUSpVWLjwBDw81uHWrRgAQFqaElevPtVyZERERMWPLUI6JDw8DkOGBOD48QdSWdOmTvDz6wNXVxstRkZERKQdTIR0xPbt1+HtvR9xcakAAJkM+Oqr1pgzpy3kcn0tR0dERKQdTITKuPj4VIwffwBbtlyVyipXtsTWrb3RurWzFiMjIiLSPiZCZVxSUjoOHrwjPf744zpYubIbrKyMtBgVERFRycDB0mWcg4MZ1q3rCQsLBbZu7Q1//75MgoiIiP7DFqEy5s6dWJQrZwQbGxOprGfPGggLmwhra2MtRkZERFTysEWojBBCYMOGYDRosBpjx+6HEELjOJMgIiKirJgIlQGxscno338nRo7ci8TEdOzaFYpt266/vSIREZGOY9dYKXf0aBiGDAnA48cJUtmoUQ3Rs2cNLUZFRERUOjARKqXS0pSYNesIliw5jcxesHLljODr2wN9+9bSbnBERESlBBOhUujmzWgMGrQLwcGRUln79lWxaVMvVKxoocXIiIiIShcmQqXMv/9Go1GjNUhOzgAAyOV6WLjwA/j4eEBPT6bl6IiIiEoXDpYuZdzcbNC1qysAwN3dFufPf4IpU1oyCSIiIioAtgiVMjKZDL/80h1ubtb4+uu2MDGRazskIiKiUksm3lxwpoyLj4+HpaUl4uLiYGFRssfTJCen48sv/0LHjtXQowdngZH2CSGQkZEBpVKp7VCIqAySy+XQ189+I/Ci+v5mi1AJdeVKJLy8duPGjWfYtu06rl37FA4OZtoOi3RYWloaIiIikJSUpO1QiKiMkslkqFixIszMiu/7jolQCaNSCSxffhbTp/+NtDT1X90vX6YhKOgJund303J0pKtUKhXCwsKgr68PJycnGBoaQibjuDQiKjxCCDx79gyPHj2Cq6trji1DhY2JUAny5EkChg/fg8DAe1JZ/fr28Pfvi1q17LQYGem6tLQ0qFQqVKpUCSYmJm+vQERUAHZ2drh//z7S09OZCOmagIBQfPLJPsTEJEtlU6Z4YP789lAoeJuoZNDT40RTIio62mhp5jeslr18mQYfn0NYuzZYKnNyMsemTb3QoUM1LUZGRERU9vHPOy17/jwZv/0WIj3u3bsmrl71ZhJERKQlX3/9NcaMGaPtMMqc1NRUVK5cGRcvXtR2KBqYCGlZpUqWWLOmO0xN5Vi7tgd27eoPGxuOwSAqbKdPn4a+vj66dOmi7VCK3P379yGTyaQfS0tLtGjRAvv27ctybnJyMubMmYMaNWpAoVDA1tYW/fr1w40bN7KcGx8fj5kzZ6JmzZowMjKCg4MDOnTogN27d6OsrMTy9OlTLF++HF999ZW2Qykyqamp+Pzzz2FrawtTU1P07NkTjx49yrVORkYGZs2ahapVq8LY2BjVqlXDt99+C5VKJZ0zfPhwjd87mUyGFi1aSMcVCgW++OILfPnll0X22gpE6Ji4uDgBQMTFxWnl+R88eCHi4lKylEdEJGghGqK8SU5OFiEhISI5OVnboRTYqFGjxMSJE4Wpqal48OBBkT5XRkaGUCqVRfocuQkLCxMAxF9//SUiIiJEaGio+Pzzz4VcLhfXrl2TzktJSREtW7YUFStWFDt27BD3798X586dE7169RKmpqbizJkz0rnPnz8XtWvXFhUrVhQbN24UN27cEP/++6/45ZdfhIuLi3j+/Hmxvb60tLQiu/b8+fNFp06d3vk6RRnju/L29hYVKlQQgYGB4tKlS6Jdu3aifv36IiMjI8c63333nbCxsRH79+8XYWFh4rfffhNmZmZi2bJl0jnDhg0TXbp0EREREdJPTEyMxnWio6OFoaGhCAkJyfZ5cvusKarvbyZCxWjbtmvC0nKhGDo0oNifm+hdlPZE6OXLl8Lc3FzcvHlTDBgwQMydO1c61qJFC/Hll19qnB8VFSUMDAzEkSNHhBBCpKamiqlTpwonJydhYmIimjVrJo4ePSqdv2HDBmFpaSn27dsn3N3dhb6+vrh37544f/686NChg7CxsREWFhaiTZs24uLFixrPFRoaKlq1aiUUCoVwd3cXgYGBAoAICAiQznn06JHo37+/sLKyEtbW1qJnz54iLCwsx9ebmQgFBwdLZfHx8QKAWLFihVT2v//9T8hkMnH58mWN+kqlUjRp0kTUqlVLqFQqIYQQn376qTA1NRWPHz/O8nwJCQkiPT09x3h+//130bhxY6FQKISNjY3o3bu3dOzN1yqEEJaWlmLDhg0ar2XHjh2ibdu2QqFQiGXLlgkjIyNx8OBBjXq7du0SJiYmIiEhoUDvmxBC1K1bV/z0008aZQcPHhStWrUSlpaWwtraWnTr1k3cuXNHOp5djOvXrxdCCLF+/XpRs2ZNoVAoRI0aNcTPP/+sce1p06YJV1dXYWxsLKpWrSpmzZpVpEnUixcvhFwuF9u3b5fKHj9+LPT09MShQ4dyrNetWzcxcuRIjbI+ffqIwYMHS4+HDRsmPvzww7fG8P7774uvv/4622PaSITYNVYM4uNTMXRoAD7+eBfi4lKxefMV7NoV8vaKRFQoduzYgRo1aqBGjRoYPHgwNmzYIHXleHl5Ydu2bRpdOzt27IC9vT3atm0LABgxYgROnTqF7du34+rVq/joo4/QpUsX3L59W6qTlJSEhQsXYu3atbhx4wbKly+PhIQEDBs2DCdOnMDZs2fh6uoKT09PJCQkAFCvz9SrVy+YmJjg3Llz+OWXXzBz5kyN2JOSktCuXTuYmZnh+PHjOHnyJMzMzNClSxekpaXl6fWnp6fD19cXgHrl3kz+/v7o2LEj6tevr3G+np4efHx8EBISgitXrkClUmH79u3w8vKCk5NTluubmZnBwCD7uTd//PEH+vTpg27duiE4OBh///03mjRpkqe4X/fll19iwoQJCA0NxUcffYRu3brBz89P4xx/f398+OGHMDMzK9D79vz5c1y/fj1LfImJiZg8eTIuXLiAv//+G3p6eujdu7dGt9CbMXbu3Bm+vr6YOXMm5s+fj9DQUCxYsABff/01Nm3aJNUxNzfHxo0bERISguXLl8PX1xdLly7N9b2oXbs2zMzMcvypXbt2jnUvXryI9PR0dOrUSSpzcnJCnTp1cPr06Rzrvffee/j7779x69YtAMCVK1dw8uRJeHp6apx37NgxlC9fHm5ubvjkk08QFRWV5VrNmjXDiRMncn2NxapQ06pSoLhbhE6efCCqVFkmgG+kn48/3imePy+df1mTbsrxr7QtjYVYXaH4f7Y0zlf8LVu2lJrw09PTha2trQgMDBRCvGr9OX78uHS+h4eHmDp1qhBCiDt37giZTJalJeSDDz4QM2bMEEKoW4QAZGlZeVNGRoYwNzcX+/btE0KoWxoMDAxERESEdM6bLULr1q0TNWrUkFpmhFC3UBkbG4vDhw9n+zyZLRTGxsbC1NRU6OnpCQCiSpUqGl0VRkZGYuLEidle49KlS1Irx9OnTwUA8cMPP+T6+rLj4eEhvLy8cjyOPLYIvd4FI4QQu3fvFmZmZiIxMVEIof5sNzIyEn/88YcQomDvW3BwsAAgwsPDc31NUVFRAoDUzZhTjJUqVRL+/v4aZfPmzRMeHh45XnvRokWicePcf7/v378vbt++nePP/fv3c6zr5+cnDA0Ns5R37NhRjBkzJsd6KpVKTJ8+XchkMmFgYCBkMplYsGCBxjnbt28X+/fvF9euXRN79+4V9evXF7Vr1xYpKZrDQZYvXy6qVKmS7fNoo0WI0+eLSHq6EvPmHcf8+SegUqn/0rSwUGDlSk94edXTcnREhSQxEnj5WNtR5Orff//F+fPnsXv3bgCAgYEBBgwYgPXr16NDhw6ws7NDx44d4efnh9atWyMsLAxnzpzBqlWrAACXLl2CEAJubporu6empsLGxkZ6bGhoiHr1NP9tR0VFYfbs2Thy5AiePn0KpVKJpKQkhIeHS7FVqlQJDg4OUp1mzZppXOPixYu4c+cOzM3NNcpTUlJw9+7dXF/7jh07ULNmTdy6dQuTJk3C6tWrYW1tnZe3TWohk8lkGv+fX5cvX8Ynn3yS73pverOVplu3bjAwMMDevXsxcOBA7Nq1C+bm5lJLR0Het+Rk9TpuRkZGGuV3797F119/jbNnzyI6OlpqCQoPD0edOnWyjfHZs2d4+PAhRo0apfH6MzIyYGlpKT3euXMnli1bhjt37uDly5fIyMh46z5azs7OuR4vCCFErvd3x44d2Lp1K/z9/VG7dm1cvnwZkyZNgpOTE4YNGwYAGDBggHR+nTp10KRJEzg7O0utgpmMjY1L1FY9TISKwJ07sRg8eDfOnXv1BdGqVSVs3doHVapYaS8wosJm6vD2c7T8vOvWrUNGRgYqVKgglQkhIJfL8fz5c5QrVw5eXl6YOHEifvzxR+mDPrO7SKVSQV9fHxcvXsyy0u3r+yEZGxtn+SIZPnw4nj17hmXLlsHZ2RkKhQIeHh5S18zbvnwyn79x48ZZuoEA9Sq8ualUqRJcXV3h6uoKMzMz9O3bFyEhIShfvjwAwM3NDSEh2XfT37x5EwDg6uoKOzs7lCtXDqGhobk+X3aMjY1zPf56opUpPT09y3mmpqYajw0NDdGvXz/4+/tj4MCB8Pf3x4ABA6QuuoK8b7a2tgDUXWSvn9OjRw9UqlQJvr6+cHJygkqlQp06dbJ0sb0eY2ay5Ovri+bNm2ucl/l7dPbsWQwcOBBz585F586dYWlpie3bt+P777/PNr5MtWvXxoMHD3I87uzsnO2sPwBwcHBAWlqa9LufKSoqCi1btszxmlOnTsX06dMxcOBAAEDdunXx4MEDLFy4UEqE3uTo6AhnZ2eNLmQAiI2NfevvbnFiIlTIQkOfoWlTXyQmqv8h6+vL8M0372P69PdgYMAhWVTGDA7SdgS5ysjIwObNm/H9999rjIkAgL59+8LPzw/jx49Hr169MHbsWBw6dAj+/v4YMmSIdF7Dhg2hVCoRFRWF1q1b5+v5T5w4gZUrV0rjKB4+fIjo6GjpeM2aNREeHo6nT5/C3t4eAHDhwgWNazRq1Ag7duxA+fLl32nH7bZt26JOnTqYP38+li9fDgAYOHAgZs6ciStXrmiME1KpVFi6dClq1aqF+vXrQyaTYcCAAdiyZQvmzJmTZZxQYmIiFApFtuOE6tWrh7///hsjRozINi47OztERERIj2/fvp3n1gIvLy906tQJN27cwNGjRzFv3jzpWEHeNxcXF1hYWCAkJERqAYyJiUFoaCjWrFkj3f+TJ0++9Vr29vaoUKEC7t27By8vr2zPOXXqFJydnTXGheWW4GQ6cOBAtsliptfHgb2pcePGkMvlCAwMRP/+/QEAERERuH79OhYtWpRjvaSkpCwry+vr62cZJ/W6mJgYPHz4EI6Ojhrl169fR8OGDXOsV+wKtaOtFCjqMUIqlUp06bJVAN8IF5fl4uzZh0XyPETFqbTOGgsICBCGhobixYsXWY599dVXokGDBtLjQYMGifr16wuZTJZler2Xl5eoUqWK2LVrlzQb7H//+580HiVz1tibGjRoIDp27ChCQkLE2bNnRevWrYWxsbFYunSpEEI9ZqhGjRqic+fO4sqVK+LkyZOiefPmAoDYs2ePEEKIxMRE4erqKt5//31x/Phxce/ePXHs2DExYcIE8fBh9p8v2c0aE0KIvXv3CoVCIR49eiSEUN/X5s2bi0qVKolff/1VPHjwQJw/fz7b6fOxsbGiZs2aomLFimLTpk3ixo0b4tatW2LdunWievXqOU6fP3r0qNDT0xOzZ88WISEh4urVq+L//u//pOMDBw4U7u7u4uLFi+LChQuiffv2Qi6XZxkj9OZrEUL9eVuxYkVRv3594eLionGsIO+bEOqZUFOmTJEeK5VKYWNjIwYPHixu374t/v77b9G0aVONsU05xejr6yuMjY3FsmXLxL///iuuXr0q1q9fL77//nshhBB79uwRBgYGYtu2beLOnTti+fLlwtraOtvfpcLk7e0tKlasKP766y9x6dIl0b59+yzT59u3by9+/PFH6fGwYcNEhQoVpOnzu3fvFra2tmLatGlCCPXMwSlTpojTp0+LsLAwcfToUeHh4SEqVKgg4uPjNZ7f2dlZbN68OdvYOH2+GBTHYOmIiAQxceJBkZCQWmTPQVScSmsi1L17d+Hp6ZntsYsXLwoA0nT2P/74QwAQbdq0yXJuWlqamD17tqhSpYqQy+XCwcFB9O7dW1y9elUIkXMidOnSJdGkSROhUCiEq6ur+O2334Szs7OUCAnxavq8oaGhqFmzpti3b58AoDGVOSIiQgwdOlTY2toKhUIhqlWrJj755JMcP8dy+mJWqVSiRo0a4tNPP5XKEhMTxaxZs0T16tWFXC4X1tbWom/fvhrrDWV68eKFmD59unB1dRWGhobC3t5edOjQQQQEBGgMSn7Trl27RIMGDYShoaGwtbUVffr0kY49fvxYdOrUSZiamgpXV1dx4MCBbAdLZ5cICSHE1KlTBQAxe/bsLMfy+74JIcShQ4dEhQoVNNaBCgwMFO7u7kKhUIh69eqJY8eO5SkREkI9ODnztZcrV060adNG7N69WyN+GxsbYWZmJgYMGCCWLl1a5IlQcnKyGD9+vLC2thbGxsaie/fuWQaIOzs7izlz5kiP4+PjxcSJE0XlypWFkZGRqFatmpg5c6ZITVV/zyUlJYlOnToJOzs7IZfLReXKlcWwYcOyXPf06dPCyspKJCUl5RhbcSdCMiHKyHKgeRQfHw9LS0vExcW9UzMzAKSlKfH110fQsaMLt8SgMi0lJQVhYWGoWrVqloGkVLhOnTqF9957D3fu3IGLi4u2w9E5Qgi0aNECkyZNwscff6ztcMqcjz76CA0bNsxx5e7cPmsK8/v7dRwjVEA3b0Zj0KBdCA6OxNat13D1qje3xiCifAsICICZmRlcXV1x584dTJw4Ea1atWISpCUymQy//PILrl69qu1QypzU1FTUr18fPj4+2g5FAxOhfBJCYM2ai5g8+TCSkzMAAM+eJeL06Yfo0aOGlqMjotImISEB06ZNw8OHD2Fra4sOHTq8ddYQFa369etnWWSS3p1CocCsWbO0HUYWTITyISoqEaNH78W+fbekMnd3W/j790WDBlqaRkxEpdrQoUMxdOhQbYdBpLOYCOXRoUN3MHz4Hjx9miiVjRvXBIsXd4KJSc5TFYmIiKjkYiL0FsnJ6Zg+/S+sWHFeKrOzM8H69R+ie3e3XGoSERFRScdE6C2ePEnAunXB0mNPT1esX98T9vZmudQiKpt0bJIpERUzbXzGcKnjt3BxscaKFV1hZGSAn37qiv37P2YSRDonc6XakrQ/EBGVPZnblry5nU1RYovQG548SYCVlZHGuJ8RIxrggw+qwtnZSnuBEWmRvr4+rKysEBUVBQAwMTEp0AacREQ5UalUePbsGUxMTLLdrqWoMBF6TUBAKD75ZB8++qgWVq3qLpXLZDImQaTzMndIz0yGiIgKm56eHipXrlysf2gxEQLw8mUafHwOYe1a9Vig1asvols3Nw6GJnqNTCaDo6Mjypcvn+uGj0REBWVoaJhlc9eipvVEaOXKlVi8eDEiIiJQu3ZtLFu2LNcdnv/55x9MnjwZN27cgJOTE6ZNmwZvb+8CP/+FC4/h5bUbt2/HSmW9e9eEh0fFAl+TqCzT19cv1v57IqKipNXB0jt27MCkSZMwc+ZMBAcHo3Xr1ujatSvCw8OzPT8sLAyenp5o3bo1goOD8dVXX2HChAnYtWtXvp9bqVRh4cITaNlyvZQEmZjIsXZtD+za1Z/bZRAREekArW662rx5czRq1AirVq2Sytzd3dGrVy8sXLgwy/lffvkl9u7di9DQUKnM29sbV65cwZkzZ/L0nJmbtrVsuRKnT78a69C0qRP8/PrA1dXmHV4RERERFYWi2nRVay1CaWlpuHjxIjp16qRR3qlTJ5w+fTrbOmfOnMlyfufOnREUFJTvMQunT6tbnfT0ZJg5szVOnRrJJIiIiEjHaG2MUHR0NJRKJezt7TXK7e3tERkZmW2dyMjIbM/PyMhAdHQ0HB0ds9RJTU1Famqq9DguLi7zCCpWtISvb3e0bFkZycmJSE5+t9dERERERSM+Ph5A4S+6qPXB0m9OkRNC5DptLrvzsyvPtHDhQsydOzebI0vx6BHQteuM/AVMREREWhMTEwNLS8tCu57WEiFbW1vo6+tnaf2JiorK0uqTycHBIdvzDQwMYGOTfbfWjBkzMHnyZOnxixcv4OzsjPDw8EJ9I6lg4uPjUalSJTx8+LBQ+3wp/3gvSg7ei5KD96LkiIuLQ+XKlWFtbV2o19VaImRoaIjGjRsjMDAQvXv3lsoDAwPx4YcfZlvHw8MD+/bt0yj7888/0aRJE2kLgDcpFAooFIos5ZaWlvylLkEsLCx4P0oI3ouSg/ei5OC9KDkKe50hrU6fnzx5MtauXYv169cjNDQUPj4+CA8Pl9YFmjFjBoYOHSqd7+3tjQcPHmDy5MkIDQ3F+vXrsW7dOnzxxRfaeglERERUiml1jNCAAQMQExODb7/9FhEREahTpw4OHDgAZ2dnAEBERITGmkJVq1bFgQMH4OPjg59//hlOTk5YsWIF+vbtq62XQERERKWY1gdLjxs3DuPGjcv22MaNG7OUtW3bFpcuXSrw8ykUCsyZMyfb7jIqfrwfJQfvRcnBe1Fy8F6UHEV1L7S6oCIRERGRNml1jBARERGRNjERIiIiIp3FRIiIiIh0FhMhIiIi0lllMhFauXIlqlatCiMjIzRu3BgnTpzI9fx//vkHjRs3hpGREapVq4bVq1cXU6RlX37uxe7du9GxY0fY2dnBwsICHh4eOHz4cDFGW/bl999GplOnTsHAwAANGjQo2gB1SH7vRWpqKmbOnAlnZ2coFAq4uLhg/fr1xRRt2Zbfe+Hn54f69evDxMQEjo6OGDFiBGJiYoop2rLr+PHj6NGjB5ycnCCTybBnz5631imU729Rxmzfvl3I5XLh6+srQkJCxMSJE4Wpqal48OBBtuffu3dPmJiYiIkTJ4qQkBDh6+sr5HK52LlzZzFHXvbk915MnDhR/N///Z84f/68uHXrlpgxY4aQy+Xi0qVLxRx52ZTf+5HpxYsXolq1aqJTp06ifv36xRNsGVeQe9GzZ0/RvHlzERgYKMLCwsS5c+fEqVOnijHqsim/9+LEiRNCT09PLF++XNy7d0+cOHFC1K5dW/Tq1auYIy97Dhw4IGbOnCl27dolAIiAgIBczy+s7+8ylwg1a9ZMeHt7a5TVrFlTTJ8+Pdvzp02bJmrWrKlRNnbsWNGiRYsii1FX5PdeZKdWrVpi7ty5hR2aTiro/RgwYICYNWuWmDNnDhOhQpLfe3Hw4EFhaWkpYmJiiiM8nZLfe7F48WJRrVo1jbIVK1aIihUrFlmMuigviVBhfX+Xqa6xtLQ0XLx4EZ06ddIo79SpE06fPp1tnTNnzmQ5v3PnzggKCkJ6enqRxVrWFeRevEmlUiEhIaHQN9jTRQW9Hxs2bMDdu3cxZ86cog5RZxTkXuzduxdNmjTBokWLUKFCBbi5ueGLL75AcnJycYRcZhXkXrRs2RKPHj3CgQMHIITA06dPsXPnTnTr1q04QqbXFNb3t9ZXli5M0dHRUCqVWXavt7e3z7JrfabIyMhsz8/IyEB0dDQcHR2LLN6yrCD34k3ff/89EhMT0b9//6IIUacU5H7cvn0b06dPx4kTJ2BgUKY+KrSqIPfi3r17OHnyJIyMjBAQEIDo6GiMGzcOsbGxHCf0DgpyL1q2bAk/Pz8MGDAAKSkpyMjIQM+ePfHjjz8WR8j0msL6/i5TLUKZZDKZxmMhRJayt52fXTnlX37vRaZt27bhm2++wY4dO1C+fPmiCk/n5PV+KJVKDBo0CHPnzoWbm1txhadT8vNvQ6VSQSaTwc/PD82aNYOnpyd++OEHbNy4ka1ChSA/9yIkJAQTJkzA7NmzcfHiRRw6dAhhYWHSZuFUvArj+7tM/Zlna2sLfX39LJl8VFRUlqwxk4ODQ7bnGxgYwMbGpshiLesKci8y7dixA6NGjcJvv/2GDh06FGWYOiO/9yMhIQFBQUEIDg7G+PHjAai/jIUQMDAwwJ9//on27dsXS+xlTUH+bTg6OqJChQqwtLSUytzd3SGEwKNHj+Dq6lqkMZdVBbkXCxcuRKtWrTB16lQAQL169WBqaorWrVvju+++Yy9CMSqs7+8y1SJkaGiIxo0bIzAwUKM8MDAQLVu2zLaOh4dHlvP//PNPNGnSBHK5vMhiLesKci8AdUvQ8OHD4e/vzz73QpTf+2FhYYFr167h8uXL0o+3tzdq1KiBy5cvo3nz5sUVeplTkH8brVq1wpMnT/Dy5Uup7NatW9DT00PFihWLNN6yrCD3IikpCXp6ml+d+vr6AF61RlDxKLTv73wNrS4FMqdCrlu3ToSEhIhJkyYJU1NTcf/+fSGEENOnTxdDhgyRzs+cfufj4yNCQkLEunXrOH2+kOT3Xvj7+wsDAwPx888/i4iICOnnxYsX2noJZUp+78ebOGus8OT3XiQkJIiKFSuKfv36iRs3boh//vlHuLq6itGjR2vrJZQZ+b0XGzZsEAYGBmLlypXi7t274uTJk6JJkyaiWbNm2noJZUZCQoIIDg4WwcHBAoD44YcfRHBwsLSUQVF9f5e5REgIIX7++Wfh7OwsDA0NRaNGjcQ///wjHRs2bJho27atxvnHjh0TDRs2FIaGhqJKlSpi1apVxRxx2ZWfe9G2bVsBIMvPsGHDij/wMiq//zZex0SocOX3XoSGhooOHToIY2NjUbFiRTF58mSRlJRUzFGXTfm9FytWrBC1atUSxsbGwtHRUXh5eYlHjx4Vc9Rlz9GjR3P9Diiq72+ZEGzLIyIiIt1UpsYIEREREeUHEyEiIiLSWUyEiIiISGcxESIiIiKdxUSIiIiIdBYTISIiItJZTISIiIhIZzERIiINGzduhJWVlbbDKLAqVapg2bJluZ7zzTffoEGDBsUSDxGVbEyEiMqg4cOHQyaTZfm5c+eOtkPDxo0bNWJydHRE//79ERYWVijXv3DhAsaMGSM9lslk2LNnj8Y5X3zxBf7+++9Ceb6cvPk67e3t0aNHD9y4cSPf1ynNiSlRScdEiKiM6tKlCyIiIjR+qlatqu2wAKg3dY2IiMCTJ0/g7++Py5cvo2fPnlAqle98bTs7O5iYmOR6jpmZWb52py6o11/nH3/8gcTERHTr1g1paWlF/txElDdMhIjKKIVCAQcHB40ffX19/PDDD6hbty5MTU1RqVIljBs3TmNX8zdduXIF7dq1g7m5OSwsLNC4cWMEBQVJx0+fPo02bdrA2NgYlSpVwoQJE5CYmJhrbDKZDA4ODnB0dES7du0wZ84cXL9+XWqxWrVqFVxcXGBoaIgaNWpgy5YtGvW/+eYbVK5cGQqFAk5OTpgwYYJ07PWusSpVqgAAevfuDZlMJj1+vWvs8OHDMDIywosXLzSeY8KECWjbtm2hvc4mTZrAx8cHDx48wL///iudk9v9OHbsGEaMGIG4uDipZembb74BAKSlpWHatGmoUKECTE1N0bx5cxw7dizXeIgoKyZCRDpGT08PK1aswPXr17Fp0yYcOXIE06ZNy/F8Ly8vVKxYERcuXMDFixcxffp0yOVyAMC1a9fQuXNn9OnTB1evXsWOHTtw8uRJjB8/Pl8xGRsbAwDS09MREBCAiRMnYsqUKbh+/TrGjh2LESNG4OjRowCAnTt3YunSpVizZg1u376NPXv2oG7dutle98KFCwCADRs2ICIiQnr8ug4dOsDKygq7du2SypRKJX799Vd4eXkV2ut88eIF/P39AUB6/4Dc70fLli2xbNkyqWUpIiICX3zxBQBgxIgROHXqFLZv346rV6/io48+QpcuXXD79u08x0REQJncfZ5I1w0bNkzo6+sLU1NT6adfv37Znvvrr78KGxsb6fGGDRuEpaWl9Njc3Fxs3Lgx27pDhgwRY8aM0Sg7ceKE0NPTE8nJydnWefP6Dx8+FC1atBAVK1YUqampomXLluKTTz7RqPPRRx8JT09PIYQQ33//vXBzcxNpaWnZXt/Z2VksXbpUegxABAQEaJwzZ84cUb9+fenxhAkTRPv27aXHhw8fFoaGhiI2NvadXicAYWpqKkxMTKSdtHv27Jnt+Znedj+EEOLOnTtCJpOJx48fa5R/8MEHYsaMGblen4g0GWg3DSOiotKuXTusWrVKemxqagoAOHr0KBYsWICQkBDEx8cjIyMDKSkpSExMlM553eTJkzF69Ghs2bIFHTp0wEcffQQXFxcAwMWLF3Hnzh34+flJ5wshoFKpEBYWBnd392xji4uLg5mZGYQQSEpKQqNGjbB7924YGhoiNDRUY7AzALRq1QrLly8HAHz00UdYtmwZqlWrhi5dusDT0xM9evSAgUHBP868vLzg4eGBJ0+ewMnJCX5+fvD09ES5cuXe6XWam5vj0qVLyMjIwD///IPFixdj9erVGufk934AwKVLlyCEgJubm0Z5ampqsYx9IipLmAgRlVGmpqaoXr26RtmDBw/g6ekJb29vzJs3D9bW1jh58iRGjRqF9PT0bK/zzTffYNCgQfjjjz9w8OBBzJkzB9u3b0fv3r2hUqkwduxYjTE6mSpXrpxjbJkJgp6eHuzt7bN84ctkMo3HQgiprFKlSvj3338RGBiIv/76C+PGjcPixYvxzz//aHQ55UezZs3g4uKC7du349NPP0VAQAA2bNggHS/o69TT05PuQc2aNREZGYkBAwbg+PHjAAp2PzLj0dfXx8WLF6Gvr69xzMzMLF+vnUjXMREi0iFBQUHIyMjA999/Dz099RDBX3/99a313Nzc4ObmBh8fH3z88cfYsGEDevfujUaNGuHGjRtZEq63eT1BeJO7uztOnjyJoUOHSmWnT5/WaHUxNjZGz5490bNnT3z22WeoWbMmrl27hkaNGmW5nlwuz9NstEGDBsHPzw8VK1aEnp4eunXrJh0r6Ot8k4+PD3744QcEBASgd+/eebofhoaGWeJv2LAhlEoloqKi0Lp163eKiUjXcbA0kQ5xcXFBRkYGfvzxR9y7dw9btmzJ0lXzuuTkZIwfPx7Hjh3DgwcPcOrUKVy4cEFKSr788kucOXMGn332GS5fvozbt29j7969+Pzzzwsc49SpU7Fx40asXr0at2/fxg8//IDdu3dLg4Q3btyIdevW4fr169JrMDY2hrOzc7bXq1KlCv7++29ERkbi+fPnOT6vl5cXLl26hPnz56Nfv34wMjKSjhXW67SwsMDo0aMxZ84cCCHydD+qVKmCly9f4u+//0Z0dDSSkpLg5uYGLy8vDB06FLt370ZYWBguXLiA//u//8OBAwfyFRORztPmACUiKhrDhg0TH374YbbHfvjhB+Ho6CiMjY1F586dxebNmwUA8fz5cyGE5uDc1NRUMXDgQFGpUiVhaGgonJycxPjx4zUGCJ8/f1507NhRmJmZCVNTU1GvXj0xf/78HGPLbvDvm1auXCmqVasm5HK5cHNzE5s3b5aOBQQEiObNmwsLCwthamoqWrRoIf766y/p+JuDpffu3SuqV68uDAwMhLOzsxAi62DpTE2bNhUAxJEjR7IcK6zX+eDBA2FgYCB27NghhHj7/RBCCG9vb2FjYyMAiDlz5gghhEhLSxOzZ88WVapUEXK5XDg4OIjevXuLq1ev5hgTEWUlE0II7aZiRERERNrBrjEiIiLSWUyEiIiISGcxESIiIiKdxUSIiIiIdBYTISIiItJZTISIiIhIZzERIiIiIp3FRIiIiIh0FhMhIiIi0llMhIiIiEhnMREiIiIincVEiIiIiHTW/wNfG0fpBlM16wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "n_classes = y_val_bin.shape[1]\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_val_bin[:, i], y_val_pred_bin[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot average ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"], color='darkorange', lw=2, label='Average ROC curve (area = %0.2f)' % roc_auc[\"macro\"])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.savefig('./output/mlp_addresses_features_only_3r.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d245961e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
